
% Откуда
% Steele, final 2006 solutions:
% уже: problem 1
% надо: довнести остальные

% Lones Smith, solving SDE by...
% надо: внести способ
%
%
% глава стох. анализ и бесконечно малые (спасение бесконечно малых дело рук самих бесконечно малых)
%
% глава стох. анализ и пространства (Prato), итальянец btw
%
%



\problemtext{
Цель: строгий курс для студентов не имеющих подготовки по теории меры, но знающих элементарный курс теории вероятностей. Дойти до простых SDE и модели БШ. Книга должна быть открыто доступна в интернете.

Пригодность для самостоятельной подготовки: после каждой subsection идет небольшое количество (5?) задач, которые нужно решить для себя. На них есть ответы. После каждой section идут дополнительные задачи (уже не обязательно с ответами?)


Идеология курса: \par
Все определения - строго \par
Все теоремы - строго формулируются \par
Несложные теоремы - строго доказываются \par
Сложные теоремы - по возможности дается набросок доказательства и ссылки для любопытных \par

Вопросы, приветы - \url{boris.demeshev@gmail.com}


Задачи на док-во лучше формулировать <<Верно ли что, ...>>, а не <<Докажите...>>
% доказать - доказать простой случай - дать схему доказательства - помахать руками на тему интуиции - дать точную ссылку, лучше несколько
% многопроходовый подход к учебнику - сначало кратко, затем подробнее, затем задраить люки
% богатство U[0;1] -> служит хорошей мотивацией для графика, где по оси х вся $\Omega$ - от нуля до одного, а любая случайная величина рисуется как обычная функция.

% условное мат. ожидание - сначала в дискретном случае, $\E(X|Y)=\sum 1_{Y=y_{i}}\E(X|Y=y_{i})$. Лучше без введения промежуточной функции f.

% ссылка how many borel sets are there
% www.math.dartmouth.edu/~m103f08/


% собрать диск с книгами, на которые идет ссылка


% вступление к каждой главе (?) в духе: в этой главе винни-пух узнает, что... и список всех определяемых слов и краткий текст теорем.
% в чем отличие от оглавления - все-таки в оглавлении покрупнее темы названы
% отличие от индекса в конце - там в алфавите
% или все-таки конце - мораль: и список определений/теорем

% некий стандарт для <<самое время попробовать упражнение ччч.ччч>>

% теоремы должны быть кликабельны - на английскую версию в википедии (!) или все-таки на русскую?
% конечно, текст открыто доступен в электронном виде!

% ссылки как у Williams - ?

Если доказательство больше страницы - в приложение.


Если временя урезано, то нарушать идеологию по принципу: \par
Оставлять только <<практические>> и компьютерные главы. \par



Глава 1. Счетность - несчетность множеств. \par
Сюда можно сделать подборку задач на повторение по теор. вер. \par
Кое-что вспомнить из матанализа. \par

Греческие буквы, аддитивный вариант, задачи из Crack \par


Глава 17. Path-Dependent Euro Option. \par


Аддон: комменты к популярных книжкам \par



}
\section{Прививки для туристов} \problemtext{

Здесь собраны сюжеты, которые нужно знать до изучения стох. анализа.

}\subsection{Бесконечности бывают разные}

\problemtext{
Икеевских карандашей никогда не наберешь достаточно!


\begin{mydef} % \label{aaa}
Множества $A$ и $B$ называются \indef{равномощными}, если между элементами этих множеств существует взаимно-однозначное соответствие.
\end{mydef}

\begin{myex} Множества $\{1,2,3,4\}$ и $\{5,11,12,17\}$ равномощны, так как есть взаимно-однозначное соответствие:

$1 \lra 5 $

$2 \lra 11 $

$3 \lra 12 $

$4 \lra 17 $
\end{myex}
\begin{myex} \label{Nto2N} Множество $\mathbb{N}$ натуральных чисел и множество четных натуральных чисел равномощны в силу соответствия:

$1 \lra 2$

$2 \lra 4$

$3 \lra 6$

$4 \lra 8$

...
\end{myex}


Заметим, что в определении требуется только существование взаимно-однозначного соответствия. Это не противоречит тому, что могут существовать другие, не взаимно-однозначные соответствия. В примере \ref{Nto2N} можно добиться и того, что среди натуральных чисел останутся <<лишние>>:

$1 \lra ?$

$2 \lra 2$

$3 \lra 4$

$4 \lra 6$

...

И того, что среди четных останутся <<лишние>>, а именно:

$? \lra 2$

$1 \lra 4$

$2 \lra 6$

$3 \lra 8$

...

\begin{myex} Множества $\{1,2,3,4\}$ и множество $\mathbb{N}$ неравномощны. При любой попытке построить взаимно-однозначное соответствие среди натуральных чисел останутся <<лишние>>.
\end{myex}

Возникает естественный вопрос, все ли бесконечные множества равномощны?


Пусть $S$ множество всех бесконечных вправо последовательностей из 0 и 1. Например, одним из элементов $S$ является последовательность 1010101010...

\begin{myth} Множество $S$ бесконечно, но не равномощно множеству $\mathbb{N}$.
\end{myth}

\begin{proof} Допустим противоположное, что $S$ и $\mathbb{N}$ равномощны. Тогда существует взаимно-однозначное соответствие между натуральными числами и последовательностями. К примеру оно могло бы выглядеть так:
$1 \lra 000000...$
$2 \lra 011000...$
$3 \lra 101011...$
$4 \lra 101001...$

...
Оказывается какое бы соответствие ни было создано, всегда существует последовательность, которой не сопоставлено ни одно число!

Создадим последовательность $a$ по следующему принципу: возьмем первую цифру из первой последовательности, затем вторую из второй, затем третью из третьей и т.д. В нашем примере $a=0110...$:
$1 \lra \underline{0}00000...$
$2 \lra 0\underline{1}1000...$
$3 \lra 10\underline{1}011...$
$4 \lra 101\underline{0}01...$


Затем построим последовательность $b$ заменив единицы на нули, а нули на единицы в последовательности $a$. В нашем примере $b=1001...$

Вне зависимости от того, какое соответствие мы взяли (как в примере, или любое другое) последовательность $b$ не может идти в нем ни под каким номером! Она не может идти под номером 1, так как отличается от первой последовательности первой цифрой. Она не может идти под номером 2, так как отличается от второй последовательности второй цифрой и т.д.

Мы пришли к противоречию, в $S$ есть <<лишняя>> незанумерованная последовательность $b$. Значит $S$ и $\mathbb{N}$ неравномощны.
\end{proof}
\begin{mydef} Мы говорим, что множество $A$ имеет мощность \indef{континуум}, \index{континуум} если оно равномощно множеству $S$ бесконечных вправо последовательностей из 0 и 1.
\end{mydef}
\begin{mydef} Множество $A$ называется \indef{счетным}, \index{счетное множество} если оно конечно или равномощно множеству $\mathbb{N}$ натуральных чисел.
\end{mydef}
Будьте бдительны при чтении других источников: некоторые авторы определяеют счетные как равномощные натуральным числам, но таких авторов меньшинство.

Из данного определения следует, что \indef{несчетные} \index{несчетное множество} множества - это бесконечные множества не равномощные множеству $\mathbb{N}$ натуральных чисел.

(...) картинка с классификацией конечные-бесконечные, счетные, несчетные

Оказывается, что любые бесконечные множества можно сравнивать: либо они равномощные, либо одно из них <<больше>>.

\begin{myth} Если $A$ и $B$, два произвольных множества, то возможна одна и только одна из трех ситуаций:
\begin{itemize}
\item[1.] $A$ и $B$ равномощны.
\item[2.] $A$ и $B$ неравномощны, но $A$ равномощно какому-нибудь подмножеству множества $B$.
\item[3.] $A$ и $B$ неравномощны, но $B$ равномощно какому-нибудь подмножеству множества $A$.
\end{itemize}
\end{myth}
\begin{proof} Доказательство можно найти (...). Может возникнуть вопрос, а что тут собственно доказывать, все же <<очевидно>>? Доказывать нужно два утверждения. Во-первых, что ситуации 2) и 3) не могут произойти одновременно. Во-вторых, что невозможна гипотетическая ситуация <<несравнимости>>, когда $A$ и $B$ неравномощны, в $A$ нет части равномощной $B$, и в $B$ нет части равномощной $A$.
\end{proof}

Из этой теоремы следует важное следствие:

\begin{myth}
Если $ A $ равномощно подмножеству $ B $, то $ A\preceq B $, т.е. либо мощность $ A$ меньше мощности $ B $, либо $ A $ и $ B $ равномощны.
\end{myth}



Важные примеры!

\begin{itemize}
\item Бесконечные счетные множества:

\begin{itemize}
\item $\mathbb{N}^{2}$. Картинка:

Фактически мы доказали, что объединение счетного количества счетных множеств счетно\footnote{Для знатоков может быть интересен тот факт, что в этом доказательстве неявно используется аксиома выбора. Без нее можно представить $\mathbb{R}$ как счетное объединение счетных множеств (ссылка, найти в Williams, Weighting the odds) }.
\item $\mathbb{Z}$. Картинка:

\item $\mathbb{Z}^{n}$
Доказательство --- по индукции. Мы уже доказали, что $ \mathbb{Z}^{1} $ --- счетное множество. Теперь предположим, что $ \mathbb{Z}^{n-1} $ --- счетное. Получаем цепочку: $ \mathbb{Z}^{n} \simeq \mathbb{Z}^{n-1}\times\mathbb{Z}^{1}\simeq \mathbb{N}\times \mathbb{N}\simeq \mathbb{N} $.
\item $\mathbb{Q}$. Пусть $ f(q) $ --- это сумма модулей числителя и знаменателя дроби (после сокращения), например, $ f(-2/3)=5 $. Сначала нумеруем дроби с $ f(q)<2 $, потом --- дроби с $ f(q)<3 $, потом --- дроби с $ f(q)<4 $ и т.д. В результате каждая дробь получает свой номер.
\end{itemize}



\item Множества мощности континуум:
\begin{itemize}
\item интервал $(0;1)$.
\item прямая $\mathbb{R}$
\item пространство $\mathbb{R}^{n}$
\item функции непрерывные на отрезке  $[0;1]$
\end{itemize}


\end{itemize}



Для целей стохастического анализа нам хватит этих сведений про мощности множеств, однако для общего развития полезно знать еще пару фактов.

Факт 1. Бесконечные множества не исчерпываются равномощными множеству $\mathbb{N}$ и множеству последовательностей $S$. Бесконечности бывают разные, и их бесконечно много. Если есть одно бесконечное множество $A$, то найдется бесконечное множесто $B$, где элементов еще больше, чем в $A$! А именно:

\begin{myth} Если $A$ произвольное множество, то $B$, множество всех подмножеств множества $A$, обозначаемое $2^{A}$, не равномощно множеству $A$.
\end{myth}
\begin{proof} Доказательству этого утверждения посвящено упражнение (...)
\end{proof}
Иными словами, подмножеств действительных чисел больше, чем действительных чисел. И так далее..

Факт 2. Невинный вопрос: а есть ли мощности промежуточные между континуумом и мощностью множества натуральных чисел? оказывается неожиданно сложным! Еще более неожиданно то, что любой ответ на него, и <<да>>, и <<нет>> оказывается верным. Для ответа на этот вопрос интуитивных представлениях о множествах не хватает и нужно аксиоматизировать теорию множеств. Так вот разные системы аксиом приводят к разным ответам. В данном курсе мы это обсуждать не будем. Но заинтересовавшиеся могут посмотреть книгу Верещагин Шень, Начала теории множеств,
\url{http://www.mccme.ru/free-books/}


%Автору больше нравится система аксиом, где промежуточных мощностей нет, но это уже вопрос вкуса.


%В данной книжке мы придерживаемся системы аксиом ZFC. Хотя бы просто потому, что автор (по крайней мере пока) не умеет думать без аксиомы выбора. Подробности можно найти Herrlich, Axiom of choice
\subsubsection*{Ссылки}

Любопытствующим: Всего 40 страниц заметок <<Set theory>> на \url{http://math.uga.edu/~pete/expositions.html}.




}

\subsubsection*{Задачи}

\problem{Чудо-чудное, диво-дивное! Существует ли список $S$ всех возможных мощностей?}
\solution{Нет! От противного, допустим $S$ существует. Для каждого $s\in S$ существует множество $A_{s}$ соответстующей мощности. Построим множество $A=\cup_{s}A_{s}$. Здесь испольуется аксиома выбора. И теперь построим множество $B=2^{A}$. Оно больше любого из $A_{s}$! Значит оно не было упомянуто в списке $S$.}




\subsection{Частичный предел. Верхний и нижний.}\problemtext{

Если есть последовательность $a_{i}$, то, забыв порядок чисел, можно рассмотреть ее как множество точек на числовой прямой.

\begin{myex} Последовательности $a_{n}=(-1)^{n}+\frac{1}{n}$ на прямой соответствует множество точек:

(рисунок)
\end{myex}
На прямой могут существовать точки в любой окрестности которых есть бесконечное количество членов последовательности $a_{n}$, в нашем примере это точки $x=-1$ и $x=1$. Это точки называются точками накопления.
\begin{mydef}
точка $x\in\R$ называется точкой \indef{накопления} или \indef{частичным пределом} для последовательности $a_{n}$, если в любой $\varepsilon$-окрестности точки $x$ содержится бесконечное количество членов последовательности $a_{n}$.
\end{mydef}
Заметим, что если точка $x$ является точкой накопления, то к ней можно <<подобраться>> сколь угодно близко выбрав некоторую подпоследовательность из последовательности $a_{n}$. Поэтому можно дать альтернативное определение:
\begin{mydef}
точка $x\in\R$ называется точкой \indef{накопления} или \indef{частичным пределом} для последовательности $a_{n}$, если из последовательности $a_{n}$ можно выбрать подпоследовательность $b_{k}$, сходящуюся к $x$.
\end{mydef}

Наконец про верхний и нижний частичные пределы. Наибольшая из точек накопления называется верхним частичным пределом, наименьшая - нижним частичным пределом. Обозначаются они $\limsup$ и $\liminf$, соответственно. Чтобы сделать эту мысль совсем точной, остается лишь добавить два крайних случая:
\begin{itemize}
\item Верхний частичный предел $\limsup a_{n}=+\infty$, если в последовательности $a_{n}$ можно найти сколь угодно большие положительные числа
\item Нижний частичный предел $\liminf a_{n}=-\infty$, если в последовательности $a_{n}$ можно найти сколь угодно сильно отрицательные числа
\end{itemize}

Если от последовательности отрезать сколько-то элементов в начале (будь то $10$, $100$ или $10^{100}$), то на точки накопления это никак не повлияет. Если вокруг некой точки $x$ было бесконечное количество членов последовательности, то после отрезания начала последовательности вокруг точки $x$ существенных изменений не произойдет. Именно на этой идее базируется формальное определение. Заодно оно проливает свет на происхождение обозначения:

\begin{mydef}
\indef{Верхний частичный предел} \index{Верхний частичный предел}, $\limsup_{n}a_{n}:=\lim_{n\to\infty}\sup_{k\geq n}a_{k}$.

\indef{Нижний частичный предел} \index{Нижний частичный предел}, $\liminf_{n}a_{n}:=\lim_{n\to\infty}\inf_{k\geq n}a_{k}$.
\end{mydef}

Несколько примеров.
\begin{myex}
Если $a_{n}=(-1)^{n}+\frac{1}{n}$, то $\limsup a_{n}=1$, $\liminf a_{n}=-1$
\end{myex}

\begin{myex}
Если $a_{n}=n(-1)^{n}$, то $\limsup a_{n}=+\infty$, $\liminf a_{n}=-\infty$
\end{myex}

\begin{myex}
Если $a_{n}=n(1+(-1)^{n})$, то $\limsup a_{n}=+\infty$, $\liminf a_{n}=0$
\end{myex}


}\subsection{Равномерная непрерывность}\problemtext{

Понадобится для доказательств связанных с характеристическими функциями.

Рассмотрим непрерывную функция $f:\R\to\R$ и произвольную точку $x_{0}$. Если мы хотим чтобы $f(x)$ не сильно отличалось от $f(x_{0})$, то нам достаточно взять значение $x$ не сильно отличающееся от $x_{0}$. А именно:

\begin{mydef}
Функция $f:\R\to\R$ называется непрерывной в точке $x_{0}$, если для любого $\delta$
 найдется такая $\varepsilon$-окрестность точки $x_{0}$, что для любого $x\in (x_{0}-\varepsilon;x_{0}+\varepsilon)$ будет выполнено неравенство $|f(x)-f(x_{0})|<\delta$.
\end{mydef}

При этом нужное $\varepsilon$ в общем случае будет зависить и от желаемого $\delta$ и от точки $x_{0}$:

\begin{myex}
Функция $f(t)=t^{2}$ на $\R$. Если мы хотим чтобы $f(x)$ отличалось от $f(2)=4$ не более, чем на 5, то достаточно взять $\varepsilon=1$. Действительно, если $|x-2|<1$, то $|f(x)-4|<5$. Однако, чтобы $f(x)$ отличалось от $f(10)=100$ не более, чем на 5, необходимо подойти к точке $x_{0}=10$ гораздо ближе чем на $\varepsilon=1$. Достаточным окажется лишь $\varepsilon=\sqrt{105}-10\approx 0.25$.
\end{myex}

Однако для некоторых функций необходимое $\varepsilon$ можно выбирать даже не зная точки $x_{0}$.

\begin{myex}
Функция $f(t)=2t+7$ на $\R$. Если мы хотим, чтобы $f(x)$ отличалось от $f(x_{0})$ не более, чем на 5, то достаточно взять $\varepsilon=2.5$, вне зависимости от $x_{0}$.
\end{myex}

Вот такие функции и называются равномерно непрерывными.
\begin{mydef}
Функция $f:\R\to\R$ называется \indef{равномерно непрерывной} на множестве $A\subset \R$, если для любого $\delta$ найдется такое $\varepsilon$, что для любых $x$ и $y$, таких что $|x-y|<\varepsilon$ будет выполнено неравенство $|f(x)-f(y)|<\delta$.
\end{mydef}

\begin{myex}
Функция $f(t)=cos(t)$ является равномерно непрерывной на $\R$.
\end{myex}

\begin{myex}
Функция $f(t)=t^{2}$ не является равномерно непрерывной на $\R$.
\end{myex}




}\subsection{Еще задачи}



\problem{Счетно ли множество $S_{1}$ бесконечных вправо последовательностей из 0 и 1, в которых количество 1 конечно? Для ясности, $1010101010...$ (нули и единицы чередуются) $\notin S_{1}$, но $010000000000...\in S_{1}$ (в последовательности только одна единица, стоящая на втором месте).}
\solution{}


\problem{Декартово произведение конечного количества счетных множеств
является счетным множеством. Да или нет?}
\solution{Да. Считаем <<змейкой>>}

\problem{Декартово произведение счетного количества счетных множеств
является счетным множеством. Да или нет?}
\solution{Нет. Бесконечные вправо последовательности из 0 и 1 - это декартово произведение счетного количества $A_{i}$, где каждое $A_{i}=\{0,1\}$}


\problem{An enemy submarine is somewhere on the number line (consider only integers for this problem). It is moving at some rate (again, integral units per minute). You know neither its position nor its velocity.\par
You can launch a torpedo each minute at any integer on the number line. If the the submarine is there, you hit it and it sinks. You have all the time and torpedoes you want. You must sink this enemy sub - devise a strategy that is guaranteed to eventually hit the enemy sub.}
\solution{Объединение счетного количества счетных множеств, считаем змейкой}

\problem{Пусть $A$ произвольное множество. Докажите, что мощность множества $2^{A}$ (множество всех подмножеств множества $A$) больше, чем мощность $A$.}
\solution{Мощность $2^{A}$ не меньше мощности $A$, т.к. есть одноточечные подмножества, которые можно сопоставить с элементами $A$. Допустим все же, что $2^{A}$ и $A$ равномощны. Значит есть взаимно однозначное соответствие $b\longleftrightarrow B$, где $b\in A$ и $B\in 2^{A}$. Построим $C\subset A$ по принципу: будем включать туда только такие $b$, которые не входят в соответствующее $B$. Этому множеству $C$ должен соответствовать некий элемент $c$. С одной стороны $c$ не может входить в $C$, с другой стороны - обязан. Противоречие.}

\problem{Верно ли следующее утверждение: у последовательности $a_{n}$ существует предел если и только если $\limsup a_{n}=\liminf a_{n}$}
\solution{да}


\section{Списки событий и сигма-алгебры} \problemtext{


}\subsection{Наделенность информацией и определение} \problemtext{
% Сигма-алгебры нужны для передачи наделенности информацией

Рассмотрим простой случайный эксперимент: игральный кубик подбрасывают два раза. Множество $\Omega$ исходов данного эксперимента содержит 36 элементов. Вася знает результат подбрасываний, и сообщает Пете значение случайной величины $Z$ - произведения очков на выпавших гранях.

Всегда ли сможет ли Петя владея своей информацией, определить произошли ли события:

$A$ - оба раза выпала единица,

$B$ - хотя бы раз выпала пятерка,

$C$ - хотя бы раз выпала шестерка?

Про события $A$ и $B$ Петя всегда сможет сказать произошли ли они: в первом случае достаточно сравнить $Z$ с единицей, во втором - определить, делится ли $Z$ на 5. Однако может сложиться такая ситуация, что Петя не будет уверен, произошло ли $C$: например, если $Z$ окажется равным шести, то может быть это была пара (6,1) и тогда $C$ произошло, а может это была пара $(2,3)$ и тогда $C$ не произошло.

Можно составить список событий, про которые Петя, зная $Z$, всегда сможет сказать, произошли ли они. Обозначим его буквой $\mathcal{F}$. В отличие от Пети Вася может уверенно сказать произошло ли любое событие и аналогичный список событий для него - все подмножества множества $\Omega$.

(упр) Приведите примеры еще 3 событий, входящих в \F, и еще 3-х событий не входящих в \F.

В список $\mathcal{F}$ входят довольно много событий, а сам список обладает рядом важных свойств, а именно:

1) $\Omega \in \mathcal{F}$ - даже ничего не зная, можно быть уверенным, что $\Omega$ произошло.

2) $\emptyset \in \mathcal{F}$ - даже ничего не зная, можно быть уверенным, что $\emptyset$ не произошло.

3) Если $A$ и $B$ входят в список $\mathcal{F}$, то $A\cup B$ и $A\cap B$ входят в список $\mathcal{F}$. Если Петя способен определить, произошли ли $A$ и $B$ по отдельности, то он путем простых логических заключений способен определить, произошли ли $A\cup B$ и $A\cap B$.

Подобные списки событий являются очень важными для нас и называются $\sigma$-алгебрами (<<сигма-алгебрами>>).

\begin{mydef} Набор подмножеств множества $\Omega$ называется $\sigma$-алгеброй\footnote{Правильный английский термин \s-algebra. В некоторых текстах встречается устаревшее $\sigma$-field. Для знающих определения поля и алгебры отметим, что \s-алгебра действительно будет полем, только если $\mathcal{F}=\{\emptyset,\Omega\}$. Вопрос для знатоков: относительно каких операций и над чем \s-алгебра будет алгеброй? }, если обладает следующими тремя свойствами:

SA1. $\Omega \in \mathcal{F}$

SA2. Если $A\in \mathcal{F}$, то $A^{c}\in \mathcal{F}$

SA3. Если $A_{1}\in\mathcal{F}$, $A_{2}\in\mathcal{F}$, $A_{3}\in\mathcal{F}$, и т.д., то $\cup_{i=1}^{\infty} A_{i} \in\mathcal{F}$.
\end{mydef}


\begin{myex}
\end{myex}

\begin{myex}
\end{myex}

Почему в определении $\sigma$-алгебры мы не потребовали, чтобы выполнялись все свойства (...)? Оказывается, неупомянутые свойства следуют из свойств SA1-SA3.

\begin{myex} Применив SA1, а затем SA2 можно понять, что в любую $\sigma$-алгебру входит пустое множество.
\end{myex}

\begin{myex} Пересечение множеств можно заменить на несколько объединений и дополнений, $\cap_{i=1}^{\infty} A_{i}=\left(\cup_{i=1}^{\infty}A_{i}^{c} \right)^{c}$. А значит из свойств SA2, SA3 следует также, что:

Если $A_{1}\in\mathcal{F}$, $A_{2}\in\mathcal{F}$, $A_{3}\in\mathcal{F}$, и т.д., то $\cap_{i=1}^{\infty} A_{i} \in\mathcal{F}$.
\end{myex}


Ссылка на упражнение про симметрическую разность (...)

Проще говоря, $\sigma$-алгебра - это набор событий замкнутый относительно любых операций с множествами ($\cup$, $\cap$, $()^{c}$, $\Delta$) взятых в счетном количестве.


Самое время упомянуть два полезных множества, которые точно находятся в $\sigma$-алгебре $\mathcal{F}$ (если известно, что все $A_{i}$ лежат в $\mathcal{F}$):

\begin{itemize}
\item $\limsup_{n} A_{n}$ - те исходы $w\in\Omega$, которые входят в бесконечное количество $A_{n}$. Почему это множество обязательно лежит в $\F$? Легко заметить, что $B_{n}=\cup_{k\geq n} A_{k}$ - это те исходы $w$, которые входят хотя бы в один $A_{k}$ при $k\geq n$. Чтобы $w$ входил в бесконечное количество $A_{n}$ необходимо и достаточно того, чтобы исход $w$ входил во все $B_{n}$. Значит, $\limsup_{n} A_{n}=\cap_{n}\cup_{k\geq n} A_{k}$.

\item $\liminf_{n} A_{n}$ - те исходы $w\in\Omega$, которые входят во все $A_{n}$, начиная с некоторого. Рассуждая аналогично, $C_{n}=\cap_{k\geq n} A_{k}$ - это те исходы $w$, которые входят во все $A_{k}$ при $k\geq n$. И, получается, что $\liminf_{n} A_{n}=\cup_{n}\cap_{k\geq n}A_{k}$

\end{itemize}





\begin{myex} При заданном наборе $\Omega$ исходов случайного эксперимента самая <<подробная>> $\sigma$-алгебра - это $2^{\Omega}$, множество всех подмножеств $\Omega$; а самая <<бедная>> $\sigma$-алгебра - это набор $\{\emptyset,\Omega\}$. Убедитесь, что аксиомы SA1-SA3 выполнены для обоих случаев!
\end{myex}




\begin{myth} Пересечение произвольного количества $\sigma$-алгебр - $\sigma$-алгебра.
\end{myth}
В силу этого простого наблюдения корректно говорить о минимальной $\sigma$-алгебре, порождаемой данным набором событие.

\begin{mydef} Пусть $\mathcal{H}$ - произвольный набор событий, не обязательно $\sigma$-алгебра. $\sigma$-алгебра $\mathcal{F}$ называется \indef{минимальной} $\sigma$-алгеброй \indef{порожденной} набором $\mathcal{H}$, если: $\mathcal{F}$ содержит набор $\mathcal{H}$, и любая другая $\sigma$-алгебра $\mathcal{F}'$, содержащая набор $\mathcal{H}$, содержит в себе $\mathcal{F}$. Обозначается порожденная $\sigma$-алгебра так: $\sigma(\mathcal{H})$.
\end{mydef}
Другими словами, чтобы найти $\sigma$-алгебру, содержащую заданный набор событий, можно рассмотреть все $\sigma$-алгебры, содержащие заданный набор событий, и взять их пересечение.

Заметим, что объединение даже двух $\sigma$-алгебр может не быть $\sigma$-алгеброй!

\begin{myex} Пусть $\mathcal{F}_{1}=\{\mathbb{R},\emptyset,(-\infty;1),[1;+\infty)\}$, $\mathcal{F}_{2}=\{\mathbb{R},\emptyset,(-\infty;2),[2;+\infty)\}$ - две $\sigma$-алгебры. Тогда, $\mathcal{F}_{1}\cup \mathcal{F}_{2}=\{\mathbb{R},\emptyset,(-\infty;1),[1;+\infty),(-\infty;2),[2;+\infty)\}$ - не $\sigma$-алгебра.
\end{myex}


В качестве небольшого итога: \s-алгебра, это список событий различимых рациональным индивидом. Т.е. список событий, про каждое из которых рациональный индивид (умеющий делать простые логические заключения) может гарантированно сказать, произошло они или нет. Забежим немного вперед и скажем, что именно для событий из \s-алгебры мы будем определять вероятность. У каждого события из данной \s-алгебры \F будет определена вероятность, число от 0 до 1. А у событий не входящих в \s-алгебру \F вероятности не будет вообще.







}\subsection{Борелевская сигма-алгебра} \problemtext{
Из всех искусств для нас важнейшим является кино\footnote{Об этой цитате можно прочесть на \url{http://liveuser.livejournal.com/62878.html}}. (Ленин)


Из всех $\sigma$-алгебр для нас важнейшей является борелевская $\sigma$-алгебра!!!


\begin{mydef} \indef{Борелевская} $\sigma$-алгебра - это $\sigma$-алгебра порожденная открытыми подмножествами множества $\Omega$.
\end{mydef}

Чаще всего нам понадобятся борелевские $\sigma$-алгебры: $\mathcal{B}(\mathbb{R})$ и $\mathcal{B}(\mathbb{R}^{n})$.

Заметим, что сам набор открытых множеств не является $\sigma$-алгеброй. Например, множество $A=(-\infty;2)$ является
открытым, а множество $\R\backslash A$ не является открытым.


\begin{mydef} Множество называется \indef{борелевским} если оно является элементом борелевской $\sigma$-алгебры
\end{mydef}

\begin{myex} Например на $ \Omega=\mathbb{R} $ борелевскими являются:
\begin{itemize}
\item любой интервал, например $(2;100)$ - т.к. он является открытым множеством
\item любой отрезок, например $[2;100]$ - т.к. его можно получить в виде $\mathbb{R}\backslash((-\infty;2)\cup (100;+\infty))$
\item любую произвольную точку, например $\{7\}$ - т.к. ее можно получить в виде $\mathbb{R}\backslash ((-\infty;7)\cup (7;+\infty))$
\item любой полуинтервал, например $[2;100)$ - т.к. его можно представить в виде объединения $[2;3] \cup (3;100)$
\end{itemize}
\end{myex}

Самое время решить упражнение (...), которое показывает, что все <<привычные>> множества - борелевские.

Существуют ли неборелевские множества? Да, существуют! Но они очень <<страшные>> и не будут изучаться в этой книжке. Их даже больше, чем борелевских. Ситуация с ними похожа на ситуация с иррациональными числами: иррациональных больше, чем рациональных, но используют при практических расчетах как-правило рациональные. А именно:

\begin{myth} Мощность борелевской $\sigma$-алгебры $\mathcal{B}(\mathbb{R})$ - континуум.
\end{myth}
\begin{proof} ссылка или в аппедникс? (...)
\end{proof}
Из этой теоремы следует, что неборелевских множеств больше, а именно $2^{continuum}$ (...)


Чуть позже (...) мы приведем три примера неборелевских множеств.


Борелевскую $\sigma$-алгебру можно породить также с помощью более простых наборов множеств. Например:

\begin{myth} \label{generate_borel}

Если $\mathcal{H}=\{(-\infty;t]|t\in\R\}$, то $\s(\mathcal{H})=\B$.
\end{myth}
\begin{proof} Шаг 1. Заметим, что $\mathcal{H}\subset\B$ и следовательно $\s(\mathcal{H})\subset\B$. Для того, чтобы доказать равенство обеих частей, осталось доказать, что любое открытое множество войдет в $\s(\mathcal{H})$.

Шаг 2. Множества вида $(a;b]$ входят в $\s(\mathcal{H})$, т.к. в рамках \s-алгебры можно брать разность множеств, а $(a;b]=(-\infty;b]\backslash (-\infty;a]$.

Шаг 3. Пусть $A$ - произвольное открытое множество. Мы докажем, что можно построить последовательность $A_{1}$, $A_{2}$, ..., такую, что каждое $A_{i}$ лежит в $\s(\mathcal{H})$ и $A=\cup A_{i}$. И следовательно, $A\in\s(\mathcal{H})$:

В качестве $A_{1}$ возьмем объединение тех множеств вида $(n;n+1]$, где $n$ - целое, а $(n;n+1]$ лежит в $A$.
В качестве $A_{2}$ ... $(0.5n;0.5(n+1)]$
...
В качестве $A_{k}$ ... $(0.5^{k-1}n;0.5^{k-1}(n+1)]$.

Иллюстрация для $A=(0;\sqrt{3})=(0;1.73...)$:
$A_{1}=(0;1]$, $A_{2}=(0;1.5]$, $A_{3}=(0;1.5]$, $A_{4}=(0;1.625]$ и т.д.

Почему нас всегда ждет успех? Рассмотрим произвольную точку $a\in A$. Вокруг любой точки открытого множества $A$ можно найти $\varepsilon$-окрестность, которая целиком лежит $A$. Длина кусочков, из которых состоит каждое $A_{k}$ стремится к 0. Значит наступит, такой момент, когда кусочки очередного $A_{k}$ <<залезут>> в произвольную $\varepsilon$-окрестность и покроют точку $a$. Следовательно, любая точка из $A$ лежит в некотором $A_{k}$. А, значит, $A=\cup_{i} A_{i}$.
\end{proof}
...

Заметим, что в качестве порождающих множеств можно взять, например, такие наборы:

....

}
\subsubsection*{Задачи}

\problem{Верно ли, что борелевскими являются следующие подмножества $\mathbb{R}$: a) множество целых чисел $\mathbb{Z}$ b) множество решений уравнения $cos(2x)+x=0$ c) множество решений неравенства $x^{5}-5x^{4}+x^{3}-x+8\geq 0$}
\solution{да, так как все эти множества представимы в виде счетного объединения точек, отрезков или интервалов.}



\subsection{Еще задачи}

\problem{За час до Нового года Дед Мороз дарит Вовочке одну конфету. За полчаса он забирает ее, съедает сам и дарит две другие конфеты. За четверть часа, забирает их, съедает и дарит четыре конфеты. И так далее. Пусть $A_{i}$ - это номера тех конфет которые находятся в распоряжении Вовочки после $i$-го действия Деда Мороза. Например, $A_{1}=\{1\}$, $A_{2}=\{2,3\}$, $A_{3}=\{4,5,6,7\}$ и так далее.

Существует ли $\lim A_{i}$? Если да, то чему он равен?}
\solution{$\lim A_{i}=\emptyset$}


\problem{Пусть $N$ - произвольная функция сопоставляющая каждому исходу число или плюс-минус бесконечность, $N:\Omega\to \R\cup \{-\infty,\infty\}$. Можно думать об $N$ как о случайной величине. Найдите $\lim_{k\to+\infty}(N<k)$}

\solution{$N<+\infty$}


\problem{Игральный кубик подбрасывается один раз. В первый момент времени
наблюдатель узнает, выпала ли четная грань или нет. Во второй
момент времени наблюдатель узнает, выпала ли грань большая двух
или нет. В третий момент времени наблюдатель точно узнает, какая
грань выпала. Укажите множество элементарных событий и
соответствующие три \s-алгебры событий. }
\solution{$\Omega=\{1,2,3,4,5,6\}...$}






\section{Случайные величины} \problemtext{

Сумма чисел на противоположных сторонах игральной кости всегда равна семи.\par


Обратите внимание, что мы начинаем главу про случайные величины перед главой про вероятность! Без последующего определения вероятности случайные величины окажутся бесполезны, но важно понимать, что понятие случайной величины не требует для себя наличия вероятности. Например, вероятность можно поменять, сохранив случайную величину, при этом, конечно, все интересные количества как то $\P(X<0)$, $\E(X)$ могут измениться.

}\subsection{Определение случайной величины}\problemtext{

\begin{mydef}
Случайная величина $X$ - это функция, сопоставляющая каждому исходу случайного эксперимента некое действительное число, $ X:\Omega\to\R $.
\end{mydef}



Если рациональному наблюдателю известно значение $ X $, то он может определить, произошли ли например события $X<0$, $X\in [2;3]$, $X=\sqrt{3}$ и др. Таким образом, с каждой случайной величиной $ X $ связана сигма-алгебра $ \sigma(X) $ событий гарантированно различимых наблюдателем, знающим значение $X$. Доведем эту идею до формального определения. Что означает, что я знаю $ X $? Это означает, что я могу сравнить $ X $ с любым действительным числом, т.е. для любого заданного $ t $ могу сказать произошло ли событие вида $ \{X<t\} $. Получаем определение:

\begin{mydef}
Сигма-алгеброй порожденной случайной величиной $ X $, $ \sigma(X) $, называется минимальная сигма-алгебра, содержащая все события вида $ \{X<t\} $, т.е. $ \sigma(X):=\sigma(\{X<t|t\in \mathbb{R}\}) $.
\end{mydef}

Как мы видели (...) с помощью подмножеств вида $ (-\infty;t) $ можно породить нашу любимую борелевскую сигма-алгебру, а значит определение можно переформулировать и так:

\begin{mydef}
Сигма-алгеброй порожденной случайной величиной $ X $, $ \sigma(X) $, называется минимальная сигма-алгебра, содержащая все события вида $ \{X\in A\} $, где $ A $ --- борелевское подмножество $ \mathbb{R} $, т.е. $ \sigma(X):=\sigma(\{X\in A|A\in \mathcal{B}(\mathbb{R})\}) $.
\end{mydef}

Тут упражнение ...

Для понимания структуры $ \sigma(X) $ полезным может оказаться понятие прообраза:

\begin{mydef} Если задана функция $X:\Omega \to \R$, то \indef{прообразом} (pullback) множества $A$ называется множество $\{w\in\Omega|X(w)\in A\}$, обозначается прообраз $X^{-1}(A)$.
\end{mydef}

\begin{myex} Функция $f(t)=t^{2}$. Примеры прообразов: $f^{-1}(5)=\{\sqrt{5},-\sqrt{5}\}$, $f^{-1}(0)=\{0\}$, $f^{-1}(-1)=\emptyset$.
\end{myex}

Используя понятие прообраза можно понять, что $ \sigma(X) $ состоит ровно из прообразов всех борелевских множеств. Действительно, прообразы борелевских множеств обязаны входить в $ \sigma(X) $ исходя из определения (...). А никакое лишнее множество нам не нужно, т.к.

\begin{myth} Пусть задана случайная величина $X$. Набор прообразов всех борелевских множеств $\{X^{-1}(B)|B\in\B\}$ является \s-алгеброй.
\end{myth}
\begin{proof} Проверяем три свойства \s-алгебры.
\begin{itemize}
\item $ \Omega=X^{-1}((-\infty;+\infty)) $
\item Если $ A=X^{-1}(B) $, то $ A^{c}=X^{-1}(B^{c}) $
\item
\end{itemize}


\end{proof}






Если рациональный индивид помимо событий из $ \sigma(X) $ различает какие-то еще события, то он конечно же, также может определить значение случайной величины $ X $. Для описания такой ситуации служит:

\begin{mydef} Случайная величина $X:\Omega\rightarrow\R$ называется \indef{измеримой} относительно $ \sigma $- алгебры $\F$, если $ \sigma(X)\subseteq \mathcal{F} $.
%для любого борелевского множества $B$ событие $X\in B$ лежит в $\sigma$-алгебре $\F$.
\end{mydef}

\begin{myex} Рассмотрим $\Omega$, состоящее из 3-х элементов, $\sigma$-алгебру $\F=\{\emptyset,\Omega,a,\{b,c\}\}$ и случайные величины $X$ и $Y$:
(...)

В данном случае $X$ является $\F$ - измеримой случайной величиной, а $Y$ - не является $\F$-измеримой.
\end{myex}


Иногда символом $\mathcal{F}$ обозначают не только саму $\sigma$-алгебру, но и множество всех случайных величин,
являющихся $\mathcal{F}$-измеримыми. Это дает право использовать короткое обозначение $X \in \mathcal{F}$, означающее, что
случайная величина $X$ является $\mathcal{F}$-измеримой величиной. Буква $\F$ оказывается слегка перегруженной, но проблем при этом не возникает. Если $A$ - событие, то $A\in \F$ следует понимать буквально: <<множество $A$ входит в список $\F$>>. Если $X$ - случайная величина, то $X\in \F$ следует понимать как <<$X$ является $\F$-измеримой случайной величиной>>. В конце концов - букв мало, а событий и случайных величин - много!

\begin{myth} Любая случайная величина $X:\Omega\rightarrow \R$ является измеримой относительно самой <<подробной>> $\sigma$-алгебры $2^\Omega$ (все подмножества множества $\Omega$).
\end{myth}

\begin{proof} Самая <<подробная>> \s-алгебра содержит все подмножества множества $\Omega$ и, в частности, содержит сигма-алгебру $ \sigma(X) $, куда входят все прообразы борелевских множеств.
\end{proof}

Пусть $X:\Omega\to\mathbb{R}$, на $\Omega$ задана \s-алгебра \F, а на \R - борелевская \s-алгебра \B. Оказывается, даже если $X$ не является \F-измеримой ...


Множества, у которых <<хороший>> прообраз (прообраз попадает в \F) образуют \s-алгебру (не обязательно совпадающую с борелевской).
\begin{myth} Пусть задана случайная величина $X$. Набор числовых подмножеств с прообразом, попадающим в \F, $\mathcal{D}:=\{D|X^{-1}(D)\in\F\}$ является \s-алгеброй.
\end{myth}
\begin{proof} Проверяем три свойства \s-алгебры.
1) $X^{-1}(\R)=\Omega$, значит $\R\in\mathcal{D}$

2) $X^{-1}(D^{c})=(X^{-1}(D))^{c}$, значит имеем цепочку $D\in\mathcal{D}\Rightarrow X^{-1}(D)\in\F \Rightarrow (X^{-1}(D))^{c}\in\F \Rightarrow X^{-1}(D^{c})\in\F \Rightarrow D^{c}\in\F$.

3) Аналогично б. в силу того, что прообраз объединения равен объединению прообразов.

\end{proof}








Говоря доступным языком, $\s(X)$ - это список событий, про которые мы сможем гарантированно сказать, произошли они или нет, если мы знаем значение $X$. Кроме того, если мы различаем события из $\s(X)$, то мы можем определить значение $X$.


Борелевская \s-алгебра - довольно сложный объект, мы даже не можем явно перечислить все входящие в нее множества. Как же на практике проверить, является ли данная случайная величина $X$ измеримой относительно данной \s-алгебры $\F$?

Оказывается вместо проверки всех борелевских множеств достаточно проверить только некоторые. А именно, достаточно убедиться, что...

\begin{myth}
Пусть $\mathcal{H}$ - произвольный набор подмножеств $\R$ порождающий борелевскую \s-алгебру $\mathcal{B}$, $\s(\mathcal{H})=\B$. Случайная величина $X$ измерима относительно \s-алгебры $\F$ если и только если для любого $H\in\mathcal{H}$ событие $\{X\in H\}\in\F$.
\end{myth}
\begin{proof}

туда:

Пусть $X$ измерима относительно $\F$. Значит прообразы всех борелевских множеств лежат в $\F$.  так как $\mathcal{H}\subset \B$, то и прообразы всех множеств из $\mathcal{H}$ лежат в $\F$.

обратно:

Мы доказывали, что $\mathcal{D}:=\{D|X^{-1}(D)\in\F\}$ - \s-алгебра.

Мы знаем, что $\mathcal{H}\subset\mathcal{D}$, $\mathcal{D}$ - \s-алгебра и $\s(\mathcal{H})=\B$. Значит $\B\subset\mathcal{D}$
\end{proof}


Пример..


Хорошая новость: \F-измеримые случайные величины можно складывать, вычитать, умножать и делить!

\begin{myth} Если $X$, $Y$ - \F-измеримые случайные величины, то: $X+Y$, $X-Y$, $X\cdot Y$ - \F-измеримые случайные величины. Если выполнено дополнительное условие $Y\neq 0$, то и $\frac{X}{Y}$ - \F-измеримая случайная величина.
\end{myth}
\begin{proof} Мы рассмотрим только случай $X+Y$, т.к. при доказательстве остальных трех случаев используется та же идея.
(...)
\end{proof}


Кроме того, можно брать смело брать пределы!

\begin{myth} Если $X_{i}$ - последовательность \F-измеримых случайных величин, то:

a) Множество $A=\{w|\exists \lim X_{i}(w)\}\in\F$.

b) Если для $\forall w\in\Omega$ существует предел $\lim X_{n}(w)$, то случайная величина $\lim X_{n}$ является \F-измеримой.
\end{myth}
\begin{proof}
\end{proof}

Если преобразовать \F-измеримую случайную величину с помощью <<хорошего>> преобразования, то снова получится \F-измеримая случайная величина.
Сначала уточним, что значит <<хорошее>> преобразование:

\begin{mydef} Функция $f:\R\to\R$ называется \indef{борелевской} если прообраз любого борелевского множества является борелевским множеством ($f^{-1}(B)\in\B$ для $\forall B\in \B$).
\end{mydef}
\begin{myex} $f(t)=t^{2}$, $f(t)=\cos(t)$, $f(t)=|t|$ - борелевские функции.
\end{myex}

Более того, все <<привычные>> функции - борелевские, о чем говорит следующая теорема:

\begin{myth} Если $f$ имеет счетное число разрывов, то она - борелевская (...проверить)
\end{myth}
(...) Используя пример неборелевского множества, постройте пример неборелевской функции (упр.)

Итак, если использовать <<хорошее>> преобразование, то \F-измеримость сохраняется:

\begin{myth} Если $X:\Omega\to\R$ - \F-измеримая случайная величина, и $f:\R\to\R$ - борелевская функция, то $f(X):\Omega\to\R$ - \F-измеримая случайная величина.
\end{myth}
\begin{proof}
\end{proof}
В случае, когда $\F=\s(X)$ эту теорему можно уточнить:

\begin{myth} Случайная величина $Y$ является $\s(X)$-измеримой если и только если $Y=f(X)$, где $f$ - борелевская функция.
\end{myth}
Туда. $X$ является $\s(X)$-измеримой. Поэтому согласно (...) если $f$ - борелевская функция, то $f(X)$ является $\s(X)$-измеримой.

Обратно.  Интуитивно: если зная $X$ можно определить, чему равно $Y$, то $Y$ - это функция от $X$. Строго:



}\subsection{Сигма-алгебры и случайные величины} \problemtext{

На самом деле большинство $ \sigma $-алгебр связано со случайными величинами. Для иллюстрации приведем три примера:

\begin{itemize}
\item Сигма-алгебра, порожденная случайной величиной, $ \sigma(X) $.
\item Сигма-алгебра, связанная с моментом остановки $ T $, $\mathcal{F}_{T}$.
\item Остаточная (хвостовая) сигма-алгебра.
\end{itemize}

...


}\subsection{Обобщение случайных величин} \problemtext{

Можно обобщать определение случайное величины по-разному. В любом случае у нас будет следующая картина. Функция $X:\Omega\to S$, где $S$ - некое (не обязательно числовое) множество. Есть две \s-алгебры: \F, заданная на $\Omega$ и $\mathcal{H}$, заданная на $S$. Чаще всего на $S$ определено понятие открытого множества и $\mathcal{H}$ является борелевской \s-алгеброй, т.е. минимальной \s-алгеброй, содержащей все открытые множества.


(....)

Самые популярные обобщения такие:

\begin{itemize}

\item Векторные случайные величины.

В $\R^{n}$ есть понятие открытого множества. Поэтому есть и понятие борелевской \s-алгебры в $\R^{n}$, т.е. минимальной \s-алгебры, содержащей все открытые множества. Впрочем, принципиально ничего нового не возникает:

\begin{myth}
Вектор $(X_{1},X_{2},..., X_{n})$ измерим относительно \s-алгебры $\F$ если и только если каждая случайная величина $X_{i}$ измерима относительно \s-алгебры $\F$.
\end{myth}

Хотя <<чудеса, леший бродит и русалка на ветвях>> сидит даже в $\R^{2}$:
\begin{myth}
Существует измеримое по Лебегу множество в $\R^{2}$, такое, что его проекция на любую координату является неизмеримым в $\R$.
\end{myth}

\begin{proof}
Пример можно найти... строится он примерно так...
\end{proof}

\item Добавление бесконечностей.

Иногда случайная величина может принимать значение плюс или минус бесконечность. Например, время первого выпадения орла при подбрасывании монетки может никогда не наступить и тогда удобно говорить, что оно равно плюс бесконечности. Порою может понадобится и минус бесконечность.

Как выглядят определения в этом случаем? Вместо старого множества значений $\mathbb{R}$ будет множество $S=\{-\infty\}\cup \mathbb{R}\cup\{+\infty\}$. В качестве \s-алгебры $\mathcal{H}$ будем использовать борелевскую \s-алгебру. Она порождается множествами вида $[-\infty;a]$, где $a\in S$. Например, $[-\infty;0)$ открыто, $(-\infty;0)$ открыто, $\{-\infty\}$ замкнуто.


\item Комплексные случайные величины, $X:\Omega\to\mathbb{C}$.

В силу того, что комплексная плоскость $\mathbb{C}$ может быть естественным образом сопоставлена с плоскостью $\R^{2}$, то на $\mathbb{C}$ есть понятие открытых множеств. Вместо одной комплексной случайной величины можно рассматривать вектор из двух действительных случайных величин. Первая компонента вектора отвечает за действительную часть, вторая - за мнимую. Понятие измеримости для комплексной случайной величины совпадает с измеримостью для вектора.

\item Случайные процессы. Об этом позже, в главе \ref{process_one_rv}.

\end{itemize}

}\subsection{Еще задачи}




\section{Вероятность} \problemtext{

}\subsection{Определение вероятности}  \problemtext{

Вероятность - это размер событий! А именно:

\begin{mydef} Пусть $\mathcal{F}$ - $\sigma$-алгебра. Функция $\mu:\mathcal{F} \rightarrow [0;+\infty]$ называется \indef{мерой}, если выполнены два условия:

M1. $\mu(\emptyset)=0$

M2. Если все $A_{i}\in \mathcal{F}$ и они попарно не пересекаются ($A_{i}\cap A_{j}=\emptyset$ при $i\neq j$), то $\mu\left(\cup_{i=1}^{\infty} A_{i}\right)=\sum_{i=1}^{\infty}\mu(A_{i})$
\end{mydef}
Обратить внимание следует на то, что мера может принимать бесконечные значения, при этом они складываются по естественным правилам: $\infty+$(любое число)$=\infty$, $\infty+\infty=\infty$.

\begin{myex} Например, $\Omega=\mathbb{R}$, $\mathcal{F}=2^{\mathbb{R}}$, и $\mu(A)$ - количество элементов в множестве $A$. Легко проверить, что это мера, которая может принимать бесконечные значения.
\end{myex}

\begin{myex} Например, $\Omega=\mathbb{R}$, $\mathcal{F}=2^{\mathbb{R}}$, и мера $\mu(A)$ - равна единице, если множество $A$ содержит $\sqrt{3}$, и равна нулю, если $A$ не содержит $\sqrt{3}$.
\end{myex}

\begin{myex} $\Omega=\mathbb{R}$, $\mathcal{F}=2^{\mathbb{R}}$. Функция $\mu(A)=\sup(A)$ - не является мерой, т.к. $\mu([0;1])\neq \mu([0;0.5))+\mu([0.5;1])$.
\end{myex}

\begin{myex} Длина. Если $\Omega=\R$, то на борелевской \s-алгебре \B можно определить меру $\lambda$ которая будет соответствовать естественному понятию длины. Например, $\lambda([0;100])=100$. К сожалению (?), эту меру нельзя определить на \s-алгебре $2^{\R}$. Этот пример содержит в себе сразу два недоказанных утверждения.  Во-первых, на \B можно определить такую меру, там не возникнет проблем с аксиомой М2. Во-вторых, не получится определить на $2^{\R}$ меру, которая соответствует естественному понятию длины. Доказательство чуть позже.
\end{myex}

\begin{mydef} Мера $P$ называется \indef{вероятностью} если $\P(\Omega)=1$.
\end{mydef}

\begin{myex} (простенький пример с конечным омега)
\end{myex}


В данном курсе мы будем иметь дело с вероятностью, которая является конечной мерой и с длиной подмножеств $\R$, которая является \s-конечной мерой.

\begin{mydef} Мера $\mu$ называется конечной, если $\mu(\Omega)<\infty$
\end{mydef}
\begin{mydef} Мера $\mu$ называется \s-конечной, если $\Omega$ можно разбить на счетное количество непересекающихся $\Omega_{i}$, так что на каждом $\Omega_{i}$ мера $\mu$ будет конечной: $\Omega=\cup \Omega_{i}$, $\mu(\Omega_{i})<\infty$.
\end{mydef}
Длина является \s-конечной в силу того, что числовую прямую можно разбить на счетное количество полуинтервалов единичной длины вида $[n;n+1)$.


}
\subsubsection*{Задачи}

\problem{Пусть $\mu_{1}$ и $\mu_{2}$ - конечные меры на $\Omega$ и $a>0$. Верно ли, что:

а) $\mu:=a\mu_{1}$ - конечная мера? б) $\mu:=\mu_{1}+\mu_{2}$ - конечная мера? }
\solution{а) да, б) да}

\problem{Пусть $\mu$ - конечная мера на $\Omega$. Верно ли, что $\nu(A):=\frac{\mu(A)}{\mu(\Omega)}$ - вероятность на $\Omega$}
\solution{да, если $\mu(\Omega)>0$}

\problem{Приведите пример $ \sigma $-алгебры $ \mathcal{F} $ и функции $ R:\mathcal{F}\to [0;1] $ такой, что:
\begin{enumerate}
\item $ R(\Omega)=1 $, $ R(\emptyset)=0 $
\item Если $ A\in \F $, $B\in \F  $ и $ A\cap B=\emptyset $, то $ R(A\cup B)=R(A)+R(B) $
\item Существует возрастающая последовательность $ A_{1}\subset A_{2}\subset A_{3}\subset \ldots $ такая, что $ R(\cup A_{n})\neq \lim R(A_{n}) $
\end{enumerate}}
\solution{ Пусть $ \Omega=[0;1]\cap \mathbb{Q} $, $ \mathcal{F} $ --- это все конечные множества и множества с конечными дополнениями.  Функция $ R $ равна 0 для конечных множеств и единице для множеств с конечным дополнением. Занумеруем все рациональные числа на $ [0;1] $: $ r_{i} $ --- $ i $-ое по счету рациональное число. Возьмем $ A_{n}=\{r_{1},r_{2},...,r_{n}\} $. Тогда $ R(A_{n})=0 $ т.к. $ A_{n} $ конечно, но $ \cup A_{n}=\Omega $ и $ R(\Omega)=1 $.}


\subsection{Свойства вероятности} \problemtext{

Нам часто понадобятся следующие свойства:

\begin{myth} Если $P$ - вероятность, то:

PP1. $\P(\cup A_{i})\leq \sum \P(A_{i})$.

PP2. Если $\P(A_{i})=0$, то $\P(\cup A_{i})=0$.

PP3. Если $\P(A_{i})=1$, то $\P(\cap A_{i})=1$.

PP4. Вероятность выдерживает взятие пределов:

PP4a. Если $A_{1}\subset A_{2}\subset A_{3} ...$, то $\P(\cup A_{i})=\lim \P(A_{i})$

PP4b. Если $A_{1}\supset A_{2}\supset A_{3} ...$, то $\P(\cap A_{i})=\lim \P(A_{i})$

PP4с. Если $lim A_{i}$ существует, то $\P(\lim A_{i})=\lim \P(A_{i})$
\end{myth}
\begin{proof}

PP1: Воспользуемся следующим трюком, от последовательности $A_{n}$ перейдем к последовательности <<добавок>> $A_{n}'$. То есть $A_{n}'$ - это те новые элементы, которые приносит с собой $A_{n}$, которых еще нет в $\cup_{i}^{n-1}A_{i}$. Формально, $A_{i}'=A_{i}\backslash(\cup_{i}^{n-1}A_{i})$. В силе этого $A_{n}'$ попарно не пересекаются.

Остается заметить, что $\P(A_{n}')\leq \P(A_{n})$ и $\P(\cup A_{n})=\P(\cup A_{n}')=\sum \P(A_{n}')\leq \sum \P(A_{n})$.

PP2: Следует из PP1.

PP3: Перейдем к дополнениям, $B_{n}=A_{n}^{c}$. Тогда $\P(B_{n})=0$ и к ним применимо свойство PP2, $\P(\cup B_{n})=0$ и $\P((\cup B_{n})^{c})=1$. Но это как раз и есть желаемое: $(\cup B_{n})^{c}=(\cup A_{n}^{c})^{c}=\cap A_{n}$.
\end{proof}


Еще несколько <<именных>> свойств, связанных с множеством $\limsup A_{i}$ (<<произошло бесконечное количество $A_{i}$>>):

Лемма Фату для вероятностей: если есть бесконечно много $A_{i}$ с вероятностью не ниже $p$, то вероятность того, что произойдет бесконечное количество $A_{i}$ не ниже $p$.

\begin{myth} $\P(\limsup A_{i})\geq \limsup \P(A_{i})$.
\end{myth}
\begin{proof} Шаг 1. Среди $A_{i}$ выбираем подпоследовательность $B_{k}$ такую, что $\lim \P(B_{k})=\limsup \P(A_{i})$. Заметим, что $\limsup B_{i}\subset\limsup A_{i}$ (если произошло бесконечное количество $B_{i}$, то произошло бесконечное количество $A_{i}$, но обратное в общем случае неверно), $\P(\limsup A_{i})\geq \P(\limsup B_{i})$.

Шаг 2. $\P(\limsup B_{i})=\P(\cap_{n=1}^{\infty}\cup_{k\geq n} B_{k})=\lim_{n\to\infty} \P(\cup_{k\geq n} B_{k})\geq \lim_{n\to\infty} \P(B_{n})$.
\end{proof}
Первая лемма Бореля-Кантелли: если сумма вероятностей $A_{i}$ не <<велика>>, то вероятность того, что произойдет бесконечное количество $A_{i}$ равна нулю. Если быть точным, <<не велика>> в данном случае - меньше бесконечности:

\begin{myth} Если $\sum \P(A_{i})<\infty$, то $\P(\limsup A_{i})=0$.
\end{myth}
\begin{proof} Шаг 1. $\P(\limsup A_{i})=\P(\cap_{n=1}^{\infty}\cup_{k\geq n} A_{k})=\lim_{n\to\infty} \P(\cup_{k\geq n} A_{k})\leq \lim_{n\to\infty}\sum_{k\geq n} \P(A_{k})$.

Шаг 2. Частичные суммы $\sum_{i=1}^{n}\P(A_{i})$ сходятся к сумме $\sum_{i=1}^{\infty}\P(A_{i})<\infty$, а это значит, что непосчитанный <<хвост>> стремится к нулю, $\lim_{n\to\infty}\sum_{k\geq n} \P(A_{k})=0$.
\end{proof}

}\subsection{Построение равномерной вероятности} \problemtext{

Оказывается, что некоторые интересные вероятности нельзя определить для произвольного подмножества числовой прямой!!!

Очень важный пример!

\subsubsection*{У некоторых множеств на прямой нет длины!}

\begin{myex} Допустим мы хотим создать равномерное распределение на интервале $[0;1)$. Казалось бы, чего проще! Берем в качестве $\F$ все подмножества данного полуинтервала и в качестве вероятности попасть в данное подмножество берем его длину! Однако это не получится! Обязательно будет нарушена аксиома М2 в определении меры.
\end{myex}

Давайте разберемся. Чего мы ждем от равномерного распределения? Если взять произвольное подмножество $A$ и его копию $A'$ сдвинутую, скажем чуть правее, то мы хотим, чтобы $\P(A)=\P(A')$. И все. Больше на ничего от равномерной вероятности ничего не нужно.

Для краткости будем использовать следующее обозначение:

\begin{mydef} $A\oplus r$ - это множество $A$ сдвинутое вправо на $r$. Если при этом результат вылезает за пределы интервала $[0;1)$, то мы выступающую часть <<внесем>> обратно в $[0;1)$ с другой стороны. Например: $[0;0,5]\oplus 0,1=[0,1;0,6]$, $(0,5;0,8)\oplus 0,3=(0,8;1)\cup [0;0,1)$.
\end{mydef}

А сейчас мы построим довольно <<хитрое>> множество $A$. Для этого мы раскрасим весь интервал $[0;1)$ в разные цвета по следующему принципу:

Числа $x\in[0;1)$ и $y\in[0;1)$ красим в один цвет, если существует рациональное число $r\in\mathbb{Q}$, такое что $x\oplus r=y$.

Из этого принципа следует, что если взять любое число $x$, то есть счетное количество покрашенных в тот же цвет чисел. Так, например, есть счетное количество чисел покрашенных в тот же цвет, что и $\sqrt{2}/2$. Заметим, что все рациональные числа покрашены в тот же цвет, что и число $0$.

%Весь интервал $[0;1)$ оказывается разбит на группы похожих между собой чисел.

Множество $A$ создадим так: возьмем по одному числу каждого цвета. Например, от рациональных можно взять ноль, от покрашенных в тот же цвет, что и $\sqrt{2}/2$ можно взять $\sqrt{2}/2+0,1$ и т.д. Неважно какого представителя мы берем, главное от каждого цвета ровно по одному.

Что у нас получилось? Если взять рациональное $r\in[0;1)$, то $A\oplus r$ не совпадает с $A$, т.к. каждый представитель своего цвета превратится в другое число своего цвета. Если взять два разных рациональных числа $r_{1}\in [0;1)$, $r_{2}\in[0;1)$, то $A\oplus r_{1}$ не пересекается с $A\oplus r_{2}$: в каждой группе представитель переходит в разных членов своей группы. Если перебрать все рациональные числа, то $\cup_{r\in\mathbb{Q}\cap [0;1)} (A\oplus r)=[0;1)$, в каждой группе представитель успеет побывать в роли каждого члена своей группы.

Здесь и рождается противоречие! Напомню, что мы хотим, чтобы $\P(A)=\P(A\oplus r)$:

С одной стороны,  $\P(\cup_{r\in\mathbb{Q}\cap [0;1)} (A\oplus r))=\P([0;1))=1$

С другой стороны, $\P(\cup_{r\in\mathbb{Q}\cap [0;1)} (A\oplus r))=\sum_{r\in\mathbb{Q}\cap [0;1)} \P(A\oplus r)=\sum_{r\in\mathbb{Q}\cap [0;1)} \P(A)$.

Но сумма бесконечного количества одинаковых слагаемых не может равняться единице! Либо нулю, если складываются нули, либо бесконечности, если складываются ненулевые числа.

Этот пример показал, что равномерную вероятность нельзя построить для произвольных подмножеств отрезка $[0;1)$. Поскольку от понятия длины мы ждем ровно той же неизменности при сдвиге вправо-влево на прямой, становится ясно, что нельзя присвоить понятие длины произвольному подмножеству \R.

Что же делать? Нужно отказаться от определения вероятности на этом <<страшном>> множестве $A$! Т.е. для некоторых множеств вероятность определена и является числом от нуля до единицы и подчиняется свойствами M1, M2, а для некоторых подмножеств вероятность просто не существует. В данном случае $\P(A\oplus r)$ и $\P(A)$ не будут существовать и противоречия не возникнет.

Возникает естественный вопрос: каким же подмножествам интервала $[0;1)$ можно присвоить вероятность, которая не менялась бы при сдвиге? Или каким подмножествам прямой можно присвоить понятие длины?

\subsubsection*{Длина есть у всех борелевских множеств!}

Нас спасет уже знакомая нам борелевская $\sigma$-алгебра $\mathcal{B}([0;1])$! На ней можно определить равномерную вероятность. А как мы видели эта $\sigma$-алгебра достаточно богата и включает все подмножества отрезка $[0;1]$ с которыми реально приходится работать.

Борелевских множеств много и они могут иметь достаточно сложную структуру, поэтому попытка явно определить <<длину>> каждого борелевского множества обречена на провал. Мы поступим следующим путем. Определим понятие <<длины>> на очень простом наборе множеств. Этот набор множеств будет порождать борелевскую \s-алгебру. И сформулируем теорему, которая будет гарантировать, что у каждого борелевского множества есть длина.

Итак, наш <<простой>> набор множеств это полуинтервалы вида $[a;b)$:

$\mathcal{H}=\{[a;b)|0\leq a<b<1\}$.

Он, конечно, \s-алгеброй на $\Omega=[0;1)$ не является: $[0.1;0.2)\in \mathcal{H}$, но $[0.1;0.2)^{c}\notin\mathcal{H}$. Зато на нем тривиально определить длину:
\begin{equation}
\lambda([a;b)):=b-a
\end{equation}

Кроме того, этот набор порождает борелевскую \s-алгебру, т.е. $\s(\mathcal{H})=\B ([0;1))$.

Формально наш набор $\mathcal{H}$ является полу-алгеброй:

\begin{mydef}

\end{mydef}

Спасительная теорема формулируется так:

\begin{myth}[Каратеодори]
Если функция $\mu$ задана на полу-алгебре $\mathcal{H}$ и на ней является \s-аддитивной (), то существует единственная мера $\mu{*}$, заданная на \s-алгебре $\s(\mathcal{H})$, совпадающая с $\mu$ на множестве $\mathcal{H}$.
\end{myth}

\begin{proof} Идея проста. Для каждого подмножества $\Omega$ определим <<внешнюю меру>> $\mu^{*}$... Эта <<внешняя мера>> $\mu^{*}$ не всегда будет \s-аддитивна, т.е. она не является мерой! Но если выбрать <<хорошие>> подмножества $\Omega$, а именно такие, на которых $\mu^{*}$ будет мерой, то они будут образовывать \s-алгебру! Единственность будет следовать из того, что каждое <<хорошее>> множество можно <<приблизить>> с помощью объединения множеств из $\mathcal{H}$, а на них любая другая мера должна совпадать с $\mu^{*}$. Полное доказательство в приложении.
\end{proof}
Заметим, что конкретно в нашем случае \s-алгебра <<хороших>> окажется строго больше $\B([0;1))=\s(\mathcal{H})$. Длина будет определена не только у борелевских множеств, но и у некоторых других. Это не страшно, и подробнее об этом чуть позже.


\begin{myex}
\url{http://math.stackexchange.com/questions/2949/which-one-result-in-maths-has-surprised-you-the-most/2953}
Пример, как можно каждое рациональное число накрыть маленьким интервальчиком и в результате длина всего множества будет конечная..
\end{myex}




\subsubsection*{Как построить любой случайный эксперимент?}

Почему так важно было установить существование равномерной вероятности? Оказывается, что имея одну равномерную случайную величину можно получить бесконечное количество независимых равномерных случайных величин! А имея бесконечно много равномерных случайных величин можно такого понастроить...

Пусть $X$ - равномерно распределенная случайная величина на $[0;1)$. Мы хотим на базе одной $X$ построить последовательность независимых равномерных $X_{1}$, $X_{2}$, $X_{3}$...

Нам окажется полезной такая неслучайная последовательность натуральных чисел:
\begin{equation}
[a_{i}]=[1,1,2,1,2,3,1,2,3,4,1,2,3,4,5,1,2,3,4,5,6...]
\end{equation}
Сначала сказали 1, потом посчитали от 1 до 2, потом от 1 до 3, потом от 1 до 4 и т.д. Эта последовательность нам будет говорить какому $X_{i}$ <<отдать>> очередную цифру из десятичной записи $X$.

Например, пусть $X(w)=0,583601935...$. Первую цифру после запятой отдаем $X_{1}$, вторую - снова $X_{1}$, третью - $X_{2}$, четвертую - снова $X_{1}$, пятую - $X_{2}$, шестую - $X_{3}$... Получаем:

$X_{1}=0,5869...$

$X_{2}=0,303...$

$X_{3}=0,15...$

Изобразим на картинке:
\begin{align*}
X(w) &=0,583601935...\\
a_{i} &=\phantom{0,}1121331234...\\
X_{1}&=0,58\phantom{0}6\phantom{0}9...\\
X_{2}&=0,\phantom{00}3\phantom{0}0\phantom{00}3...\\
X_{3}&=0,\phantom{00000}1\phantom{00}5...\\
\end{align*}



В последовательность $a_{i}$ каждое натуральное число $k$ упомянуто бесконечное количество раз. Значит каждая случайная величина  $X_{k}$ получит от $X$ бесконечное количество цифр. Разные цифры в десятичном разложении величины $X$ независимы, отсюда будет следовать независимость $X_{k}$. Каждая цифра в десятичном разложении $X$ равновероятно принимает значения от $0$ до $9$, значит и каждая цифра в десятичном разложении каждого $X_{k}$ также равновероятно принимает значения от $0$ до $9$. Следовательно, все $X_{k}$ равномерны на $[0;1)$.

Имея последовательность независимых равномерных $X_{k}$ можно получить независимую последовательность $Y_{k}$ с произвольным законом распределения. А в главе про броуновское движение мы узнаем, как из последовательности нормальных случайных величин сварить это самое броуновское движение.

Упр. докажите, что если $X$ -равномерное, то $...$ - экспоненциальное, а $...$ - пуассон.





}\subsection{Почти наверное и пополнение вероятностного пространства!} \problemtext{




неборелевское - не лежит в $\mathcal{B}$.
неизмеримое (или, точнее, не измеримое по Лебегу, не лебеговоское) - не лежит в пополнении $\mathcal{B}$.



}\subsection{Еще задачи}

\problem{Можно ли придумать последовательность $\sigma$-алгебр $\mathcal{F}_{1}$, $\mathcal{F}_{2}$, $\mathcal{F}_{3}$, ..., такую, что одновременно выполнены два условия: 1) для любого $i$: $\mathcal{F}_{i}\subset \mathcal{F}_{i+1}$; 2) $\cup \mathcal{F}_{i}$ - не $\sigma$-алгебра.}
\solution{да}



\section{Зоопарк!} \problemtext{
\subsection{Канторово множество - дикое но симпатичное}
Пример достаточно <<сложного>> борелевского множества - Канторово множество\index{Канторово множество}. Строится оно следующим образом...

Для начала возьмем отрезок $C_{0}=[0;1]$:

(...) рисунок

Затем вырежем из него середину, получим $C_{1}=[0;1/3]\cup [2/3;1]$.

(...) рисунок

Затем из каждого отрезка вырежем его середину, получим $C_{2}=[0;1/9]\cup[2/9;3/9]\cup[6/9;7/9]\cup [8/9;1]$.

(...) рисунок

Продолжая процесс вырезания середины каждого отрезка бесконечно долго мы получим последовательность вложенных множеств $C_{0}\supset C_{1}\supset C_{2}\supset C_{3}\supset ...$.

\begin{mydef} \indef{Канторово множество} - $C=\cap_{i=1}{\infty}C_{i}$.
\end{mydef}
Может показаться, что кроме концов отрезков там ничего не остается, однако это не так.

\begin{myex} (проверить) точка $1/4$ не является концом отрезка, но лежит в каждом $C_{i}$, а следовательно, лежит в $C$.
\end{myex}

Каждое $C_{i}$ лежит в борелевской \s-алгебре, а значит и их счетное пересечение, Канторово множество лежит в борелевской \s-алгебре. Раз Канторово множество является борелевским, значит у него есть длина (согласно (...) на борелевских множествах можно определить классическое понятие длины). Суммарная длина выкинутых отрезков равна единице: $1/3+2/9+4/27+...=\frac{1/3}{1-2/3}=1$. Значит Канторово множество имеет длину 0.

Несмотря на свою нулевую длину Канторово множество несчетно! точнее говоря, имеет мощность континуум. Существует взаимно однозначное соответствие между множеством бесконечных вправо последовательностей из 0 и 1 и точками Канторова множества. Берем произвольную точку в Канторовом множестве: в $I_{1}$ она попадает либо в правый отрезок, либо в левый (0 или 1); в рамках выбранного отрезка, в $I_{2}$ она попадает либо в правый отрезок, либо в левый (0 или 1) и т.д. И наоборот, если задана последовательность из 0 и 1, то ее можно переделать в последовательность <<вправо>>-<<влево>>, а каждой такой последовательности сопоставить единственную точку. На \R любая последовательность Коши имеет предел, поэтому получается взаимнооднозначное соответствие.



Внутри него можно найти неборелевское! Существование неборелевского множества внутри Канторова можно установить путем разных рассуждений. Например, неконструктивно: подмножеств Канторова множества больше, чем континуум, а борелевских (...) (ссылка еще раз) - континуум. А можно построить в явном виде, что мы сделаем с помощью Канторовой лестницы (...).


Оно совершенно. Каждая точка является пределом последовательности из него.

Оно нигде не плотно.

\begin{mydef} Подмножество $A\subset \R$ называется \indef{нигде не плотным}, если (...)
\end{mydef}



Почему оно так важно?

Во-первых, оно чудесным образом сочетает характеристики, которые на первый взгляд кажутся противоречивыми (несчетность и нулевую длину, несчетность и нигде не плотность). <<Чудо>>, коротко говоря.

Во-вторых, характеристики Канторова множества типичны для множества нулей броуновского движения. Если взять типичную (выпадающую с вероятностью 1) траекторию броуновского движения, и посмотреть, где она пересекает горизонтальную ось, то это множество нулей будет несчетным, нулевой длины, нигде не плотным и совершенным. Подробнее об этом в главе про броуновское движение.

}\subsection{Канторова лестница} \problemtext{


}\subsection{Парадокс Банаха-Тарского} \problemtext{

}\subsection{Еще один пример неборелевского множества} \problemtext{

Мы приведем еще один пример с целью свыкнуться с мыслью: неборелевских множеств очень много, но на них нелегко наткнуться!
Неизмеримые множества - это очень странные математические объекты, способные поражать воображение. Но они лишены физического смысла! Легко отрезать веревку длиной (хотя бы примерно) $\sqrt{2}$, но разрезать арбуз так, чтобы из кусков получилось два арбуза (хотя бы примерно) не получится!

Каждое действительное число можно представить в виде непрерывной дроби:

$x=a_{0}+\frac{1}{a_{1}+\frac{1}{a_{2}+\frac{1}{...}}}$, где $a_{0}$ - целое, а остальные $a_{i}$ - натуральные числа.

(представление иррациональных чисел - единственно, у каждого рационального числа есть два представления, более короткое считается каноническим).


Пусть $A$ - те числа, для которых непрерывная дробь обладает условием:
последовательность целых чисел $a_{i}$ содержит в себе подпоследовательность, где каждый последующий член делится на предыдущий.

\begin{myth} $A$ - неборелевское, однако $A$ - измеримо по Лебегу.
\end{myth}
\begin{proof} Lusin (...)
\end{proof}

}\subsection{Еще задачи}


\problem{У нас есть счетное количество пленников. Пленники занумерованы натуральными числами и каждый из них видит цвета колпаков пленников с большим номером. Каждому пленнику надевают колпак, равновероятно белый или черный. У каждого пленника есть одна попытка угадать цвет своего колпака. Пленники заранее могут договориться об общей стратегии. Уточнение: никто из пленников не знает, ни что говорили предыдущие, ни угадали ли они. Сколько пленников можно гарантированно спасти?}
\solution{Гарантированно спасаем всех кроме конечного количества! Решение основано на неизмеримых множествах. В парадоксе Банаха-тарского - разрезали и меняем после переставновки объем. Здесь разрезали и мат. ожидание доли перестало равняться вероятности}




\problem{Верно ли, что $1/4$ лежит в Канторовом множестве? Верно ли, что $1/4$ является концом одного из выброшенных интервалов?}
\solution{да, лежит; нет, не конец интервала}



\section{Математическое ожидание - интеграл Лебега} \problemtext{
}\subsection{Интеграл Лебега} \problemtext{

Математическое ожидание - это синоним интеграла Лебега. Единственное отличие в том, что интеграл Лебега иногда считают относительно произвольной меры, а математическое ожидание - только относительно вероятности.

Нам потребуется строгое определение математического ожидания, подходящее для любой случайной величины. Мы будем строить математическое ожидание пошагово. Начнем с простых случайных величин. Затем рассмотрим произвольные неотрицательные, затем действительные. И, когда это требуется, комплексные.

Итак, перед нами четыре объекта:
$\Omega$ - множество исходов
$\F$ - \s-алгебра событий
$P$ - вероятность, определенная для событий из $\F$
$X$ - случайная величина, измеримая относительно $\F$
Сразу уточним, что все рассматриваемые случайные величины должны быть измеримы относительно $\F$.

\begin{mydef}
Случайная величина $X$ называется простой, если принимает конечное число значений.
\end{mydef}


Если случайная величина простая, то ее можно представить в виде: $X=\sum_{i}^{n}x_{i}1_{A_{i}}$, где $A_{i}$ не пересекаются. Таких представлений может быть несколько (можно множество $A_{1}$, где $X$ равна, скажем 5, разбить на два подмножества).


Шаг 1. Простая неотрицательная случайная величина.

\begin{mydef}
Пусть $X$ - простая неотрицательная случайная величина, т.е. $X=\sum_{i=1}^{n}x_{i}1_{A_{i}}$. Интегралом Лебега по мере $P$ (или математическим ожиданием) называется число
\begin{equation}
\E(X):=\int X dP:=\sum_{i=1}^{n}x_{i}\P(A_{i})
\end{equation}
\end{mydef}

В определении неявно задействована измеримость. Вероятность $P$ определена только для событий из некой \s-алгебры \F, поэтому чтобы $\P(A_{i})$ существовали необходимо, чтобы случайная величина $X$ была измерима относительно этой \s-алгебры \F. Легко заметить, что определение корректно, т.к. не зависит от выбранного разбиения.


Кроме того, выполняются следующие свойства.

Если $X$, $Y$ - простые неотрицательные случайные величины и $a\geq 0$ - константа, то:

1. $\E(X+Y)=\E(X)+\E(Y)$.

2. $\E(aX)=a\E(X)$.

3. Если $X\geq Y$, то $\E(X)\geq \E(Y)$.


Шаг 2. Произвольная неотрицательная случайная величина.

\begin{mydef}
Пусть $X$ - произвольная неотрицательная случайная величина. Интегралом Лебега по мере $P$ (или математическим ожиданием) называется величина
\begin{equation}
\E(X):=\int X dP:=\sup_{Z\leq X, Z-simple}  \E(Z)
\end{equation}
\end{mydef}

Т.е. мы перебираем все простые случайные величины $Z$, не превосходящие $X$ и выбираем наибольшее из получающихся математических ожиданий. При этом нужно отметить, что в результате может получится уже не число, а плюс бесконечность. Также заметим, что новое определение не противоречит старому, т.к. если изначально $X$ - простая, то взяв $Z:=X$ мы получим старое значение математического ожидания, а больше получить невозможно в силу неравенства (...).


Все те же свойства:


Шаг 3. Произвольная случайная величина.

Любую случайную величину $X$ всегда можно представить в виде $X=X^{+}-X^{-}$, где $X^{+}=\max\{X,0\}$ - неотрицательная часть $X$, а $X^{-}=-\min\{X,0\}$ - неположительная часть $X$, домноженная на (-1). Величины $X^{+}$ и $X^{-}$ являются неотрицательными, а для неотрицательных у нас уже мат. ожидание придумано.

Картинка [...]

\begin{mydef}
Пусть $X$ - произвольная случайная величина. Интегралом Лебега по мере $P$ (или математическим ожиданием) называется величина
\begin{equation}
\E(X):=\int X dP:=\E(X^{+})-\E(X^{-})
\end{equation},

\end{mydef}




PE1.

PE2.


PE3. Если $X\geq 0$, то $\E(X)\geq 0$.

PE4. Если $X\geq 0$ и $\E(X)=0$, то $\P(X=0)=1$. (часто используется)

PE5. Если $X\geq 0$ и $\E(X)<\infty$, то $\P(X=\infty)=0$.




Обобщение для комплексных случайных величин!




}\subsection{MCT, DCT, Fatou's lemma} \problemtext{

\begin{myth}
Если:

1. $X_{n}$ - неубывающая последовательность неотрицательных случайных величин измеримых относительно \F, $X_{1}\leq X_{2}\leq X_{3}\leq ...$

2. $\lim X_{n}=X$

То:

1. $X$ - измерима относительно $\F$

2. $\lim \E(X_{n})=\E(X)$
\end{myth}

Теорема учитывает случай, когда предел с обеих сторон равен плюс бесконечности.

\begin{proof}
Во-первых, заметим, что $\E(X_{n})\leq \E(X_{n+1})$. Т.е. предел слева обязательно существует, хотя возможно и равен плюс бесконечности.

Случай 1. Среди $X_{n}$ есть такая величина $X_{k}$, что $\E(X_{k})=\infty$.

Если $\E(X_{k})=\infty$, то для любого числа $M$ найдется такая простая случайная величина $S$, что $S\leq X_{k}$, но $\E(S)>M$. Замечаем, что $X\geq X_{k}\geq S$, а значит, $\E(X)\geq \E(S)>M$. Но $M$ произвольное число, значит $\E(X)=\infty$.

Случай 2. Все $\E(X_{n})$ конечны, но $\E(X_{n})\to\infty$.


Случай 3. Все $\E(X_{n})$ конечны, и $\E(X_{n})\to const$.

\end{proof}




\begin{myth}
Если:

1. Последовательность $X_{n}$ ограничена интегрируемой случайной величиной $Y$, т.е $|X_{n}|\leq Y$ и $\E(Y)\infty$.

2. $\lim X_{n}=X$

То:

$\lim \E(X_{n})=\E(X)$

\end{myth}
\begin{proof}

\end{proof}




Если применить лемму Фату к индикаторам, то получается лемма Фату для вероятностей.



Добавить Витали (?) Vitali convergence theorem





}\subsection{Неравенства, леммы Бореля Кантелли} \problemtext{

Еще раз про леммы Бореля-Кантелли.

Первая лемма Бореля-Кантелли: если сумма вероятностей $A_{i}$ конечна, то вероятность того, что произойдет бесконечное количество $A_{i}$ равна нулю. теперь можно дать другое прочтение этой формуле. Пусть $N$ - количество произошедших $A_{i}$, и случайная величина $N$ может принимать значение $+\infty$. Если среднее значение $N$ конечно, то вероятность того, что $N=\infty$ равна нулю.

\begin{myth} Если $\sum \P(A_{i})<\infty$, то $\P(\limsup A_{i})=0$.
\end{myth}
\begin{proof} $\E(N)=\E(\sum_{i} 1_{A_{i}})$. Применяя MCT получаем, что $\E(N)=\sum \E(1_{A_{i}})=\sum \P(A_{i})<\infty$. А значит (используя PE5) и $\P(N=\infty)=0$.
\end{proof}
Вторая лемма Бореля-Кантелли: если $A_{i}$ независимы (или отрицательно коррелированы) и сумма вероятностей $A_{i}$ <<велика>> (равна бесконечности), то вероятность того, что произойдет бесконечное количество $A_{i}$  равна 1. Обобщение на отрицательно зависимые случайные величины заимстовано из \cite{ross:scp}

(самое время сделать упр. про $Cov(1_{A},1_{B})=0$ <> независимость)

\begin{myth} Если события $A_{i}$ независимы или неположительно коррелированы ($Cov(1_{A_{i}},1_{A_{j}})\leq 0$ для $\forall i,j$) и $\sum \P(A_{i})=\infty$, то $\P(\limsup A_{i})=1$.
\end{myth}
\begin{proof} Пусть $N_{k}$ - число произошедших событий среди первых $k$ событий, $N_{k}=1_{A_{1}}+1_{A_{2}}+...+1_{A_{k}}$.

Шаг 1. $Var(N_{k})\leq \E(N_{k})$: $Var(N_{k})\leq \sum Var(1_{A_{i}})$ (т.к. ковариация либо нулевая, либо отрицательная), $\sum Var(1_{A_{i}})=\sum \P(A_{i})(1-\P(A_{i}))\leq \sum \P(A_{i}) =\E(N_{k})$.

Шаг 2. Рассмотрим произвольное число $x<\E(N_{k})$. Для такого $x$: $\P(N_{k}<x)=\P(\E(N_{k})-N_{k}>\E(N_{k})-x)\leq \P(|\E(N_{k})-N_{k}|>\E(N_{k})-x)\leq \frac{Var(N_{k})}{(\E(N_{k})-x)^2}\leq \frac{\E(N_{k})}{(\E(N_{k})-x)^2}$.

Шаг 3. Рассмотрим произвольное число $x$. В силу того, что $\E(N_{k})\to \E(N)=\infty$, наступит такой момент, что неравенство из шага 2 начнет работать. А значит $\lim_{k\to\infty} \P(N_{k}<x)=0$. Но, $\P(N<x)\leq \P(N_{k}<x)$, значит для $\forall x$, вероятность $\P(N<x)=0$.

Шаг 4. Для множеств действует предел $\lim (N<k)=N<\infty$, вероятность непрерывна,  а значит $\P(N<\infty)=0$.
\end{proof}


Неравенство Чебышева (Маркова). $\P(|X|\geq a)\leq \frac{\E(|X|)}{a}$.
\begin{proof}
\end{proof}
Неравенство Йенсена. Если $f:\R\to\R$ - выпуклая функция (уточним, выпуклая вниз, как, например, $f(t)=t^{2}$), то $\E(f(X))\geq f(\E(X))$.
\begin{proof}
\end{proof}
Мне тут попалось малоизвестное забавное неравенство. Будем его популяризировать!

Неравенство <<Раз-два-три>>! Если $X$ и $Y$ независимые случайные величины, то $\E(|X-Y|<2)<3\P(|X-Y|<1)$.

Noga Alon, The 123 theorem and its extensions. Или в упражнения (да, оно дальше не используется)?






}\subsection{Производная Радона-Никодима} \problemtext{


Оказывается, если из одной вероятности легко получить новую!

\begin{myth} Если $X$-неотрицательная случайная величина и $\E(X)>0$, то функция $Q:\F\to [0;1]$, определяемая по формуле: $Q(A)=\frac{\E(1_{A}X)}{\E(X)}$ является вероятностью.
\end{myth}
\begin{proof}
Легко убедиться, что $Q(\emptyset)=\frac{\E(0)}{\E(X)}=0$ и $Q(\Omega)=\frac{\E(X)}{\E(X)}=1$. Осталось проверить счетную аддитивность (аксиому M2 в определении меры).

Пусть $A_{i}$ - попарно непересекающиеся события. Определим $Y_{n}=\sum_{i=1}^{n}1_{A_{i}}X$. Последовательность $X_{n}$ монотонная и поточечно сходится к $Y=\sum_{i=1}^{\infty}1_{A_{i}}X$. Согласно MCT (...) $\E(Y)=\lim \E(X_{n})=\lim \sum_{i=1}{n} \E(1_{A_{i}}X)=\sum_{i=1}{\infty} \E(1_{A_{i}}X)$. Разделив обе части на $\E(X)$ получаем $Q(\cup A_{i})=\sum Q(A_{i})$.
\end{proof}

\begin{myex} Пусть (табличка), $Q(A)=\frac{\E(1_{A}X)}{\E(X)}$
...
Найдите $Q(Y>0)$, $E_{Q}(Y)$
\end{myex}

\begin{myth} Для новой вероятности $Q(A)=\frac{\E(1_{A}X)}{\E(X)}$ новое математическое ожидание будет считаться по формуле $E_{Q}(Y)=\frac{\E(XY)}{\E(X)}$.
\end{myth}
\begin{proof} Доказательство использует стандартный пошаговый метод.
Сначала для простых $Y$.

Теперь для неотрицательных $Y$.

Теперь для произвольных $Y$.
\end{proof}

\begin{myex} Здесь будет дискретный пример.
\end{myex}


\begin{mydef} Вероятность $Q$ называется \indef{абсолютно непрерывной} по отношению к вероятности $P$, если из условия $\P(A)=0$ всегда следует, что $Q(A)=0$. Обозначается абсолютная непрерывность $P>>Q$.
\end{mydef}
\begin{myex} Пусть $\Omega=[0;1]$, $\F=\B[0;1]$, $\lambda$ - классическая мера Лебега на $[0;1]$. ... Чтобы была абсолютная и второй пример, чтобы не было.
\end{myex}



Оказывается иногда верно и обратное, а именно:
\begin{myth} Если $P$ и $Q$ - две вероятности, $P>>Q$, то существует единственная почти-наверное случайная величина $X$, такая что $E_{P}(X)=1$ и $Q(A)=E_{P}(X1_{A})$.
\end{myth}
\begin{proof} Доказательство существования - в аппендикс (?)
Нетрудно доказать, что $E_{P}(X)=E_{P}(X\cdot 1_{\Omega})=Q(\Omega)=1$. Легко доказать и единственность:
Пусть $X$ и $Y$ две функции, удовлетворяющие теореме, тогда $Q(X>Y)=E_{P}(X\cdot 1_{X>Y})=E_{P}(Y\cdot 1_{X>Y})$. Отсюда, $E_{P}((X-Y)1_{X-Y>0})=0$. Но, $(X-Y)1_{X-Y>0}$ - неотрицательная случайная величина, значит $\P((X-Y)1_{X-Y>0}>0)=0$ и $\P(X-Y>0)=0$. Из симметрии $\P(Y-X>0)=0$ и, наконец, $\P(X=Y)=1$.
\end{proof}

\begin{myex} (или упр.) найдите производную радона-никодима - дискретный случай
\end{myex}

\begin{myex} Пусть $\Omega=[0;1]$,  (упр.?) - производная радона-никодима непрер. случай
\end{myex}




}\subsection{Пространство L2 и его геометрия} \problemtext{


\begin{mydef} Пусть $X$ - случайная величина и $p\geq 1$. Определим $||X||_{p}:=(\E(|X|^{p}))^{1/p}$.
\end{mydef}
Это определение допускает, что $||X||_{p}$ может равняться $+\infty$.

Упражнение. приведите пример $X$, такой что $||X||_{1}<\infty$, а $||X||_{2}=\infty$.

\begin{mydef} Пространством $L^{p}(\Omega,\F,P)$ назовем множество \F-измеримых случайных величин, таких, что $||X||_{p}<+\infty$.
\end{mydef}
Когда понятно о каких \F и $P$ идет речь мы будем сокращать обозначение $L^{p}(\Omega,\F,P)$ до $L^{p}(\Omega)$ и даже до $L^{p}$.

\begin{myth} Пространство $L^{p}$ является линейный пространством над $\R$. Если $X\in L^{p}$, $Y\in L^{p}$ и $a\in \R$, то $X+Y\in L^{p}$ и $aX\in L^{p}$.
\end{myth}
\begin{proof}
\end{proof}
\begin{myth} Если $1\leq p\leq q$, то $L^{q}\subset L^{p}$
\end{myth}
\begin{proof}
\end{proof}
Holder, Minkowski


Чуть позже (...) мы докажем полноту пространства $L^{p}$.

Среди пространств $L^{p}$ наибольший интерес представляет для нас пространство $L^{2}$. Во-первых, потому, что именно в $L^{2}$ мы будем по началу определять интеграл Ито. Во-вторых, потому, что в $L^{2}$ есть красивая геометрия, даже две!

(вставка про геометрию)


}\subsection{Сеанс связи с Землей} \problemtext{

Может показаться, что этот конспект - какой-то другой курс теории вероятностей. Формально определяется то, что раньше без всяких проблем и заморочек считалось. Осталось связать эти <<два>> курса, указав, что способ подсчета был верный.

Как до теории меры мы считали математической ожидание случайной величины или функции от нее?

Мы использовали функцию плотности $p(x)$ и брали обычный (Римановский) интеграл:

$\E(f(X))=\int_{-\infty}^{+\infty}f(x)p(x)dx$

Чтобы обосновать этот способ сначала напомним пару определений:

\begin{mydef} Функция $p(x)$ называется \indef{функцией плотности} случайной величины $X$, если...
\end{mydef}
(дать два варианта? с борелевскими и с нормальными?)

\begin{mydef} Функция называется интегрируемой по Риману...
\end{mydef}

Теоремы, связывающие:



}\subsection{Еще задачи}

\section{Сходимости} \problemtext{

Случайные величины - более сложные объекты, чем числа, поэтому сходимость случайных величин бывает разная.

}\subsection{Разные виды сходимостей} \problemtext{

\begin{mydef} Последовательность случайных величин $X_{n}$ сходится к случайной величине $X$ \indef{поточечно} если для любого $w\in\Omega$ имеет место сходимость $X_{n}(w)\to X(w)$.
\end{mydef}
Поскольку ни вероятность, ни математическое ожидание <<не чувствуют>> изменения происходящие на множестве меры нуль, то это определение имеет разумное обобщение:

\begin{mydef} Последовательность случайных величин $X_{n}$ сходится к случайной величине $X$ \indef{почти наверное} если $\P(w|X_{n}(w)\to X(w))=1$.
\end{mydef}
В силу определений, из поточечной сходимости следует сходимость почти наверное, т.к. $\P(\Omega)=1$.

\begin{myex}
\end{myex}

Несколько другим подходом является рассмотрение случайных величин, как векторов пространства $L^{p}$.

\begin{mydef} Последовательность случайных величин $X_{n}$ сходится к случайной величине $X$ \indef{в пространстве} $L^{p}$ ($p\geq 1$), если $||X_{n}-X||_{p}\to 0$ или, эквивалентно, $E\left(|X_{n}-X|^{p}\right)\to 0$.
\end{mydef}
Следующие примеры показывают, что сходимость в $L^{p}$ и сходимость почти наверное не всегда одно и то же.

\begin{myex}
\end{myex}

\begin{myex}
\end{myex}

\begin{myex}
\end{myex}



Однако и сходимость в $L^{p}$ и сходимость почти наверное приводят к тому, что случайные величины сходятся по вероятности

\begin{mydef} Последовательность случайных величин $X_{n}$ сходится к случайной величине $X$ \indef{по вероятности}, если для любого $\varepsilon$ вероятность $\P(|X_{n}-X|>\varepsilon)\to 0$.
\end{mydef}
Как и было обещано, две теоремы:

\begin{myth} Если $X_{n}$ сходится к $X$ почти наверное, то $X_{n}$ сходится к $X$ по вероятности.
\end{myth}
\begin{proof}
\end{proof}
\begin{myth} Если $X_{n}$ сходится к $X$ в $L^{1}$, то $X_{n}$ сходится к $X$ по вероятности.
\end{myth}
\begin{proof}
\end{proof}

Для сходимостей по вероятности, почти наверное, в $L^{p}$ и поточечной требуется, чтобы и все $X_{n}$, и $X$ были заданы на одном вероятностном пространстве $(\Omega,\F,P)$. Ибо только в этом случае будет определена разность $X_{n}-X$.

От этого требования можно отказаться и получить еще более <<слабую>> концепцию сходимости.

Мы приведем два эквивалентных определения слабой сходимости и (?) докажем их эквивалентность:

\begin{mydef} Последовательность случайных величин $X_{n}$ сходится \indef{слабо} (или \indef{по распределению}) к случайной величине $X$, если для любой непрерывной ограниченной функции $f:\R\to\R$ сходятся математические ожидания $\E(f(X_{n}))\to \E(f(X))$.
\end{mydef}
\begin{myex}
\end{myex}

Почему в определении включены непрерывность и ограниченность показывают два примера:

\begin{myex}
\label{conv_unif_to_zero}
Пусть $X_{n}$ равномерно на $[0;\frac{1}{n}]$. А $X$ - тождественно равно нулю. Интуитивно понятно, что $X_{n}$ становятся похожи на $X$ при $n\to\infty$. Возьмем разрывную $f(t)=1_{t=0}$. Получается, что $\E(f(X))=\E(1)=1$, но $\E(f(X_{n}))=0$. Если же функция $f$ непрерывна, то при достаточно большом $n$ окажется, что $f(X_{n})$ не может отличаться от $f(0)$ больше чем на $\varepsilon$. Следовательно, $\E(f(X_{n}))\to \E(f(X))$. Это и означает, что $X_{n}$ слабо сходится к $0$. Заметим, что $X_{n}$ могли быть заданы на разных вероятностных пространствах.
\end{myex}

\begin{myex}

\end{myex}

Второе определение формулируется с помощью функции распределения:

\begin{mydef} Последовательность случайных величин $X_{n}$ (с функцией распределения $F_{n}(t)$) сходится \indef{слабо} (или \indef{по распределению}) к случайной величине $X$ (c функцией распределения $F(t)$), если $F_{n}(t)\to F(t)$ для любой точки $t$, в которой функция распределения $F(t)$ непрерывна.
\end{mydef}

Почему в определении требуется сходимость только в тех точках, где $F_{X}(t)$ непрерывна можно понять из того же примера \ref{conv_unif_to_zero}:
\begin{myex}
\label{conv_unif_to_zero2}
Пусть $X_{n}$ равномерно на $[0;\frac{1}{n}]$. А $X$ - тождественно равно нулю. На рисунках видно, что функции распределения $F_{n}(t)$ сходятся к $F(t)$ во всех точках, кроме точки $t=0$. Но для точки $0$ сходимость не требуется. Значит $X_{n}$ слабо сходится к нулю.

(картинки)
\end{myex}


Доказательство эквивалентности:







<<Слабая сходимость>> соответствует своему названию, и следует из любой другой.

\begin{myth} Если $X_{n}$ сходится к $X$ по вероятности, то $X_{n}$ слабо сходится к $X$.
\end{myth}
\begin{proof}
\end{proof}
В результате общая картина сходимостей выглядит так:




Неединственность предела. \par
Все виды сходимостей (кроме поточечной) используют либо понятие математического ожидания, либо понятие вероятности. Ни математическое ожидание, ни вероятность не меняются, если значение случайной величины изменить на множестве меры нуль. Значит любой из пределов (кроме поточечного) не единственный! Т.е. из того, что $\lim X_{n}=Y$ и $\lim X_{n}=Z$ строго говоря не следует $X=Y$. \par
Конечно, не все так плохо и для всех сходимостей (кроме сходимости по распределению) будет верным утверждение: если $\lim X_{n}=Y$ и $\lim X_{n}=Z$ то $Y=Z$ почти наверное. \par

Старые свойства выполнены: \par
$\lim X_{n}+\lim Y_{n}=\lim (X_{n}+Y_{n})$ \par




Три критерия сходимости почти наверное: (тттк)
\begin{itemize}
\item Для любого $\varepsilon$ существует такое $N$, что для всех $n>N$ выполнено $\P(|X_{n}-X|<\varepsilon)>1-\varepsilon$
\item $\sum \P(|X_{n}-X|>\varepsilon)<\infty$ для всех $\varepsilon$.
\item $\P(\limsup |X_{n}-X|>\varepsilon)=0$ для всех $\varepsilon$.
\end{itemize}
Наиболее полезны, пожалуй, первые два, т.к. они <<вытаскивают>> предел изнутри вероятности наружу.





Упражнение. \par
Докажите, что обратные утверждения к леммам BC1 и BC2 неверны. \par

В силу неравенства Йенсена: $X \in L_{p} \Rightarrow X \in
L_{p-1}$ для $p>1$. \par



}\subsection{Обратные теоремы? Иногда!} \problemtext{

В некоторых важных случаях можно получить <<обратные>> теоремы.

\begin{myth} Если $X_{n}$ сходится к $X$ по вероятности, то из последовательности $X_{n}$ можно выбрать подпоследовательность $Y_{k}$, сходящуюся к $X$ почти наверное.
\end{myth}

\begin{myth}
(Скороход) $X_{n}$ слабо сходится к $X$, если и только если существует последовательность $X_{n}^{'}$, сходящаяся к $X'$ почти наверное, такая что для любого $n$ распределение $X_{n}$ совпадает с распределением $X_{n}^{'}$ и $ X\sim X' $
\end{myth}







\begin{myth}
Если $ X_{n} $ сходится по вероятности к константе...
\end{myth}

% сюда поставить Бореля-Кантелии!
% взять текст из Stochastic Process, Amir Dembo



Докажите такую характеристику сходимости по распределению:

$X_{n}$ слабо сходится к $X$, если и только если существует последовательность $X_{n}^{'}$, сходящаяся к $X'$ по вероятности, такая что для любого $n$ распределение $X_{n}$ совпадает с распределением $X_{n}^{'}$, а $ X'\sim X $.



Пусть $ X_{i} $ - независимы и $ N(0;1) $. Рассмотрим последовательность $ Y_{n}=\sqrt{n}\bar{X} $. К чему и в каких смыслах она сходится?

По распределению сходится, т.к. $ Y_{n}\sim N(0;1) $. По вероятности не сходится (трудно).




}\subsection{Еще задачи}


\section{Независимость и произведения пространств} \problemtext{

Мы уже употребляли независимость, настала пора ее строго определить.

}\subsection{Независимость случайных величин} \problemtext{


\begin{mydef}
\s-алгебры $\F_{1}$ и $\F_{2}$ называются независимыми \index{Независимость \s-алгебр}, если независимы любые два события $F_{1}\in\F_{1}$ и $F_{2}\in\F_{2}$, т.е. $\P(F_{1}\cap F_{2})=\P(F_{1})\P(F_{2})$.
\end{mydef}

Интуитивно независимость \s-алгебр понимается просто: если про каждое событие из $\F_{1}$ вам сказали произошло оно или нет, то это никак не меняет вашу оценку вероятности для событий из $\F_{2}$.

С каждой случайной величиной $X$ связана \s-алгебра $\s(X)$ поэтому, определив независимость  \s-алгебр, мы можем дать...
\begin{mydef}
Случайные величины $ X $ и $ Y $ называются независимыми, если независимы \s-алгебры $\s(X)$ и $\s(Y)$.
\end{mydef}

\begin{mydef}
Случайная величина $ X $ и \s-алгебра $\mathcal{H}$ называются независимыми, если независимы \s-алгебры $\s(X)$ и $\mathcal{H}$.
\end{mydef}

Опять же, интуитивное понимание независимости случайных величин просто: если вам сказали $X$, то это никак не меняет вашу оценку вероятностей связанных с $Y$.

Парочка важных теоремок:

\begin{myth}
Если $X$ и $Y$ независимы, то и $f(X)$ и $g(Y)$ независимы.
\end{myth}
\begin{proof}
Заметим, что $\s(f(X))\subset \s(X)$ и $\s(g(Y))\subset \s(Y)$. По условию \s-алгебры $\s(X)$ и $\s(Y)$ независимы, значит независимы и \s-алгебры $\s(f((X))$ и $\s(g(Y))$.
\end{proof}



\begin{myth}
Если $X$ и $Y$ независимы, то $\E(XY)=\E(X)\E(Y)$
\end{myth}
\begin{proof}
Доказательство построено пошагово почти так же как и определение математического ожидания.

\end{proof}


Остается добавить про связь между независимостью и некоррелированностью. Из теоремы \ref{th:indep_to_uncorr} следует, что из независимости случайных величин следует их некоррелированность. Можно установить и взаимно однозначную связь между некоррелированностью и независимостью:

\begin{myth}
Случайные величины $X$ и $Y$ независимы, если и только если корреляция $Corr(f(X), g(Y))=0$ для любых борелевских функций $f$ и $g$.
\end{myth}
\begin{proof}
В одно сторону: если независимы $X$ и $Y$, то независимы $f(X)$ и $g(Y)$, значит $Corr(f(X),g(Y))=0$. В другую: возьмем в качестве функции $f$ индикатор произвольного борелевского множества $A$, а в качестве функции $g$ индикатор произвольного борелевского множества $B$. Из некоррелированности индикаторов следует независимость событий $\{X\in A\}$ и $\{Y\in B\}$. Все события из $\sigma(X)$ имеют вид $\{X\in A\}$, а все события из $\sigma(Y)$ имеют вид $\{Y\in B\}$.
\end{proof}



}\subsection{Произведение пространств} \problemtext{



Важные следствия:

Когда можно переставлять производную и математическое ожидание?


Когда можно переставлять интеграл и математическое ожидание?




}\subsection{Еще задачи}

\section{Условное ожидание} \problemtext{

Понятие <<условное ожидание>> используется в двух смыслах:
\begin{itemize}
\item $\E(Y|A)$, где $Y$ - случайная величина и $A$ - событие. В этом случае $\E(Y|A)$ - число.
\item $\E(Y|\mathcal{H})$, где $Y$ - случайная величина и $\mathcal{H}$ - \s-алгебра. В этом случае $\E(Y|\mathcal{H})$ - случайная величина.
\end{itemize}

}\subsection{Условное ожидание как константа} \problemtext{

Условное ожидание $\E(Y|A)$ скорее всего знакомо человеку, освоившему вводный курс теории вероятностей. Условное ожидание $\E(Y|A)$ считается точно так же, как и обычное $\E(Y)$, только вместо обычной вероятности $\P(\cdot)$ используется условная вероятность $\P(\cdot|A)$. Если $A$ - событие с положительной вероятностью, то мы можем сменить вероятность каждого события $C$ с $\P(C)$ на $\tilde{P}(C):=\P(C|A)$. В упр. (...) мы видели, что $\tilde{P}$ - это действительно вероятность на \s-алгебре \F. Значит можно считать математическое ожидание (интегрировать) относительно нее:
\begin{mydef}
\label{def:alter_p}
Условное ожидание величины $Y$ относительно события $A$, с $\P(A)>0$ определяется по формуле:
\begin{equation}
\E(Y|A):=E_{\tilde{P}}(Y)=\int_{\Omega}Yd\tilde{P},
\end{equation}
где $\tilde{P}(\cdot):=\P(\cdot|A)$.
\end{mydef}

Можно дать и эквивалентное определение:

\begin{mydef}
\label{def:with_indic}
Условное ожидание величины $Y$ относительно события $A$, с $\P(A)>0$ определяется по формуле:
\begin{equation}
\E(Y|A):=\frac{\E(1_{A}Y)}{\P(A)}
\end{equation}
\end{mydef}

\begin{myth}
Определения \ref{def:alter_p} и \ref{def:with_indic} эквивалентны.
\end{myth}
\begin{proof}
Cтандартная пошаговая процедура.

Для простых случайных величин эти определения эквивалентны:
\begin{multline}
\int_{\Omega}Yd\tilde{P}=\sum_{i=1}^{n}Y_{i}\P(Y=y_{i}|A)=\sum_{i=1}^{n}y_{i}\frac{\P(Y=y_{i}\cap A)}{\P(A)} \\
=\frac{1}{\P(A)}\sum_{i=1}^{n}y_{i}\E(1_{A}1_{Y=y_{i}})=\frac{1}{\P(A)}E\left(\sum y_{i}1_{Y=y_{i}1_{A}}\right)
=\frac{\E(1_{A}Y)}{\P(A)}
\end{multline}
А дальше применяется MCT...
\end{proof}

}\subsection{Условное ожидание как случайная величина. Конечный случай.} \problemtext{

Гораздо более интересно условное ожидание относительно \s-алгебры!

Для начала рассмотрим конечно-порожденную \s-алгебру.

Пример. (...)

\begin{mydef}
Если $A_{1}$, ..., $A_{n}$ попарно не пересекаются, $\P(A_{i})>0$ и $\mathcal{H}=\s(\{A_{i}\})$, то
\begin{equation}
\label{e_cond_simple}
\E(Y|\mathcal{H}):=\sum_{i}\E(Y|A_{i})1_{A_{i}}
\end{equation}
\end{mydef}

По этому определению, если произойдет $A_{1}$, то величина $\E(Y|\mathcal{H})$ будет равна $\E(Y|A_{1}$), если произойдет $A_{2}$, то величина $\E(Y|\mathcal{H})$ будет равна $\E(Y|A_{2}$) и т.д. А поскольку мы заранее не знаем, какое из $A_{i}$ произойдет, то $\E(Y|\mathcal{H})$ является случайной величиной.

Для краткости обозначим $\hat{Y}:=\E(Y|\mathcal{H})$.

Как правильно думать об условном математическом ожидании $\E(Y|\mathcal{H})$?
\begin{itemize}
\item Во-первых, полезно представлять себе $\E(Y|\mathcal{H})$ как <<грубую>>, усредненную, версию $Y$. На множестве $A_{i}$ случайная величина $Y$ может принимать разные значения. А случайная величина $\E(Y|\mathcal{H})$ на множестве $A_{i}$ принимает фиксированное значение $\E(Y|A_{i})$, а это не что иное, как среднее значение величины $Y$ на множестве $A_{i}$.

(картинка)

\item Проекция $Y$ на множество $\mathcal{H}$-измеримых случайных величин. Если рассмотреть все $\mathcal{H}$-измеримые случайные величины, то $\E(Y|\mathcal{H})$ --- самая похожая на случайную величину $Y$. <<Самая похожая>> в том смысле, что расстояние $||Y-\E(Y|\mathcal{H})||_{L^{2}}$ - наименьшее из возможных.


(рисунок)
\item $ \hat{Y} $ --- как решение системы уравнений. С помощью ковариаций и мат. ожидания нельзя почувствовать разницу между $Y$ и $\hat{Y}$! А именно, наш прогноз $\hat{Y}$ - это единственное решение системы уравнений:

\begin{equation}
\begin{cases}
\E(\hat{Y})=\E(Y) \\
Cov(X_{1},\hat{Y})=Cov(X_{1},Y) \\
Cov(X_{2},\hat{Y})=Cov(X_{2},Y) \\
... \\
Cov(X_{n},\hat{Y})=Cov(X_{n},Y) \\
\end{cases}
\end{equation}
где $X_{i}$ - это всевозможные\footnote{Здесь есть некоторая вольность: таких случайных величин бесконечное количество, а вовсе не $n$. Но в случае конечно порожденной $ \sigma $-алгебры можно ограничиться индикаторами $ A_{i} $}   $\mathcal{H}$-измеримые случайные величины.

\end{itemize}

\begin{myex}
здесь дискретный пример с иллюстрацией трех свойств.

\end{myex}

Доказательство корректности второй и третьей интерпретации мы проведем для произвольной $\mathcal{H}$. Но для начала надо обобщить само определение условного математического ожидания на случай произвольной \s-алгебры. Каждую из трех идей можно довести до определения подходящего в общем случае. Кратко о каждом способе:

\begin{itemize}

\item Уточнение грубой версии. Нужно переходить к пределу рассматривая все более и более мелкие $A_{i}$. Легко перейти на счетно-порожденные \s-алгебры. Гораздо трудно перейти на \s-алгебры не являющиеся счетно-порожденными (например такой является хвостовая \s-алгебра).

\item Обобщение проекции. Проекция определена там, где есть углы и скалярные произведения, т.е. в $L^{2}$. Самая главная трудность состоит в переходе от $L^{2}$ определения к $L^{1}$ определению.

\item Решение системы уравнений. Никаких проблем, годится для общего случая. Но трудно доказать существование условного ожидания, т.к. в системе бесконечное количество уравнений, которое не сводится к конечному количеству. Мы пойдем этим путем. За доказательство существования будет отвечать т. Радона-Никодима.
\end{itemize}


Чаще всего приходится иметь дело не с абстрактной \s-алгеброй $\mathcal{H}$, а с \s-алгеброй, порожденной некоей случайной величиной $X$, $\mathcal{H}=\sigma(X)$. В этом случае используют вместо $\E(Y|\sigma(X))$ более простое обозначение $\E(Y|X)$. Если $X$ принимает конечное количество значений, то $\sigma(X)$ будет конечнопорожденной \s-алгеброй, и в этом случае можно искать $\E(Y|X)$ по формуле \ref{e_cond_simple}.

Мы интерпретируем $\E(Y|X)$ как среднее значение $Y$ при известном $X$. Значение $\E(Y|X)$ является функцией от $X$, а поскольку $X$ является случайной величиной, то и $\E(Y|X)$ является случайной величиной.


}\subsection{Условное ожидание как случайная величина. Общий случай.} \problemtext{

\begin{mydef}
Пусть $\mathcal{H}$ - произвольная \s-алгебра и $Y$ - случайная величина с $\E(Y)<\infty$. Условным ожиданием $\E(Y|\mathcal{H})$ называется любая случайная величина $\hat{Y}$ удовлетворяющая двум условиям:

\begin{itemize}
\item $\hat{Y}$ является $\mathcal{H}$-измеримой
\item Для любого события $A\in\mathcal{H}$ верно равенство: $\E(\hat{Y}1_{A})=\E(Y1_{A})$
\end{itemize}
\end{mydef}

Отметим в частности, что в любую $\mathcal{H}$ входит множество $\Omega$, поэтому $\E(\hat{Y})=\E(Y)$.

Зачем в определении требуется, чтобы $\E(Y)<\infty$? Если этого не потребовать, могут возникнуть некоторые парадоксы.

Например: (две шкатулки)

Конечно же,
\begin{myth}
Если $\mathcal{H}$ - конечно порожденная \s-алгебра, то определения ... и ... совпадают.
\end{myth}
\begin{proof}

\end{proof}

Условные ожидания всегда существуют и почти наверное единственны:
\begin{myth}
Если $\E(Y)<\infty$ и $\mathcal{H}$ - \s-алгебра, то существует $\hat{Y}=\E(Y|\mathcal{H})$. Если еще и $\hat{Y}'=\E(Y|\mathcal{H})$, то $\P(\hat{Y}=\hat{Y}')=1$.
\end{myth}
\begin{proof}
\begin{itemize}
\item Существование. Если $Y\geq 0$, то на \s-алгебре $\mathcal{H}$ можно определить конечную меру $\mu(A):=\E(Y1_{A})$. На $\mathcal{H}$ эта мера абсолютно непрерывна по отношению к мере $P$. По теореме Радона-Никодима существует $\mathcal{H}$ измеримая случайная величина $\hat{Y}$, такая что $\mu(A)=\E(\hat{Y}1_{A})$. Для произвольного $Y$ существование доказывается путем разложения $Y=Y^{+}-Y^{-}$.
\item Единственность. Величины $\hat{Y}$ и $\hat{Y}'$ являются $\mathcal{H}$-измеримыми, поэтому $A=\{\hat{Y}-\hat{Y}'>\varepsilon\}\in\mathcal{H}$. $\E((\hat{Y}-\hat{Y}')1_{A})=\E(\hat{Y}1_{A})-\E(\hat{Y}'1_{A})=\E(Y1_{A})-\E(Y1_{A})=0$. С другой стороны, $\E((\hat{Y}-\hat{Y}')1_{A})\geq \E(\varepsilon 1_{A})=\varepsilon \P(A)$. Значит $\P(A)=0$ для всех $\varepsilon$. Событие $(\hat{Y}>\hat{Y}')=\cup_{\varepsilon=1/n}A(\varepsilon)$. В силу непрерывности вероятности, $\P(\hat{Y}>\hat{Y}')=0$. Из соображений симметрии, $\P(\hat{Y}'>\hat{Y})=0$.
\end{itemize}
\end{proof}

Условное ожидание обладает рядом хороших свойств:


\subsubsection*{Как считать условное ожидание?}

\begin{itemize}
\item Для конечной $\mathcal{H}$ ответ дает формула с которой мы начали определение условного ожидания:


\item Если нужно посчитать $\E(Y|X)$, где у пары случайных величин $X$ и $Y$ есть совместная функция плотности, то можно воспользоваться готовым рецептом:
\begin{myth}
Если у пары $X$, $Y$ есть совместная функция плотности $p(x,y)$, то условное ожидание $\E(Y|X)$ можно найти по формуле:
\begin{equation}
\E(Y|X)=\int_{-\infty}^{+\infty}y\cdot p(y|X)dy
\end{equation}
где $p(y|x)$ - условная функция плотности, $p(y|x)=\frac{p(x,y)}{p(x)}$.
\end{myth}
\begin{proof}

\end{proof}

\item В остальных случаях остается одно. Думать. Иногда из интуитивных или геометрических соображений можно догадаться до правильного ответа и тогда остается лишь проверить, что догадка $\hat{Y}$ удовлетворяет определению условного ожидания. При этом может помочь тот факт, что при проверке равенства $\E(\hat{Y}1_{A})=\E(Y1_{A})$ не обязательно проверять все $A\in\mathcal{H}$:
\begin{myth}
Пусть $\mathcal{M}$ - набор событий замкнутый относительно пересечений (если $A$, $B$ лежат в $\mathcal{M}$, то и $A\cap B$ лежит в $\mathcal{M}$), $\mathcal{H}=\sigma(\mathcal{M})$, $\E(Y)=\E(\hat{Y})<\infty$. Если $\E(\hat{Y}1_{A})=\E(Y1_{A})$ для всех $A\in\mathcal{M}$, то $\E(\hat{Y}1_{A})=\E(Y1_{A})$ для всех $A\in\mathcal{H}$.
\end{myth}
\begin{proof}
Рассмотрим набор множеств $\mathcal{N}$, для которых $\E(\hat{Y}1_{A})=\E(Y1_{A})$. Мы докажем, что $\mathcal{N}$ - \s-алгебра. Набор множеств $\mathcal{N}$ содержит $\mathcal{M}$ по условию. Если $\mathcal{N}$ - действительно \s-алгебра, то она обязана содержать наименьшую \s-алгебру $\mathcal{H}$ порождаемую набором $\mathcal{M}$. А это нам и требуется доказать.

По условию в $\mathcal{N}$ входит $\Omega$. Если $A\in\mathcal{N}$, то и $A^{c}\in\mathcal{N}$, т.к. $\E(Y1_{A^{c}})=\E(Y)-\E(Y1_{A})=\E(\hat{Y})-\E(\hat{Y}1_{A})=\E(\hat{Y}1_{A^{c}})$.

Если $A_{i}\in\mathcal{N}$, то и $\cup A_{i}\in\mathcal{N}$. Для непересекающихся $A_{i}$ это следует в силу DCT. а от пересекающихся можно легко перейти к непересекающимся. Здесь требуется замкнутость набора $\mathcal{M}$.
\end{proof}

Например, в самом распространенном случае, при поиске $\E(Y|X)$, т.е. когда $\mathcal{H}=\sigma(X)$, достаточно проверять не все множества из $\sigma{X}$, а только множества вида $X\leq t$. Вспомните теоремку \ref{generate_borel}.



\end{itemize}

Примеры...


\subsubsection*{Условное ожидание как функция и парадокс Колмогорова-Бореля}

Образно говоря, <<при прогнозировании монеток не подкидывают>>:
\begin{myth} \label{e_cond_as_f}
Случайная величина $\E(Y|X)$ представима в виде $\E(Y|X)=f(X)$, где $f$ - неслучайная борелевская функция.
\end{myth}
\begin{proof}

\end{proof}
Эта теорема говорит, что вся случайность величины $\E(Y|X)$ связана только со случайной величиной $X$. Случайная величина $\E(Y|X)$ не может использовать другие источники случайности, не связанные с $X$!

Можно нарисовать такую схему:

% \Omega-> R (X)
% \Omega-> R {\E(Y|X)
% в осях \E(Y|X), X - график f


Уточним, что $f$ не обязательно единственна! Можно лишь утверждать, что если $f_{1}$ и $f_{2}$ две подобные функции, то $f_{1}(X)=f_{2}(X)$ почти наверное.

Очень часто хочется говорить о величине $\E(Y|X=x)$ (среднее значение $Y$, если $X=x$). Если $\P(X=x)>0$, то тут нет никаких проблем. Если $\P(X=x)=0$, то можно прибегнуть к представлению $\E(Y|X)=f(X)$. А именно, сказать что, по определению $\E(Y|X=x):=f(x)$. Например, для непрерывных $X$ и $Y$ хочется определить:

\begin{equation}
\E(Y|X=x)=\int_{-\infty}^{+\infty}yf(y|x)dy
\end{equation}

Это интуитивно понятно, но не стоит этим злоупотреблять! Дело в том, что функция $f$ определена не однозначно, а только почти наверное. Это означает, что для каждого конкретного $x$ можно выбрать любое $f(x)$! Именно поэтому предлагаемое <<определение>> не устойчиво к преобразованиям.

\begin{myex} Парадокс Колмогорова-Бореля.
Пусть совместная функция плотности $X$ и $Y$ имеет вид:
\begin{equation}
p_{X,Y}(x,y)=\left\{
\begin{array}{ll}
  1, & 0<y<1, -y<x<1-y \\
  0, & otherwise \\
\end{array}
\right.
\end{equation}

Пусть $U=\frac{X}{Y}+1$. Найдите:

а) $p_{Y|X}(y|x)$

б) $p_{U,Y}(u,v)$ и $p_{Y|U}(y,u)$

в) Верно ли, что $X=0 \Leftrightarrow U=1$?

г) Верно ли, что $p_{Y|X}(t|0)=p_{Y|U}(t,1)$?

д) Мораль?

\end{myex}







\subsubsection*{Условное ожидание и независимость}

Как связаны условное ожидание и независимость?

Из независимости $ X $ и $ \sigma $-алгебры $ \mathcal{H} $ следует, что $ \E(X|\mathcal{H})=\E(X)$. Обратное неверно, как показывает:
\begin{myex}
Пусть $ X\sim N(0;1) $. Зависимы ли $ X $ и $ X^{2} $? Найдите $ \E(X|X^{2}) $.

Решение. Очевидно зависимы, но $ \E(X|X^{2})=0=\E(X) $
\end{myex}

Тем не менее, независимость и условные ожидания тесно связаны:
\begin{myth}
Случайные величины $ X $ и $ Y $ независимы если и только если $ \E(f(X)|Y)=\E(f(X))$ для любой борелевской функции $f$.
\end{myth}
\begin{proof}
Если $ X $ и $Y  $ независимы, то независимы $f(X)  $ и $ Y $. Значит $ \E(f(X)|Y)=\E(f(X))$.

...

\end{proof}

А именно, если $X$ и $Y$ независимы, можно ли утверждать, что $\E(X|\mathcal{H})$ и $\E(Y|\mathcal{H})$ независимы?

Интуитивно на этот вопрос легко ответить используя геометрическую интерпретацию. Пусть есть две некоррелированные случайные величины $X$ и $Y$. На рисунке (???) они изображены как перпендикулярные векторы. Могут ли их проекции на какую-нибудь плоскость не быть перпендикулярны? Да, конечно могут! Скорее наоборот, чтобы между проекциями получился прямой угол нужно выполнения особого условия (???) вектор $X-Y$ должен лежать в плоскости (??? проверить утверждение)

В качестве конкретного примера подойдет практически первый попавшийся! Например, правильную монетку подбрасывают 20 раз, $X$ - число орлов в первых 10 подбрасываниях, $Y$ - число орлов в последних 10 подбрасываниях, $Z$ - в подбрасываниях с 6-го по 15-ое. Очевидно, что $X$ и $Y$ независимы, однако $\E(X|Z)=\E(Y|Z)=\frac{Z}{2}+\frac{5}{2}$.

А может быть из независимости $X$ и $Y$ будет следовать хотя бы $\E(XY|\mathcal{H})=\E(Y|\mathcal{H})\cdot \E(Y|\mathcal{H})$, <<условная некоррелированность>>?

Предыдущий пример также показывает, что это не так. Разложив $X$ и $Y$ в сумму индикаторов, можно установить, что $\E(XY|Z)=25\left(\frac{Z(Z+8)}{90}+\frac{1}{4}\right)\neq \left(\frac{Z}{2}+\frac{5}{2}\right)^{2}$.



% Хотя кое-какая еще связь есть... (откуда я помню дикую формулу и куда ее применить?)




}
\subsubsection*{Задачи}

\problem{Пусть $\hat{Y}=\E(Y|\mathcal{H})$, где $\mathcal{H}$ - произвольная \s-алгебра. Пусть $X$ - $\mathcal{H}$-измеримая случайная величина, принимающая конечное множество значений. Докажите, что $Cov(X,\hat{Y})=Cov(X,Y)$}
\solution{$X$ допускает разложение $X=\sum x_{i}1_{A_{i}}$. В силу линейности ковариаций достаточно проверить равенство для индикаторов. Проверяем: $Cov(1_{A_{i}},\hat{Y})=\E(\hat{Y}1_{A_{i}})-\E(\hat{Y})\E(1_{A_{i}})=\E(Y1_{A_{i}})-\E(Y)\E(1_{A_{i}})=Cov(1_{A_{i}},Y)$.}


\problem{ Приведите пример, таких $Y_{1}$, $Y_{2}$ и $\mathcal{H}$, что $\E(Y_{1}|\mathcal{H})$ $\E(Y_{2}|\mathcal{H})$ независимы, а $Y_{1}$ и $Y_{2}$ зависимы.}
\solution{Например, пусть $Y_{1}$ - распределено геометрически и $Z$, независимо от $Y_{1}$, принимает равновероятно значения $+1$ или $-1$. Определим $Y_{2}:=ZY_{1}$ и $\mathcal{H}:=\sigma(Y_{1})$. Получаем, что $Y_{1}=|Y_{2}|$, но $\E(Y_{2}|\mathcal{H})=0$, поэтому $\E(Y_{1}|\mathcal{H})$ и $\E(Y_{2}|\mathcal{H})$ независимы.}







\subsection{Еще задачи}


\section{Производящие функции} \problemtext{

\url{http://www.stats.uwaterloo.ca/~dlmcleis/s901/s901_2005.pdf}
\url{http://www.mathematik.uni-muenchen.de/~lerdos/WS04/FA/compl.pdf}

Если есть случайная величина $X$, то как описать ее закон распределения?

Есть много способов! Если величина непрерывная, то можно описать ее с помощью функции плотности, $p(t)$. Если случайная величина дискретная --- с помощью функции $p(t):=\P(X=t)$. Есть универсальный способ записи, подходящий для любых случайных величин --- функция распределения, $F(t):=\P(X\leq t)$. В конце концов можно описать просто текстом: например, <<правильную>> монетку подкидывают $n$ раз и $X$ - это количество <<орлов>>.

Сейчас мы познакомимся еще с одной идеей, позволяющей описать закон распределения случайной величины.

Эта идея будет представлена тремя функциями:

\begin{itemize}
\item Производящая функция, $ g_{X}(t):=\E(t^{X}) $
\item Функция производящая моменты, $ m_{X}(t):=\E(e^{tX}) $
\item Характеристическая функция, $ \phi_{X}(t):=\E(e^{itX}) $
\end{itemize}


}\subsection{Производящая функция} \problemtext{


Если $ X $ --- целочисленная неотрицательная случайная величина, то для ее описания подходит

\begin{mydef}
Функция $ g_{X}(t):=\E(t^{X}) $ называется производящей функцией случайной величины $ X $.
\end{mydef}


Пример с табличкой. (...)


Найдем производящую функцию для пуассоновской случайной величины.

$ g_{X}(t)=\E(t^{X})= $



Производящая функция может не существовать...

Пример. ....



По производящей функции можно <<опознать>> случайную величину:
\begin{myth}
Если совпадают производящие функции $ g_{X}(t) $ и $ g_{Y}(t) $, то случайные величины $ X $ и $ Y $ имеют одинаковое распределение.
\end{myth}


Легко найти производящую функцию суммы:
\begin{myth}
Если существуют $ g_{X}(t) $ и $ g_{Y}(t) $, то :
\[g_{X+Y}(t)=g_{X}(t)\cdot g_{Y}(t)\]
\end{myth}


С помощью производящей функции легко считать математическое ожидание и другие моменты:
\begin{myth}
Если существуют $ g_{X}(t) $ и $ \E(X) $, то:

\[ \E(X)=g'_{X}(1) \]

\[ \E(X(X-1))=g''_{X}(1) \]

\[ \E(X(X-1)(X-2))=g'''_{X}(1) \]

...

\end{myth}


Найдем производящую функцию для биномиальной случайной величины.

Упражнение. Пусть $ X \sim Bin(n,p)$. Найдите $ g_{X}(t) $.

Решение. Биномиальная случайная величина представима в виде суммы независимых $ X=X_{1}+X_{2}+...+X_{n} $. Находим производящую функцию отдельного слагаемого, получаем $ g_{X_{i}}(t)=pt+1-p $. Значит для биномиальной случайной величины $ g_{X}(t)=(pt+1-p)^{n} $




Теперь попробуем применить производящую функцию на реальных задачах:

Пример.






Сейчас мы познакомимся еще с одним способом описать закон распределения случайной величины, но для этого нам потребуются комплексные случайные величины.





}\subsection{Комплексные случайные величины} \problemtext{

Для работы с характеристическими функциями нам потребуются комплексные случайные величины.

\begin{mydef}
\indef{Математическим ожиданием} комплексной случайной величины $Z$ называется число
\begin{equation}
z:=\E(Re(Z))+i\E(Im(Z))
\end{equation}
при условии, что $\E(|Z|)<\infty$.

\end{mydef}


У математического ожидания по-прежнему сохраняются все полезные свойства:
\begin{itemize}
\item $\E(cZ)=c\E(Z)$, если $c\in\mathbb{C}$
\item $\E(Z_{1}+Z_{2})=\E(Z_{1})+\E(Z_{2})$, если мат. ожидания существуют

\end{itemize}





}\subsection{Определение и примеры} \problemtext{

Однако есть принципиально другой подход к описанию закона распределения случайной величины, а именно - производящие/характеристические функции. Их много видов:

\begin{itemize}
\item Производящая функция, $g(t)=\E(t^{X})$
\item Функция производящая моменты, $m(t)=\E(e^{tX})$
%\item Преобразование Лапласа, $L(t)=\E(e^{-tX})$
%\item Преобразование Фурье, $\E(e^{-itX})$
\item Характеристическая функция, $\phi(t)=\E(e^{itX})$.
\end{itemize}

Чем они хороши?

\begin{itemize}
\item Любой случайной величине (дискретной, непрерывной...) сопоставляется непрерывная функция!
\item Во-первых, они подходят для описания закона распределения случайной величины. Если у величин $X$ и $Y$ совпадают производящие функции, то у них совпадает закон распределения.
\item Если $X$ и $Y$ - независимые случайные величины, то производящая функция суммы легко находится: $g_{X+Y}(t)=g_{X}(t)g_{Y}(t)$. Для сравнения: при использовании функций плотности придется считать интеграл!
\item С помощью них легко считать моменты случайной величины $\E(X^{k})$, при этом нужно будет только находить производную.
\item Некоторые из них, а именно преобразование Фурье и характеристическая функция существуют для любых случайных величин.
\end{itemize}

Чем они плохи?
\begin{itemize}

\item Их труднее интерпретировать. Мы постараемся...
\item Вероятности с их помощью считать труднее.
\item Многие студенты в 21 веке до сих пор боятся комплексных чисел\footnote{Впрочем, это скорее недостаток студента, а не характеристической функции}.
\end{itemize}

Давайте попробуем посчитать и убедимся, что все не так трудно!
\begin{myex} Пусть $X$ принимает значения $-1$, $2$ и $4$ с вероятностями $0.1$, $0.4$ и $0.5$ соответственно. Найдите
\begin{enumerate}
\item Производящую функцию
\item Функцию производящую моменты
\item Характеристическую функцию
\end{enumerate}
Выписав значения соответствующих величин получаем:
\begin{enumerate}
\item $g_{X}(t)=0.1t^{-1}+0.4t^{2}+0.5t^{4}$,
\item $m_{X}(t)=0.1e^{-t}+0.4e^{2t}+0.5e^{4t}$,
\item $\phi_{X}(t)=0.1e^{-it}+0.4e^{2it}+0.5e^{4it}$. У характеристической функции можно выделить мнимую и действительную части: $\phi_{X}(t)=0.1\cos(t)+0.4\cos(2t)+0.5\cos(4t)+i(-0.1\sin(t)+0.4\sin(2t)+0.5\sin(4t))$.
\end{enumerate}

\end{myex}

Уже можно заметить, что производящие функции оказались неограниченными, а характиристическая - ограничена! Еще один пример:

\begin{myex} Какие значения с какими вероятностями принимает случайная величина $X$ если:

\begin{enumerate}
\item Производящая функция равна $g_{X}(t)=0.6t^{-5}+0.4t^{7}$
\item Функция производящая моменты равна $m_{X}(t)=0.7e^{3t}+0.3e^{27t}$
\item Характеристическая функция равна $\phi(t)=0.5(1+\cos(t))+i\cdot 0.5\sin(t)$.
\end{enumerate}
Ответы, конечно, читаются в условии:

\begin{enumerate}
\item $X$ принимает значения $-5$ и $7$ с вероятностями $0.6$ и $0.4$ соответственно.
\item $X$ принимает значения $3$ и $27$ с вероятностями $0.7$ и $0.3$ соответственно.
\item Заметим, что $1=\cos(0\cdot t)$ и $0=\sin(0\cdot t)$, поэтому наша функция равна $phi_{X}(t)=0.5e^{i\cdot 0\cdot t}+0.5e^{i\cdot 1\cdot t}$. Значит $X$ равновероятно принимает значения $0$ и $1$.
\end{enumerate}

В этом примере есть маленькая нестрогость: мы нашли случайную величину с данной производящей функцией, но не доказали, что не существует другой.
\end{myex}

\begin{myex} Пример, когда $g(t)$ не существует
\end{myex}

Мы остановимся более подробно на характеристической функции, так как она определена для любой случайной величины.

Для начала маленькое напоминание про математическое ожидание комплексных случайных величин. Если $Z=X+iY$ - комплексная случайная величина, то (по определению), $\E(Z)=\E(X)+i\E(Y)$. Заметим также, что $e^{itX}=\cos(tX)+i\sin(tX)$. Поэтому, под выражением $\E(e^{itX})$ нужно понимать не что иное как $\E(\cos(tX))+i\E(\sin(tX))$. Из этого сразу следует, что характеристическая функция всегда существует. Действительно, косинус и синус ограничены, значит оба математических ожидания всегда существуют.

\begin{myex} Пусть $X$ равномерна на $[0;1]$. Найдем характеристическую функцию: $\phi(t)=\E(e^{itX})=\E(\cos(tX)+i\sin(tX))=\int_{0}^{1}\cos(tx)dx+i\int_{0}^{1}\sin(tx)dx=\frac{\sin(t)}{t}+i\frac{\cos(t)-1}{t}$. При $t=0$, особый, но простой случай, $\phi(0)=1$.
\end{myex}

Все, конечно, хорошо представляют как выглядит график функции плотности равномерной случайной величины:
(...)

А как представить графически характеристическую функцию? Можно поступить несколькими способами:

\begin{itemize}
\item Нарисовать кривую в 3-х мерном пространстве (рисунок)
\item Нарисовать два графика на плоскости: $Re(\phi(t))$ и $Im(\phi(t))$:
\item Нарисовать два графика на плоскости: $|\phi(t)|$ и $\arg(\phi(t))$ (в качестве аргумента комплексного числа можно выбрать любую версию, например попадающую в интервал $[0;2\pi)$ или непрерывную)
\end{itemize}

Второй способ, по всей видимости, предпочтительнее так как в случае, когда закон распределения случайной величины $X$ симметричен относительно нуля (т.е. $\P(X\leq t)=\P(X\geq -t)$ для $\forall t$), оказывается, что $Im(\phi(t))=0$ и достаточно одного графика. Чуть позже мы докажем это, а пока еще один пример.

\begin{myex} Случайная величина $X$ принимает равновероятно значения $1$ и $(-1)$. Как выглядит ее характеристическая функция? $\phi(t)=\E(e^{itX})=0.5e^{-it}+0.5e^{it}=0.5(\cos(-t)-i\sin(t))+0.5(\cos(t)+i\sin(t))=\cos(t)$. Как и было обещано, мнимая часть отсутствует.
\end{myex}




}\subsection{Свойства характеристической функции} \problemtext{

\begin{itemize}
\item $\phi(0)=1$

По определению, $\phi(0)=\E(\cos(0\cdot X))+i\E(\sin(0\cdot X))=1$

\item $|\phi(t)|\leq 1$ для любого $t$

$|\phi(t)|=|\E(\cos(t\cdot X)+i\sin(t\cdot X))|\leq \E(|\cos(t\cdot X)+i\sin(t\cdot X)|)=1$
\item $\phi_{-X}(t)=(\phi_{X}(t))$- сопряжение поставить!

\item $\phi_{aX+b}(t)=e^{iat}\phi(bt)$


\item Если $X$ и $Y$ независимы, то $\phi_{X+Y}(t)=\phi_{X}(t)\phi_{Y}(t)$

\begin{multline}
\phi_{X+Y}(t)=E\left(e^{it(X+Y)}\right)=E\left(e^{itX}e^{itY}\right)\\
=E\left(e^{itX}\right)E\left(e^{itY}\right)=\phi_{X}(t)\phi_{Y}(t),
\end{multline}
в силу независимости $e^{itX}$ и $e^{itY}$

\item Если закон распределения $X$ симметричен, то $Im(\phi_{X}(t))=0$
\item Функция $\phi$ является равномерно непрерывной
\end{itemize}



}\subsection{Доказательство ЦПТ} \problemtext{



}\subsection{Поиск вероятностей и среднего с помощью характеристической функции} \problemtext{

Допустим нам нужно найти вероятность связанную с суммой случайных величин. В силу того, что для суммы легко ищется характеристическая функция, бывает что проще искать вероятность именно с ее помощью.


Пример. Вероятность вымирания. \par

Еще Пример. Поиск вероятности с использованием производящей функции.\par
Мы рассмотрим пример с векторными случайными величинами.


Пример. Мы подбрасываем монетку до тех пор, пока количество орлов не привысит количества решек. $T$ - количество подбрасываний. Найдите $\E(1/T)$.

Заметим, что $1/T=\int_{0}^{1}x^{T-1}dx$.

Ссылаясь на теорему ... $\E(1/T)=\int_{0}^{1}\E(x^{T-1})dx$.

А $\E(x^{T})$ - это не что иное, как производящая функция!



Из этого примера следует мораль: производящие/характеристические функции дают возможность заменить дискретную сумму на интеграл непрерывной функции!

Хотите поговорить об этом?

}\subsection{Суммирование рядов с помощью производящих функций...} \problemtext{


основное из статьи A unified method to sum a variety of infinite series with applications



}\subsection{Еще задачи}

\section{Мартингалы в дискретном времени} \problemtext{
}\subsection{О случайном блуждании} \problemtext{

Случайное блуждание - пожалуй, самый важный из дискретных случайных процессов. Броуновскому движению в непрерывном времени многие свойства случайного блуждания <<перейдут по наследству>>. Поэтому мы достаточно подробно изучим симметричное случайное блуждание.

\begin{mydef}
Пусть $X_{i}$ - последовательность независимых случайных величин, равновероятно принимающих значение $+1$ или $(-1)$. Процесс $S_{n}=\sum_{i=1}^{n}X_{i}$ называется \indef{симметричным случайным блужданием}.
\end{mydef}

Графически $S_{n}$ - это координаты частицы, которая начав в нуле равновероятно смещается на один шаг влево или вправо.

Чтобы <<почувствовать>> некоторые свойства случайного блуждания мы ответим на несколько вопросов:
\begin{enumerate}
\item Пусть $a$ и $b$ - два натуральных числа. Какова вероятность того, что случайное блуждание никогда не достигнет ни точки $a$, ни точки $-b$? Какова вероятность того, что $S_{n}$ <<коснется>> точки $a$ раньше, чем точки $-b$?
\item Сколько шагов в среднем потребуется, чтобы достигнуть точки $1$?
\item Сколько шагов в среднем потребуется, чтобы достигнуть уровня $a$ или $-b$?
\item Какова вероятность того, что случайное блуждание посетит точку $a$?
\item Какова вероятность того, что случайное блуждание вернется в точку $0$?
\item Сколько раз в среднем случайное блуждание посетит точку $a$?
\item Сколько раз в среднем случайное блуждание посетит точку $a$ прежде чем впервые вернется в точку $0$?
\end{enumerate}

Попробуйте для начала ответить на эти вопросы устно, без вычислений, интуитивно. Запишите свои ответы и потом сравните с правильными. В этой главе мы ответим на эти вопросы не произнося слова <<мартингал>>. Поехали!

\begin{enumerate}
\item Пусть $a$ и $b$ - два натуральных числа. Какова вероятность того, что случайное блуждание никогда не достигнет ни точки $a$, ни точки $-b$? Какова вероятность того, что $S_{n}$ <<коснется>> точки $a$ раньше, чем точки $-b$?

Предположим, что мы стартуем не в нуле, а в произвольной точке $ x\in\{-b,-b+1,..., a\} $. Обозначим интересующую нас вероятность как $ p_{x} $. По определению, $ p_{a}=1 $ и $ p_{-b}=0 $. Для остальных $ x $ выполнено рекуррентное соотношение:

\[ p_{x}=0.5p_{x-1}+0.5p_{x+1} \]

Если разбить $ p_{x} $ на два одинаковых слагаемых $ p_{x}=0.5p_{x}+0.5p_{x} $, то мы получим

\[ p_{x}-p_{x-1}=p_{x+1}-p_{x} \]

Это означает, что $ p_{x} $ растет линейно с постоянной скоростью от $ p_{-b}=0 $ до $ p_{a}=1 $. В частности, $ p_{0}=\frac{b}{a+b} $.


\item Сколько шагов в среднем потребуется, чтобы достигнуть точки $1$?

Пусть $m$ - это интересующее нас мат. ожидание. Заметим, что оно очевидно больше 1 и, а-приори, нельзя исключать, что оно бесконечно.

После первого шага мы либо достигли точки $1$ (и нам потребовался один шаг), либо отошли еще дальше от точки $1$ и нам в среднем потребуется $m$ шагов, чтобы вернуться в $0$ и еще в среднем $m$ шагов, чтобы попасть в $1$. Итого:
\begin{equation}
m=0.5\cdot 1 + 0.5 (1 + 2m)
\end{equation}
Хм, решений у этого уравнения нет. Точнее есть, а именно, $m=+\infty$.

\item Сколько шагов в среднем потребуется, чтобы достигнуть уровня $a$ или $-b$?

Пусть $e_{k}$ - искомое количество ходов, при условии, что сейчас мы находимся в точке $k$. Краевые условия: $e_{a}=0$ и $e_{b}=0$. Разностное уравнение:
\begin{equation}
e_{k}=1+0.5e_{k-1}+0.5e_{k+1}
\end{equation}

Чтобы не мучится с методом неопределенных коэффициентов, который, конечно, сработает, мы поступим так. Заметим, что решение - квадратный трехчлен, обнуляющийся в $a$ и $b$. Значит, это что-то типа $e_{k}=-(k-a)(k+b)$. Проверяем, подходит. Находим, что $e_{0}=ab$.

\item Какова вероятность того, что случайное блуждание посетит точку $a$?

Для начала посчитаем вероятность когда-либо посетить точку $1$. Обозначим ее $p$.

После первого шага мы либо уже в точке $1$ с вероятностью $0.5$, либо отошли влево. Если мы отошли влево, то чтобы посетить когда-нибудь точку $1$ придется сначала когда-нибудь посетить точку $0$, а затем когда-нибудь точку $1$. Итого:
\begin{equation}
p=0.5\cdot 1 + 0.5 p^{2}
\end{equation}

Единственное решение этого уравнения $p=1$. По-честному, нужно еще доказать, что событие <<процесс когда-нибудь достигнет точки 1>> - это событие, чтобы не случилось так, что вероятность не определена.

Теперь рассмотрим произвольную точку $a$. Мы с вероятностью 1 когда-нибудь попадем из точки $0$ в точку $1$. Когда-нибудь с вероятностью 1 попадем из $1$ в $2$ и т.д. Значит с вероятностью $1$ когда-нибудь попадем в $a$.

\item Какова вероятность того, что случайное блуждание вернется в точку $0$?

После первого шага мы отойдем на единичку вправо (или влево). А потом с вероятностью 1 вернемся в $0$.

\item Сколько раз в среднем случайное блуждание посетит точку $a$?

C вероятностью 1 мы попадем в $ a $ хотя бы раз. Затем мы отойдем на единичку вправо или влево. И снова с вероятностью 1 попадем в $a$. Значит в среднем мы посетим $a$ бесконечное количество раз.

\item Сколько раз в среднем случайное блуждание посетит точку $a$ прежде чем впервые вернется в точку $0$?
\end{enumerate}






Задачи...

Решите все указанные задачи для несимметричного случайного блуждания.










}\subsection{Про <<хвостовую>> сигма-алгебру. Для опоздавших.} \problemtext{

Пусть кто-то подбрасывает монетку бесконечное количество раз. Раз за разом, скажем одно подбрасывание в минуту. Введем случайную величину $X_{i}$, которая будет равна 1, если в $i$-ый раз выпала решка и 0, если орел. Величины $X_{1}$, $X_{2}$, ... - независимы и одинаково распределены.

Известно, что Вася (любитель подольше поспать) опоздал к началу эксперимента. Опоздал на неизвестное нам время. То есть он наблюдает значения $X_{i}$ только начиная с некоторого номера $T$.

Есть ли какой-то список событий, которые Вася различает вне зависимости от того, на сколько минут он опоздал?

Казалось бы ответ <<нет>>. Ни про одну из $X_{i}$ нельзя быть уверенным в том, что она известна Васе. Он мог опоздать на 10 минут и не знать $X_{1}$, ..., $X_{9}$. А мог опоздать на 1000 минут и не знать значений $X_{1}$, ..., $X_{999}$.

Однако это не так! На сколько бы Вася не опоздал, он всегда сможет сказать, произошли ли события <<начиная с некоторого момента были только орлы>> или <<орел сменялся на решку бесконечное количество раз>>.

Насколько бы Вася не опоздал он станет свидетелем целой кучи событий!

\begin{mydef} Пусть $\F_{n}'=\s(X_{n},X_{n+1},...)$ - \s-алгебра событий различимых наблюдателем, пришедшем в момент времени $n$. \indef{Остаточной} \s-алгеброй называется \s-алгебра $\cap_{n} \F_{n}'$.
\end{mydef}
(упр) Приведите еще три примера событий, наблюдателем которых станет Вася, вне зависимости от величины опоздания.

Правда все события из этой \s-алгебры в каком-то смысле тривиальны и ради них не стоило и торопиться. Можно было не выходя из дома, сказать произойдут они или нет (почти наверное)!

\begin{myth}[Закон 0-1 Колмогорова] Если $X_{i}$ - последовательность независимых одинаково распределенных случайных величин, и $\mathcal{H}$ - остаточная \s-алгебра, то для любого события $H\in\mathcal{H}$ вероятность $\P(H)=0$ или $\P(H)=1$.
\end{myth}

\begin{proof}
\end{proof}

\begin{myex} Рассмотрим событие $A$ - <<последовательность <<Решка-Решка-Орел>> встречается бесконечное количество раз>>. Это событие входит в остаточную \s-алгебру, поэтому его вероятность либо 0, либо 1. ... В результате она равна 1.
\end{myex}


}\subsection{Определение мартингала} \problemtext{

\begin{mydef}
Пусть $(\Omega,\F,P)$ - вероятностное пространство. Последовательность \s-алгебр $\{\F_{t}\}$ называется \indef{фильтрацией}, если $\F_{n}\subset \F_{n+1}$ и $\F_{n}\subset \F$ для всех $n$.
\end{mydef}

Говоря простым языком, $\F_{n}$ - это список событий, которые рациональный наблюдатель способен различить в момент времени $n$. С течением времени наблюдатель накапливает информацию (ничего не забывает), поэтому этот список становится все больше и больше.

\begin{mydef}
Процесс $X_{n}$ называется адаптированным к фильтрации $\F_{n}$ если для каждого $n$ случайная величина $X_{n}$ является $\F_{n}$-измеримой.
\end{mydef}

Другими словами, в любой момент времени $n$, информации, содержащейся в \s-алгебре $\F_{n}$ достаточно, чтобы сказать, чему равна случайная величина $X_{n}$. С каждым процессом всегда связана <<естественная>> фильтрация, а именно: $\F_{1}:=\s(X_{1})$, $\F_{2}:=\s(X_{1},X_{2})$, $\F_{3}:=\s(X_{1},X_{2},X_{3})$ и т.д.


\begin{mydef}
Случайный процесс $X_{n}$ называется мартингалом по отношению к фильтрации $\{\F_{n}\}$, если:
\begin{itemize}
\item[M1.] Для всех $n$ математическое ожидание $\E(X_{n})$ конечно.
\item[M2.] Процесс $X_{n}$ адаптирован к фильтрации $\F_{n}$.
\item[M3.] $\E(X_{n+1}|\F_{n})=X_{n}$ a.s.
\end{itemize}
\end{mydef}

Самое существенное условие M3 говорит: наилучший прогноз будущего значения мартингала - это его текущее значение. Поэтому бывает удобно представлять мартингал как благосостояние азартного игрока, играющего в <<справедливую>> игру в казино.

Иногда дают определение мартингала без явного упоминания фильтрации:
\begin{mydef}
Случайный процесс $X_{n}$ называется мартингалом, если:
\begin{itemize}
\item[M1.] Для всех $n$ математическое ожидание $\E(X_{n})$ конечно.
\item[M3'.] $\E(X_{n+1}|X_{n},X_{n-1},...,X_{1})=X_{n}$ a.s.
\end{itemize}
\end{mydef}

Это определение равносильно первому, если в качестве фильтрации взять естественную.


Примеры.

\begin{myex}. Случайное блуждание - мартингал относительно естественной фильтрации:
\begin{multline}
\E(X_{n+1}|\F_{n})=\E(X_{n}+I_{n+1}|\F_{n})=X_{n}+\E(I_{n+1}|\F_{n})=X_{n}+\E(I_{n})=X_{n},
\end{multline}
мы воспользовались тем, что $\F_{n}=\s(X_{1},X_{2},...,X_{n})=\s(I_{1},I_{2},...,I_{n})$. Поэтому $I_{n+1}$ не зависит от $\F_{n}$, а $X_{n}$ измерима относительно $\F_{n}$.
\end{myex}

Можно обобщить идею случайного блуждания. Не обязательно прибавлять плюс или минус единицу равновероятно. Главное, чтобы добавка имела нулевое условное ожидание, $\E(X_{n+1}-X_{n}|\F_{n})=0$. Например, если $I_{n}$ - независимые случайные величины, и $\E(I_{n})=0$, то $X_{n}=\sum_{i=1}^{n}I_{i}$ - мартингал.


\begin{myex}. Мультипликативный мартингал. $X_{1}=1$, случайные величины $I_{n}$ - независимы и $\E(I_{n})=1$. Рассмотрим $X_{n}=\prod_{i=1}^{n} I_{i}$. Он является мартингалом относительно естественной фильтрации:
\begin{multline}
\E(X_{n+1}|\F_{n})=\E(X_{n}\cdot I_{n+1}|\F_{n})=X_{n}\cdot \E(I_{n+1}|\F_{n})=X_{n}\E(I_{n})=X_{n},
\end{multline}
\end{myex}

Хозяйке на заметку! Если у вас в холодильнике есть случайный процесс, не являющийся мартингалом, а до прихода гостей осталось несколько минут, то из него можно сварить превосходный мартингал!

Может эти сюжету включить после? Т.к. не совсем понятно, зачем варить мартингал?


Если в холодильнике завалялась последовательность iid...

Пусть $I_{i}$ - независимые одинаково распределенные случайные величины с $\E(I_{i})\neq 0$.

\begin{itemize}
\item[Рецепт 1.] Отрежем лишнее! Определим $X_{n}:=\sum_{i=1}^{n} I_{i}-n\E(I_{i})$.
\item[Рецепт 2.] Создание <<мультипликативного мартингала>>. Найдем такое число $a>0$, что $\E(a^{I_{i}})=1$. Определим $X_{n}:=a^{\sum_{i=1}^{n}I_{i}}$.
\end{itemize}

Если в холодильнике только марковская цепь... [Нужна ли глава про марковские цепи?]

Рецепт 3. Если $X_{n}$ - цепь маркова, то можно поискать такую функцию $f$, что $M_{n}=f(X_{n})$ - мартингал.

\begin{myex}
Пусть $X_{1}=1$, а далее в каждый момент времени мы делаем шаг либо вправо, либо влево. Вероятности зависят от $n$ и равны $p_{n\to n+1}=\frac{n+1}{2n}$ и $p_{n\to n-1}=\frac{n-1}{2n}$. Найдите такое преоборазование $f$, что $f(X_{n})$ - мартингал.

Решение. Если $f(X_{n})$ - мартингал, то и $af(X_{n})+b$ - тоже мартингал

Т.к. $f(X_{n})$ - это мартингал, то получаем следующее рекуррентное соотношение:
\begin{equation}
f(n)=p_{n\to n-1} f(n-1)+p_{n\to n+1} f(n+1)
\end{equation}

В нашем случае:
\begin{equation}
f(n)=\frac{n-1}{2n}f(n-1)+\frac{n+1}{2n} f(n+1)
\end{equation}

Как решить такое разностное уравнение? Можно домножить на $n$ и сделать замену $g(n)=nf(n)$. После этого получим линейное уравнение и находим, что $g(n)=c_{1}+c_{2}n$. Т.е. $f(n)=\frac{c_{1}}{n}+c_{2}$.

Мы вольны выбрать любое решение, поэтому выбираем самое простое, $f(n)=\frac{1}{n}$. Т.е. $M_{n}=1/X_{n}$ - это мартингал. Конечно, $M_{n}:=0$ тоже мартингал, но он не будет полезен при нахождении вероятностей связанных с процессом $X_{n}$.
\end{myex}







Высший пилотаж! В холодильнике всего одна случайная величина!!!

\begin{myex}
Рецепт 4. Мартингал Леви. Берем произвольную случайную величину $X$ с $\E(X)<\infty$ и произвольную фильтрацию $\F_{n}$. И строим последовательность $X_{n}$ по принципу $X_{n}:=\E(X|\F_{n})$.
\end{myex}

Неожиданно, но многие мартингалы устроены по принципу мартингала Леви. Даже если ...









У мартингалов есть два очень хороших свойства:
\begin{itemize}
\item Во-первых, многие преобразования оставляют мартингал мартингалом.
\item Во-вторых, многие мартингалы сходятся. (...) сюда про Леви
\end{itemize}
Поэтому очень часто при изучении случайных процессов не являющихся мартингалами полезно увидеть мартингал.



}\subsection{Момент остановки} \problemtext{
% момент остановки обозначаем буквой тау! (так у Steele)

\begin{mydef} Случайная величина $\tau$, принимающая значения из
множества $\{1,2,...\}\cup \{+\infty\}$ называется моментом
остановки, если $\{\tau=n\} \in \mathcal{F}_{n}$ для любого $n$.
\end{mydef}

Другими словами, вывод о том, что надо остановиться в момент
времени $n$ можно сделать в момент времени $n$. Возможно, что вывод может быть сделан и раньше (так как вполне возможно, что событие $\{\tau=n\}$ содержится не только в \s-алгебре $\F_{n}$, но и в более ранней).

\begin{myex} Момент времени, когда индекс Доу-Джонса,
достигает своего ежегодного максимума, не является моментом остановки. Этот момент времени не обнаруживается сразу, чтобы понять, что он был в момент времени $n$, нужно ждать конца года. Мы не можем использовать стратегию типа <<когда индекс достигнет своего годового максимума я сделаю то-то и то-то>>. Хотя,
безусловно, этот момент времени - случайная величина.
\end{myex}

\begin{myex} Момент первого касания (first hitting time). Момент $\tau$ - это тот день, когда индекс Доу-Джонса впервые превысит $1000$, $\tau=\min\{n|X_{n} \ge 1000\}$. Если траектория такова, что индекс никогда не превышает 1000, то $\tau=+\infty$.
\end{myex}


Дадим эквивалентное определение:

Упражнение. Убедитесь, что определение не изменится, если
$\{\tau=n\}$ заменить на $\{\tau \le n\}$ или на $\{\tau > n\}$ \par

Упражнение. Если $\tau$ - момент остановки, то множества $\{\tau<n\}$,
$\{\tau\le n\}$, $\{\tau=n\}$, $\{\tau\ge n\}$ и $\{\tau>n\}$ лежат в
$\mathcal{F}_{n}$. \par



Упражнение. \par
Верно ли, что $\tau=a$ - момент остановки? \par

Пусть $\tau_1$ и $\tau_2$ - моменты остановки, верно ли что $\tau_1\wedge \tau_2$,
$\tau_1\vee \tau_2$, $\tau_1+a$ и $\tau_1+\tau_2$ - моменты остановки? \par

\subsubsection{Информация к моменту остановки.}

Каждому моменту остановки $\tau$ можно сопоставить $\sigma$-алгебру,
отражающую всю информацию, известную к моменту времени $\tau$. \par
\begin{mydef}
Пусть $\tau$ - момент остановки.
\begin{equation}
\mathcal{F}_{\tau}:=\{A \in \mathcal{F}|A\cap \{\tau=n \} \in
\mathcal{F}_{n},\forall n\}
\end{equation}
\end{mydef}



\begin{mydef}
Если $\tau$ - время первой аварии на недавно построенном
шоссе, то событие $A=\{$за день до аварии был туман$\}$ лежит в
$\mathcal{F}_{\tau}$. Это событие может не содержаться ни в одной
$\mathcal{F}_{n}$. \par
Событие $B=\{$на следующий день после аварии был туман$\}$ в
$\mathcal{F}_{\tau}$ может не содержаться.
\end{mydef}




В $\mathcal{F}_{\tau}$ входят те события, про которые в момент
времени $\tau$ точно можно будет
сказать, произошли они или нет.\par
Если возможно несколько сценариев развития события, при одном из
которых мы в момент времен $N$ будем знать, произошло ли $A$ или
нет, а при другом - не будем знать, то $A$ в $\mathcal{F}_{\tau}$ не
входит. \par
$\mathcal{F}_{\tau}$ - это не случайный объект а 'нормальная'
$\sigma$-алгебра. \par
Полезно представлять себе $\mathcal{F}_{n}$ как газету, выходящую
в день $n$, а $\sigma$-алгебру $\mathcal{F}_{\tau}$ как спецвыпуск
газеты, посвященный произошедшей аварии (или другому наступившему
моменту остановки). \par

Упражнение. \par
Определение не изменится, если $\tau=n$ заменить на $\tau\le n$. \par

Упражнение. \par
Если $\tau$ - момент остановки, то $\mathcal{F}_{\tau}$ - действительно
$\sigma$-алгебра и $\tau\in \mathcal{F}_{\tau}$. \par

Упражнение. \par
$N\equiv n \Rightarrow \mathcal{F}_{N}=\mathcal{F}_{n}$ и $N\equiv +\infty \Rightarrow \mathcal{F}_{N}=\mathcal{F}$ \par

Упражнение. \par
Если $\tau<+\infty$ - момент остановки и $Y_{n}\in\mathcal{F}_{n}$,
то $Y_{\tau}\in\mathcal{F}_{\tau}$. \par
В частности, из этого упражнения следует, что
$\sum_{i=1}^{\tau}Y_{i}$ и $\max_{n\le \tau}\sum_{i=1}^{n}Y_{i}$ являются
$\mathcal{F}_{\tau}$-измеримыми. \par

Упражнение. \par
Если $M$ и $N$ - моменты остановки, то
$\mathcal{F}_{M}\cap\mathcal{F}_{N}=\mathcal{F}_{M\wedge N}$ \par
"Доказательство": Вынесем $\mathcal{F}$ за скобки и заострим $\cap$ :) \par

Упражнение. Если $N$ - момент остановки, то $\mathcal{F}_{N\wedge
n} \subseteq \mathcal{F}_{n}$ \par

Упражнение. \par
Пусть $M\le N$ - моменты остановки.
Как связаны между собой $\sigma$-алгебры $\mathcal{F}_{M}$ и $\mathcal{F}_{N}$? \par

Упражнение. \par
Пусть $T$ - момент остановки, $A\in\mathcal{F}_{T}$ и $m\le n$.
Тогда $A\cap\{T=m\}\in\mathcal{F}_{T\wedge n}$ \par

Упражнение. \par
Пусть $T_{1}$, $T_{2}$, $T_{3}$, ... - моменты остановки и
существует $T=\lim_{n\rightarrow +\infty}T_{n}$. Тогда $T$ - момент
остановки. \par

Упражнение. \par
Пусть $T_{1}\ge T_{2}\ge T_{3}\ge ...$ - последовательность
моментов остановки с пределом $T$. Докажите, что
$\mathcal{F}_{T}=\cap_{n}\mathcal{F}_{T_{n}}$. \par
Пусть $T_{1}\le T_{2}\le T_{3}\le ...$ - последовательность
моментов остановки с конечным пределом $T$. Докажите, что
$\mathcal{F}_{T}=\sigma(\cup_{n}\mathcal{F}_{T_{n}})$. \par
Приведите пример к предыдущему утверждению, доказывающий
необходимость конечности $T$. \par
Подсказка: \par
$$
\Omega=\bigcup_{n}\bigcup_{L=1}^{\infty}\bigcap_{l=L}^{\infty}\left(T_{l}=T=n\right)
$$



}\subsection{Остановленный мартингал} \problemtext{



% про теорему о моменте остановки
% сначала в дискретном времени, потом в непрерывном

% идеология: лучше сделать лишний повтор, ибо: 1 - можно рассказать несколько раз, не опасаясь, что кто-нибудь поймет :), 2 - появляется большая независимость глав.

% аудитория: студенты-нематематики, хотя и студенты-математики могут найти что-нибудь новое для себя


% \section{Теорема Дуба}

На стиль изложения во многом повлияли источники \cite{stirzaker:prp}, \cite{chang:sp}, \cite{ross:scp}

Пусть $X_{t}$ - наше благосостояние в справедливой игре в момент времени $t$ или мартингал. Наша стратегия заключается в том, чтобы в нужный момент завершить игру, скажем, после крупного выигрыша. Другими словами, наша стратегия определяется моментом остановки $T$. Этот момент остановки - случайная величина, так как может зависить от хода игры. Случайной величиной является также и $X_{T}$ - выигрыш на момент выхода из игры. Вопрос в том, чему равен средний выигрыш на момент прекращения игры, $\E(X_{T})$?

Ответ дает теорема Дуба:
Если не ждать <<слишком>> долго, то каким бы хитрым не был момент остановки ожидаемый выигрыш будет равен начальной сумме, $\E(X_{T})=\E(X_{1})$.

Сразу приведем пример <<слишком>> долгого ожидания: ждать до выигрыша в один рубль в классическом случайном блуждании. Условие  $\E(X_{T})=\E(X_{1})$ здесь нарушено: выигрыш на момент выхода из игры равен одному рублю (по построению), а стартовая сумма равна нулю. Почему это слишком долгое ожидание? Потому, что в этом случае можно доказать, что $\E(T)=+\infty$.

Заметим, что для того, чтобы случайная величина $ X_{T} $ была определена (хотя бы почти наверное) необходимо, чтобы $ \P(T<\infty)=1 $.

Точный смысл понятия <<слишком>> долго можно увидеть в теореме:

Если $X_{t}$ - мартингал, $T$ - момент остановки, $ \P(T<\infty)=1 $, и выполнено хотя бы одно из пяти условий:
\begin{itemize}
\item [TD1.] Момент $T$ ограничен, то есть существует число $M$, такое что $T<M$.

\item [TD2.] Процесс $X_{t\wedge T}$ ограничен, то есть существует число $M$, такое что для любого $t$ верно неравенство $|X_{t\wedge T}|<M$.

\item [TD3.] $\E(T)<+\infty$ и существует число $M$, такое что для любого $t$ верно неравенство $\E(|X_{t+1}-X_{t}||\mathcal{F}_{n})<M$.

\item [TD4.] $\E(|X_{T}|)<\infty$ и $lim_{t\to\infty}\E(X_{t}1_{T>t})=0$.

\item [TD5.] Мартингал $X_{t}$ является равномерно интегрируемым.

\end{itemize}


То: $\E(X_{T})=\E(X_{1})$.

В большинстве случаев первых трех критериев достаточно для практического применения.
Четвертый критерий является следствием любого из первых трех (?).

В пятом критерии используется определение равномерной интегрируемости...
Набор случайных величин является равномерно интегрируемым, если...


Из этих критериев все кроме третьего (может есть какой-то <<предельный>> аналог и третьего? - я не знаю) работают в непрерывном времени.

Из теоремы Дуба легко вывести тождество Вольда. Wald's identity.

Если складывать случайное количество случайных величин (опять же, не <<слишком>> много), то среднее значение суммы равно произведению среднего размера слагаемых на среднее количество слагаемых. Это кажется очевидным, но на самом деле не все так просто, так теорема допускает, что количество слагаемых может зависить от размера слагаемых.

Если $X_{i}$ - независимые одинаково распределенные случайные величины и $T$ - случайная величина принимающая целые неотрицательные значения и $\E(T)<\infty$, то $\E(\sum_{i=1}^{T}X_{i})=\E(X_{i})\E(T)$.

Доказательство:

Случаный процесс $M_{t}=\sum_{i=1}^{t}X_{i}-t\cdot \E(X_{i})$ - мартингал. Применяя к нему теорему Дуба получаем, что $\E(M_{T})=\E(M_{1})$. Здесь $\E(M_{1})=0$, $M_{T}=\sum_{i=1}^{T}X_{i}-T\cdot \E(X_{i}$, поэтому $\E(\sum_{i=1}^{T}X_{i})=\E(X_{i})\E(T)$.




%\section{Примеры}

Между примерами и задачами нет существенного различия. Если легко, то можно взять условие примера и попробовать его решить как задачу. А если тяжело, то можно посмотреть решение задачи. Пожалуй, тексты примеров в каком-то смысле <<классические>>. Иногда используемые для решения мартингалы настолько изящны, что вспоминаются субтитры при показе сложных трюков по телевизору: <<Трюки выполнены профессиональными каскадерами. Не пробуйте повторить их самостоятельно>>. Только здесь нужно пробовать!

% включить доказательство без теоремы Дуба


Задача. Симметричное случайное блуждание.

Улитка начинает свой путь в точке 0 и за каждую минуту равновероятно смещается влево или вправо на один сантиметр\footnote{Скорость виноградной улитки около 4 см в минуту, но у нас улитка попалась ленивая.}. Справа от улитки на расстоянии $a$ находится виноградное дерево, слева на расстоянии $b$ - шелковица.

Какова вероятность того, что улитка доползет до виноградного дерева раньше? Сколько в среднем времени ей потребуется чтобы доползти до любого из деревьев?

Решение с мартингалами: $X_{t}$ - координата улитки в момент времени $T$ - мартингал. Пусть $T$ - момент достижения одной из границ ($a$ или $-b$), тогда $|X_{t\wedge T}|\leq \max\{a,b\}$. Момент времени $T$ можно смажорировать геометрической случайной величиной. Разобьем время на интервалы по $(a+b)$ шагов. Будем засчитывать выход за пределы множества $(-b;a)$ только на границах этих интервалов. Очевидно, что требуемое для выхода время от этого только возрастет.

За каждый интервал вероятность выхода случайного блуждания за пределы множества $(-b;a)$ выше чем $(1/2)^{a+b}$ (это вероятность того, что случайное блуждание сделает $(a+b)$ шагов вправо). Значит требуемое для выхода количество временных интервалов можно ограничить сверху случайной величиной $M$ с геометрическим распределением и вероятностью успеха равной $p=(1/2)^{a+b}$. Получаем, что $\P(T=\infty)\leq \P(M=\infty)=0$ и $\E(T)\leq (a+b) \E(M)=(a+b) 2^{a+b}$.

Применяя пункт (ii) теоремы Дуба получаем, что $\E(X_{T})=\E(X_{1})$. По условию $\E(X_{1})=0$. Величина $X_{T}$ может принимать только два значения $a$ или $-b$. Пусть значение $a$ принимается с вероятностью $p$. Тогда $pa+(1-p)(-b)=0$ и $p=\frac{b}{a+b}$.

Заметим также, что $M_{t}=X^{2}_{t}-t$ - также мартингал: $\E(M_{t+1}-M_{t}|\mathcal{F}_{t})=\E(2X_{t}\Delta X_{t+1}+(\Delta X_{t+1})^{2}-1|\mathcal{F}_{t})=2X_{t}\E(\Delta X_{t+1}|\mathcal{F}_{t})+\E((\Delta X_{t+1})^{2})-1=0+1-1=0$.

Применяя ??? пункт (iii) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. При этом $\E(M_{1})=0$, а $M_{T}=X_{T}^{2}-T$, значит $\E(X_{T}^{2})=\E(T)$. Величина $X_{T}^{2}$ принимает только два значения: $a^{2}$ и $b^{2}$, значит $\E(T)=a^{2}\frac{b}{a+b}+b^{a}\frac{a}{a+b}=ab$.

Задача. Несимметричное случайное блуждание

Улитка начинает свой путь в точке 0 и за каждую минуту смещается влево или вправо на один сантиметр. Однако влево идти улитке не очень хочется, поэтому вправо она идет с вероятностью $p>1/2$, влево - с вероятностью $(1-p)$. Справа от улитки на расстоянии $a$ находится виноградное дерево, слева на расстоянии $b$ - шелковица.

Какова вероятность того, что улитка доползет до виноградного дерева раньше? Сколько в среднем времени ей потребуется чтобы доползти до любого из деревьев?

Решение с мартингалами: $X_{t}$ - координата улитки в момент времени $T$ - не мартингал, т.к. в улитка склонна смещаться вправо.

Как сварить из немартингала мартингал? Один из стандартных приемов следующий: вместо процесса $X_{t}$ рассмотреть процесс $M_{t}=u^{X_{t}}$, где число $u$ подбирается так, чтобы $M_{t}$ стал мартингалом. Из нескольких возможных $u$ выбирают $u\neq 1$, т.к при $u=1$ процесс $M_{t}$ всегда будет равен 1.

Ищем $u$ в нашем случае. Требуем, чтобы $M_{t}$ был мартингалом: $\E(M_{t+1}|\mathcal{F}_{t})=M_{t}$. Это условие упрощается до $\E(u^{\Delta{X}_{t+1}})=1$ или $p\cdot u^{1}+(1-p)\cdot u^{-1}=1$.
Квадратное уравнение имеет два корня, $u=1$ и $u=\frac{1-p}{p}$, выбираем второй.

Как и в случае симметричного случайного блуждания улитки $\P(T=\infty)=0$, $\E(T)<\infty$ так как время $T$ снова мажорируется геометрической случайной величиной. Также и процесс $M_{t\wedge T}$ ограничен сверху.

Применяя пункт (ii) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. Величина $M_{T}$ принимает всего два значения: $u^{a}$ и $u^{-b}$, а $\E(M_{1})=1$. Пусть $p$ - вероятность доползти сначала до точки $a$ (виноградного дерева). Из уравнения $pu^{a}+(1-p)u^{-b}=1$ находим $p=\frac{...}{...}$.

Чтобы найти $\E(T)$ можно использовать мартингал $Y_{t}=X_{t}-t\cdot \E(\Delta X_{t})$ или, что в принципе то же самое, тождество Вольда. По тождеству Вольда среднее количество слагаемых равно среднему значению суммы делить на средний размер слагаемого: $\E(T)=\frac{\E(Y_{T})}{\E(\Delta X_{t})}=...$


Задача. ABRACADABRA \cite{ross:scp}\cite{williams:pwm}
% Ross, Second course, Williams, probability with martingales

Если одна мартышка печатает наугад буквы на клавиатуре, то она рано или поздно с единичной вероятностью напечатает роман Льва Толстого <<Война и мир>>. Мы поставим вопрос по-другому: сколько нажатий на клавиши в среднем потребуется чтобы напечатать слово <<абракадабра>>? Какова дисперсия требуемого количества нажатий?

Решение через мартингалы.  Организуем казино! Перед каждым нажатием в казино приходит
новый игрок с начальным капиталом в 1 рубль. Каждый входящий игрок
действует по одной и той же схеме: ставит все имеющиеся деньги на
очередную букву слова АБРАКАДАБРА (войдя в казино игрок ставит на А, потом на Б, потом на Р и т.д. Если слово кончилось, то игрок покидает казино с выигрышем). Если обезьяна напечатала нужную букву, то игрок получает свою ставку, увеличенную в 33 раза, если нет - то игрок покидает казино без денег.

Пусть $X_{t}$ - суммарное благосостояние всех игроков, начавших игру до нажатия номер $t$. Величина $X_{t}$ естественно раскладывается на благосостояния отдельных игроков пришедших в казино $X_{t}=Y_{1t}+...+Y_{tt}$. Здесь $Y_{it}$ - это благосостояние $i$-го игрока после нажатия номер $t$. Заметим, что для каждого игрока $Y_{it}$ - это мартингал, т.к. игра справедливая - на каждом шаге игрок либо теряет деньги, либо с вероятностью $1/33$ увеличивает свой выигрыш в 33 раза. Так как игроки начинают с одного рубля, то $\E(Y_{it})=1$. Чистый выигрыш игроков к моменту времени $t$, $M_{t}=X_{t}-t$ оказывается мартингалом: $\E(M_{t+1}-M_{t}|\mathcal{F}_{t})=\E(Y_{1,t+1}-Y_{1,t}|\mathcal{F}_{t})+...+\E(Y_{t,t+1}-Y_{t,t}|\mathcal{F}_{t})+\E(Y_{t+1,t+1}-1|\mathcal{F}_{t})=0$.

Заметим, что когда слово <<абракадабра>> напечатано впервые, все игроки кроме трех проиграли по одному рублю. Угадавший <<абракадабра>> имеет $33^{11}$, угадавший <<абра>> имеет $33^{4}$ и угадавший <<а>> имеет $33$ рубля. Значит $M_{T}=33^{11}+33^{4}+33-T$. Также получаем, что $M_{t}1_{T>t}\leq (33^{11}+33^{4}+33)1_{T>t}$.

Время $T$ можно смажорировать с помощью геометрической случайной величины. Можно давать обезьяне чистый лист после каждый 11 нажатий и засчитывать <<абракадабру>>, только если слово напечатано на отдельном листе. Очевидно, что ожидаемое время при этом возрастет. Количество листов $L$ будет иметь геометрическое распределение с $p=\frac{1}{33^{11}}$ и $\E(L)=33^{11}$. Значит $T<11L$ и $\E(T)<\E(11\cdot L)=11\cdot 33^{11}$.

Для геометрического распределения $\P(L>t)$ стремится к нулю при $t\to\infty$. Значит $\E(M_{t}1_{T>t}\leq (33^{11}+33^{4}+33)\E(1_{T>t})\leq (33^{11}+33^{4}+33) \P(L<t/11)$ стремится к нулю.

Применяя пункт (iv) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. При этом $\E(M_{T}=(33^{11}+33^{4}+33)-\E(T)$, а $\E(M_{1})=0$, значит $\E(T)=33^{11}+33^{4}+33$.

Про дисперсию. Теперь игроки приходят в наше казино с возрастающими суммами денег: первый с одним рублем, второй - с двумя и т.д. Снова рассмотрим $X_{t}$, суммарное благосостояние игроков вступивших в игру к моменту времени $t$ и чистый выигрыш этих игроков, $M_{t}=X_{t}-(1+2+...+t)=X_{t}-\frac{t(t+1)}{2}$.

При данном изменении выигравших будет также трое и на момент появляения <<абракадабры>> общий чистый выигрыш составит $M_{T}=(T-10)\cdot 33^{11}+(T-3)\cdot 33^{4}+T\cdot 33-\frac{T(T+1)}{2}$.

Как и раньше $\E(T)<\infty$ и $\E(M_{t}1_{T>t})\to 0$ ...

Применяя пункт (iv) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. Значит $\E(M_{T})=0$. Из этого уравнения выражается $\E(T^{2})$, а затем и по формуле $Var(T)=\E(T^{2})-\E(T)^{2}$ находим дисперсию $Var(T)=(33^{11}+33^{4}+33)^{2}-(11\cdot 33^{11}+4\cdot 33^{4}+ 33)$.


Задача. <<Следующая карта - дама>> \cite{morters:m}, \cite{winkler:gpdp}

Перед гадалкой колода из 36 карт, хорошо перемешанная. Гадалка
должна предсказать появление дамы. Гадалка открывает
одну за другой карты из колоды и в любой момент может остановиться
и сказать <<Следующая карта будет дамой>>. Если это окажется правдой, то гадалка выиграла.

Какую вероятность выигрыша дает следующая стратегия: дождаться появления первой дамы и после этого рискнуть и заявить, что следующая карта будет дамой? Какова оптимальная стратегия? Каковы при шансы выиграть при оптимальной стратегии?

Решение через мартингалы. Рассмотрим процесс $X_{t}$ - долю дам в еще неоткрытой части колоды после $t$ открытых карт. После $t$ открытых карт в колоде остается $(36-t)$ карт, из которых $(36-t)X_{t}$ дам. С вероятностью $X_{t}$ (доля дам совпадает с вероятностью открыть даму) количество дам уменьшится на одну.

Считаем $\E(X_{t+1}|\mathcal{F}_{t})=\E(X_{t+1}|X_{t})=\frac{(36-t)X_{t}+X_{t}(-1)}{36-t-1}=X_{t}$.

Значит, $X_{t}$ - мартингал. Момент остановки $T$ в любом случае ограничен 36 картами, следовательно, требования пунтка (i) теоремы Дуба выполнены и $\E(X_{T})=\E(X_{0})=\frac{4}{36}$ для любой стратегии.

Решение без мартингалов. Шансы гадалки не меняются, если она будет угадывать последнюю карту, а не следующую: информации о последней карте ровно столько, сколько о следующей. А шансы того, что последняя карта будет дамой равны $\frac{4}{36}$.
Значит все стратегии оптимальны и дают выигрыш в $4/36$

Задача. <<И в воздух чепчики бросали...>> % Ross, Second Course in Probability

Приезжающих из армии или от двора встречают $n$ женщин. Они
одновременно подбрасывают вверх $n$ чепчиков. Ловят чепчики
наугад, каждая женщина ловит один чепчик.
Женщины, поймавшие свой чепчик уходят. А женщины,
поймавшие чужой чепчик, снова подбрасывают его вверх.
Подбрасывание чепчиков продолжается до тех пор, пока каждая не
поймает свой чепчик.

Найдите:

а) среднее количество женщин, поймавших свой чепчик при одном подбрасывании

б) среднее количество подбрасываний

Решение с мартингалами. Пусть $N_{1}$ - количество женщин поймавших чепчики при первом подбрасывании. Величина $N$ легко раскладывается в сумму индикаторов: $N_{1}=X_{1}+...+X_{n}$, где $X_{i}$ - принимает значение 0 или 1 в зависимости от того, поймала ли $i$-ая женщина свой чепчик. Находим $\E(X_{i})=\P(X_{i}=1)=1/n$ и $\E(N_{1})=n\cdot \frac{1}{n}=1$. Аналогично и для остальных раундов, где участвует меньшее количество женщин.

Значит в каждом раунде в среднем одна женщина ловит свой чепчик. Пусть $Y_{t}=N_{1}+...+N_{t}$ - суммарное количество женщин поймавших свой чепчик после раунда $t$. Получаем, что $\E(Y_{t})=t$. Случайный процесс $M_{t}=Y_{t}-t$ - это мартингал, так как $\E(M_{t+1}|\mathcal{F}_{t})=\E(M_{t+1}|M_{t})=\E(M_{t}+N_{t+1}-1|M_{t})=M_{t}$. Разность $M_{t+1}-M_{t}=N_{t+1}-1$ ограничена количеством женщин $n$.

Смажорируем $T$, чтобы увидеть, что $\E(T)<\infty$. Вероятность того, что конкретная женщина поймает свой чепчик равна единице делить на количество женщин, участвующих в раунде, а следовательно не меньше $1/n$. Если вместо подбрасывания чепчиков в каждом раунде одна (любая) женщина будет уходить с вероятностью $1/n$, а с вероятностью $1-1/n$ не будет уходить никто, то ожидаемое количество раундов возрастет (занижена вероятность ухода, возможность ухода нескольких женщин за один раунд исключена). Количество раундов для ухода одной женщины в этом случае будет иметь геометрическое распределение со средним значением $n$ раундов, а ожидаемое общее количество раундов равно $n^{2}$. Следовательно, $\E(T)<n^{2}$.

Применяя пункт (iii) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. Так как $M_{T}=Y_{T}-T=n-T$ и $\E(M_{1})=\E(N_{1}-1)=0$, получаем, что $\E(T)=n$.

Ключи и сейфы \cite{aops:keys} % aops:keys

Ballot problem \cite{ross:scp} % Ross, Second




Задача. РРО против ОРО\cite{li:ma}. % Li, Martingale Approach

Правильную монетку подбрасывают до появления последовательности РРО или ОРО. Сколько подбрасываний в среднем нужно? Какова вероятность того, что подбрасывания закончатся последовательностью РРО?

Решение с мартингалами. ???

Решение без мартингалов. ???



Задача. <<Вампиры-гладиаторы>> \cite{winkler:gpdp} % Winkler, Games people don't play

Две команды вампиров-гладиаторов борются за победу в турнире. В вашей команде 100 вампиров с силами от 1,2,..., 100. В команде противника 59 вампиров с силами 72,73,..., 130. Турнир состоит из последовательных раундов в каждом из которых участвует по одному гладиатору с каждой стороны. Если встретились гладиаторы с силами $a$ и $b$, то первый побеждает с вероятностью $\frac{a}{a+b}$, а второй - с вероятностью $\frac{b}{a+b}$. Победитель добавляет к свой силе силу побежденного (получает силу $a+b$), а побежденный выбывает из турнира (получает силу $0$). Турнир продолжается до полного выбывания одной из команд.

Вы знаете, что команда противника будет выставлять гладиаторов по следующему принципу: на арену всегда выходит самый слабый из команды.

Какова ваша оптимальная стратегия? Какова вероятность выигрыша при этой стратегии?

Решение с мартингалами. Пусть $X_{t}$ - суммарная сила гладиаторов нашей команды после $t$ боев. Процесс $X_{t}$ - мартингал: $\E(X_{t+1}-X_{t}|\mathcal{F}_{t})=\frac{a}{a+b}b+\frac{b}{a+b}(-a)=0$.

Момент окончания турнира $T$ ограничен, т.к. за каждый раунд выбывает ровно один гладиатор, то есть $T<100+59$.

Применяя пункт (i) теоремы Дуба получаем, что $\E(X_{T})=\E(X_{0})$. Начальная суммарная сила нашей команды, $X_{0}=50\cdot 101$. В конце турнира суммарная сила $X_{T}$ может принимать два значения: либо 0, если мы проиграли, либо $50\cdot 101+59\cdot 101$. Если $p$ - вероятность нашей победы, то $(1-p)\cdot 0+p\cdot (109\cdot 101)=50\cdot 101$. Значит $p=\frac{50}{109}$. Причем результат не зависит от используемой стратегии, т.к. она нигде не использовалась при подсчете!




% Задача. <<Гладиаторы>> - а может у нее нет мартингального решения?

% Задача. Какую долю от имеющейся ставить на цвет следующей карты?
% есть ли мартингальное решение




% Задача о втором тузе. \cite{morters:m} - совмещена с гадалкой
% Second heart problem -  Morters, Martingales, p. 31

% На столе хорошо перемешанная колода из 36 карт. Карты открывают одну за одной до появления первого туза. Какова вероятность того, что следующая карта будет тузом?

% Решение через мартингалы. Рассмотрим процесс $X_{t}$ - долю тузов в еще неоткрытой % части колоды после $t$ открытых карт. После $t$ открытых карт в колоде остается % $(36-t)$ карт, из которых $(36-t)X_{t}$ тузов. С вероятностью $X_{t}$ (доля тузов % совпадает с вероятностью открыть туза) количество тузов уменьшится на один.

% Считаем %$\E(X_{t+1}|\mathcal{F}_{t})=\E(X_{t+1}|X_{t})=\frac{(36-t)X_{t}+X_{t}(-1)}{36-t-1}=X_{t}% $ .

% Значит, $X_{t}$ - мартингал. Оптимальный момент остановки $T$ в любом случае %ограничен 36 картами, следовательно, требования пунтка (i) теоремы Дуба выполнены и $ %\E(X_{T})=\E(X_{0})=\frac{4}{36}$.

% Решение без мартингалов. Шансы открыть туза не меняются, если открывать последнюю  карту, а не следующую: информации о последней карте ровно столько, сколько о следующей. % А шансы того, что последняя карта будет тузом равны $\frac{4}{36}$.






%\section{Задачи}

Ряд задач взят из \cite{stirzaker:prp}, \cite{stirzaker:otep}, \cite{zastawniak:bsp}, \cite{blom:pspt}


Задача.

%Усталость улитки.
%Усталость улитки в момент времени $t$ определяется как $U_{t}=t\cdot S_{t}$ (чем %дальше улитка
% эх плохо - разный знак у S_{t} - как бы это обозвать?

Пусть $X_{t}$ - симметричное случайное блуждание.

Найдите $\E(TS_{T})$,

Задача. \cite{wilmott:chap} % wilmott:chap

Бабушка изготовила кисель. В банке киселя плавают 10 вишенок. За один день Вовочка выпивает случайное количество киселя равномерно распределенное от нуля до всей банки. Вовочка пьет кисель прямо с вишенками, если они ему попадаются. Чтобы бабушка ничего не заметила каждый день Вовочка доливает в банку воды до полного объема.
Вовочка пьет до тех пор пока в банке не останется 5 вишенок. Пусть $T$ - количество дней, которые Вовочка будет пить кисель, а $X_{t}$ концентрация киселя в день $t$.

Докажите, что $\E(T)=-\E(\ln X_{T})$

Решение. Заметим, что $ X_{t+1}=X_{t}\cdot U_{t+1} $, где $ U_{t} $ --- доля невыпитого Вовочкой в день $ t $ равномерно распределена на $ [0;1] $. Применяем народную примету: если есть умножение, значит логарифм где-то рядом. Поигравшись получаем мартингал: $ M_{t}=\ln(X_{t})+t$. Применяем к нему теорему Дуба: $\E(\ln X_{T})+\E(T)=0$ .




Задача. Вариация на тему дней рождения.

Мы набираем людей по одному в группу до тех пор, пока в группе не будет хотя бы одного совпадающего дня рождения. Пусть $T$ количество людей, которое потребуется набрать. Найдите\footnote{величина $\E(T)$ является <<некрасивой>> в том смысле, что не целая и точное значение имеет громоздкую запись. Оказывается, что $\E(T)\approx 23$, но для в решении данной задачи это не используется} $\E(T^{2})-\E(T)$.

Решение через мартингалы. Каждый вступающий человек приходит в группу с количеством денег равным количеству людей уже вступивших в группу. Обяжем каждого вступающего человека сыграть с каждым уже вступившим в группу в такую лотерею: входящий ставит на кон 1 рубль, если их дни рождения совпадают, то входящий получает 365 рублей, если нет, то входящий теряет рубль (деньги платит и получает устроитель, существующие члены группы ничего не платят и не получают). Пусть $X_{t}$ - чистый выигрыш всех участников после вступления в группу $t$ человек. Поскольку каждая лотерея по отдельности справедлива, то $X_{t}$ - мартингал.

Момент остановки $T$ ограничен сверху, $T\leq 365$. Применяя пункт (i) теоремы Дуба получаем, что $\E(X_{T})=\E(X_{1})$. При этом $\E(X_{1})=0$, а $X_{T}=365-(1+2+...+(T-1))=365-\frac{T(T-1)}{2}$. И $\E(T^{2}-T)=2\cdot 365$.

Задача. Улитка отдыхает (симметричное блуждание), \cite{blom:pspt}
% r-in-advance game, Blom, Problems and Spanshots from probability theory

Улитка начинает свой путь в точке 0 и за каждую минуту равновероятно смещается влево или вправо на один сантиметр или отдыхает никуда не перемещаясь. Влево (и вправо) улитка ползет с одинаковой вероятностью $p$, отдыхает - с вероятностью $(1-2p)$.

Справа от улитки на расстоянии $a$ находится виноградное дерево, слева на расстоянии $b$ - шелковица.

Какова вероятность того, что улитка доползет до виноградного дерева раньше? Сколько в среднем времени ей потребуется чтобы доползти до любого из деревьев?



Задача. Улитка отдыхает (несимметричное блуждание), \cite{blom:pspt}
% r-in-advance game, Blom, Problems and Spanshots from probability theory

Улитка начинает свой путь в точке 0 и за каждую минуту смещается влево или вправо на один сантиметр или отдыхает никуда не перемещаясь. Влево улитка ползет с вероятностью $p_{l}$, вправо - с вероятностью $p_{r}$, отдыхает - с вероятностью $(1-p_{l}-p_{r})$.

Справа от улитки на расстоянии $a$ находится виноградное дерево, слева на расстоянии $b$ - шелковица.

Какова вероятность того, что улитка доползет до виноградного дерева раньше? Сколько в среднем времени ей потребуется чтобы доползти до любого из деревьев?

Задача. Ждем 1 рубль.

Найдите $\E(T)$


Задача. Войны Добра и Зла \cite{stirzaker:otep}, 12-13

Изначально воюют один воин Добра и один воин Зла. Судьба выбирает одного из воюющих наугад и добавляет еще одного воина той же стороны. Пусть $T$ - время, когда Судьба впервые добавит война Добра. Найдите $\E(\frac{T}{T+2})$


Войны Добра и Зла. (Взято из  Kingman, Martingales in the OK Corral)

На одном холме выстроились $d$ войнов Добра, а на другом - столько же войнов Зла. Обычные стрелы не долетают, слишком велико расстояние. Но каждый день Судьба выбирает одного из всех войнов наугад и вкладывает в его колчан Золотую Стрелу. Золотая стрела бьет без промаха. Великая Битва длится покуда одна из сторон не будет полностью побеждена. Пусть случайная величина $S$ - количество выживших в этой Битве. Обозначим, $X_{t}$ и $Y_{t}$ - количество войнов Добра и Зла в конце дня $t$.  Разберитесь с асимптотикой $\E(S^{4})$ при $d\to\infty$. Подсказка: может быть найдется функция $f$ такая, что $f(X_{t},Y_{t})$ - мартингал?

Решение.

Из того, что $f(X_{t},Y_{t})$ - мартингал получаем:
\begin{equation}
f(m,n)=\frac{n}{n+m}f(m-1,n)+\frac{m}{n+m}f(m,n-1)
\end{equation}

У этого уравнения куча решений, поищем чего-нибудь простое... Попробуем многочлены невысокой степени... Находим, $f(m,n)=(m+0.5)^{2}-(n+0.5)^{2}$, $f(m,n)=(m+n+1)(m+n+2)(m+n+3(m-n)^2)$, ...


Если применить теорему Дуба к первому получает $0=0$, вот ко второму уже интереснее... Итак, рассматриваем мартингал
\begin{equation}
M_{t}=(X_{t}+Y_{t}+1)(X_{t}+Y_{t}+2)(X_{t}+Y_{t}+3(X_{t}-Y_{t})^{2})=(2d-t+1)(2d-t+2)(2d-t+3(X_{t}-Y_{t})^{2})
\end{equation}

Применяем к нему теорему Дуба:

\begin{equation}
(2d+1)(2d+2)2d=M_{0}=\E(M_{\tau})=\E((S+1)(S+2)(S+3S^{2}))
\end{equation}

И мы получаем, что $\E(S^{4})\sim \frac{8}{3}d^{3}$.


Задача. Банковский счет улитки. \cite{stirzaker:prp}, 12.5

Перед отправкой в свой долгий путь улитка положила все свои сбережения (один рубль) в банк. За каждую минуту банк начисляет небольшой процент $r>0$, такой что $0<r<1/cos(\frac{\pi}{a+b})-1$. Какая сумма в среднем будет находится на счету улитки к моменту достижения ей любого из деревьев?

Задача. Сумма координат улитки. \cite{stirzaker:prp}, 12.7

Каждый раз проходя через точку с координатой $x$ улитка получает $x$ рублей. Каков суммарный заработок улитки?

% Какова средняя координата? - считается ли?

Задача. Улитка на плоскости.  \cite{stirzaker:otep}, 12-17





% Задача. Улитка на склоне. (???) - уже скучновато про улитку





% название файла с коллекцией названий статей/книг

% источники:
% Ross, Second course in probability
% Stirzaker, Probability and random processes
% Stirzaker, One thousand exercises in probability
% Williams, Probability with martingales
% Morters, Martingales
% Chang, Stochastic processes
% Blom, Problems and snapshots from probability theory
% Li, Martingale Approach to the Study of Occurrence of Sequence Patterns in  Repeated % Experiments
% Winkler, Games people don't play
% Zastawniak, Basic stochastic processes
% упр. 3.12 $(-1)^{\tau}=(-1)^{K}$ без всяких ожиданий!

% Shreve, Stochastic calculus for finance I - ??? (пока не включен, а что там было?)
% aops, keys
% wilmott, ts_t






\begin{myex}
Пусть $X_{1}=1$, а далее в каждый момент времени мы делаем шаг либо вправо, либо влево. Вероятности зависят от $n$ и равны $p_{n\to n+1}=\frac{(n+1)^{2}}{n^{2}+(n+1)^{2}}$ и  $p_{n\to n-1}=\frac{n^{2}}{n^{2}+(n+1)^{2}}$. Если процесс попадает в точку ноль, то происходит Большой Взрыв. Найдите какую-нибудь $f$, чтобы $f(X_{n})$ было мартингалом. А затем посчитайте вероятность того, что когда-нибудь будет Большой Взрыв.

Решение. Для начала уточним мы будем работать с <<остановленным>> процессом. Т.е. будем считать, что если $X_{n}$ достиг точки $0$, то он остается равным нулю навсегда. Поэтому величина $f(0)$ не имеет никакого значения - можем выбрать как хотим. Величина $f(1)$ влияет только на математическое ожидаемое мартингала. Давайте возьмем самые простые значения $f(0)=0$ и $f(1)=1$. Хотя можно было взять и другие. Если взять совсем тривиальные $f(0)=f(1)=0$, то тоже получится мартингал, но он будет скучным, $M_{n}:=0$.

Т.к. $f(X_{n})$ - это мартингал, то получаем следующее рекуррентное соотношение:
\begin{equation}
f(n)=p_{n\to n-1} f(n-1)+p_{n\to n+1} f(n+1)
\end{equation}

Из этого соотношения и из начальных условий получаем, $f(k)=\sum_{i=1}^{k}\frac{1}{i^{2}}$.

Чему равна вероятность когда-нибудь вернуться в 0? Давайте найдем вероятность достигнуть точки $0$ раньше, чем точки $n$, $\P(\tau_{0}<\tau_{n})$. Здесь $\tau_{i}$ - момент времени, когда впервые достигнута точка $i$, если точка $0$ оказалась достигнута раньше точки $i$ и процесс <<залип>> в нуле, то считаем, что $\tau_{i}=\infty$.

Для нахождения этой вероятности применим теорему Дуба. Получаем, что для любого $i$:
\begin{equation}
f(1)=M_{1}=\E(M_{1})=\E(M_{\tau_{i}})=\P(\tau_{i}<\tau_{0})f(n)+\P(\tau_{i}>\tau_{0})f(0)
\end{equation}

Проверка, что теорема Дуба работает...

Из этого уравнения находим, что $\P(\tau_{n}<\tau_{0})=\frac{f(1)-f(0)}{f(n)-f(0)}$

В связи с нашим выбором $f(0)=0$ и $f(1)=1$ получаем: $\P(\tau_{n}<\tau_{0})=\frac{1}{\sum_{i=1}^{n}\frac{1}{i^{2}}}$

Если большой взрыв происходит за конечное время, то какие-то точки на прямой остаются непосещенными. Значит событие $B=\{$Большой Взрыв когда-нибудь произойдет$\}$ можно представить в виде $B=\cap_{n=1}^{\infty}\{\tau_{n}<\tau_{0}\}$. Поскольку эта последовательность событий монотонна, то в силу непрерывности вероятности (...) получаем: $\P(B)=\lim_{n\to\infty}\P(\tau_{n}<\tau_{0})=\frac{1}{\sum_{i=1}^{\infty}\frac{1}{i^{2}}}$.

Как известно знатокам, $\sum_{i=1}^{\infty}\frac{1}{i^{2}}=\frac{\pi^{2}}{6}$, а кто не в курсе - читает вики \url{http://en.wikipedia.org/wiki/Basel_problem}. Следовательно,
$\P(B)=\frac{6}{\pi^{2}}$.

\end{myex}


\begin{myex}


\end{myex}




}\subsection{Мартингалы сходятся} \problemtext{

}\subsection{Еще задачи}

\section{Процессы в непрерывном времени} \problemtext{

Начиная с этой главы читателю предстоит бороться с дополнительной трудностью - с меняющимися обозначениями. Почему? Потому, что писать $X_{t}$ (значение процесса в момент времени $t$) проще, чем писать $X(t)$, но иногда приходится иметь дело с последовательностями процессов, и тогда удобнее будет обозначение $X_{n}(t)$.


}\subsection{Версии, непрерывность справа} \problemtext{


}\subsection{Гауссовские процессы} \problemtext{

Для определения гауссовоского процесса напомним, что такое многомерное нормальное распределение...


\input{gaussian.tex}





Гауссовский случайный процесс.
\begin{mydef} Случайный процесс $X_{t}$ называется гауссовским, если любой вектор $(X_{t_{1}},X_{t_{2}},...,X_{t_{k}})$ имеет многомерное нормальное распределение (возможно вырожденное).
\end{mydef}
Из определения ясно, что разные гауссовские процессы могут различаться математическим ожиданием, функцией $\mu(t)=\E(X_{t})$, и ковариационной функцией, $\gamma(s,t)=Cov(X_{t},X_{s})$. Важнее, конечно, ковариационная функция, т.к. простым преобразованием $Y_{t}=X_{t}-\E(X_{t})$ всегда можно добиться того, что математическое ожидание равно нулю.


}

\subsubsection*{Задачи}

\problem{ \label{geometric sense of correlation}
Пусть величины $X$ и $Y$ имеют совместное нормальное распределение с нулевым средним, единичной дисперсией и корреляцией $\rho$. \\
a) Представьте $Y$ в виде $Y=aX+bZ$, так, чтобы $Z\sim N(0;1)$, а $Z$ и $X$ не были бы коррелированы. \\
б) Что представляет собой множество $X>0\cap Y>0$ в осях $(X,Z)$? \\
в) Чему равна вероятность $\P(XY>0)$? \\
г) Постройте график $\P(XY>0)$ как функции от $\rho$ }
\solution{
a) $Y=\rho X+\sqrt{1-\rho^{2}} Z$ \\
б) Угол с градусной мерой $\theta=\pi/2+\arcsin(\rho)$ \\
в) $\P(XY>0)=\theta/\pi$ }

\problem{
Пусть величины $X$, $Y$, $Z$ - имеют совместное нормальное распределение, с математическим ожиданием $0$ и некоей ковариационной матрицей $B$. \\
Как зависит от $B$ вероятность $\P(XYZ>0)$?}
\solution{
Никак. Если рассмотреть величины $-X$, $-Y$, $-Z$, то у них такое же математическое ожидание и такая же ковариационная матрица. Значит $\P(XYZ>0)=\P((-X)(-Y)(-Z)>0)$. Но эти вероятности в сумме дают 1, значит они равны по 0.5. }




\subsection{Случайный процесс - это одна случайная величина} \problemtext{
\label{process_one_rv}


Буквально только что мы сказали, что случайный процесс - это набор случайных величин. Оказывается, что можно и иногда полезно рассматривать целый случайный процесс как \indef{одну} случайную величину. Вот как это можно сделать:

Для примера возьмем случайный процесс для $t\in[0;1]$. Случайным образом выберем траекторию, затем случайно (равномерно) выберем момент времени $t$. И вуаля, вместо целого процесса $X_{t}$ мы получили одну случайную величину $X$! При этом мы изменили пространство $\Omega$ на котором был задан случайный процесс $X_{t}$. А именно, новая случайная величина $X$ задана на множестве $\Omega'=\Omega\times [0;1]$. А вероятности считаются с помощью новой меры $P'=P\times \lambda$, где $\lambda$ - классическая мера Лебега, задающая равномерное распределение.

При такой интерпретации корректно говорить, например, о $P'(X<0.2)$ и о $\int_{\Omega'}XdP'=E'(X)$. Давайте попробуем на паре конкретных задач:

\begin{itemize}
\item Какой случайный процесс соответствует случайной величине $1_{\Omega'}$?

Очень просто! Для любого $w'=(w,t)$ значение $1_{\Omega'}(w')=1$, значит наш случайный процесс $X_{t}$ всегда равен 1 (на любой траектории и в любой момент времени).

\item Пусть $Y$ равномерная случайная величина на $[0;1]$, и $X_{t}=Y-t$, процесс определенный для $t\in[0;1]$. Нарисуйте несколько разных траекторий процесса $X_{t}$. Рассмотрев процесс как одну случайную величину, найдите $P'(X<0,2)$ и $E'(X)$.

Любая траектория начинается в точке $y\in[0;1]$ и с единичной скоростью убывает на отрезке $[0;1]$. Какова при заданном $y$ вероятность того, что выбрав случайную точку на отрезке $[0;1]$ мы получим ординату меньше 0,2? Если $y\leq 0.2$, то вероятность равна 1; если $y>0.2$, то вероятностью равна $(y-0,2)$. Находим искомую вероятность:
\begin{equation}
P'(X<0,2)=\P(Y<0.2)+\P(Y>0.2)\E(Y-0.2|Y>0.2)=0.2+0.8\cdot 0.4=0.52
\end{equation}

Переходим к $E'(X)$. При фиксированном $y\in[0;1]$ траектория с постоянной скоростью опускается с отметки $y$ до отметки $y-1$, поэтому при фиксированном $y$ средняя ордината равна $\frac{y+y-1}{2}=y-0.5$. Усредняя по $y$ получаем, что $E'(X)=\E(Y-0.5)=0$. Попутно отметим, что $E'(X)$ можно интерпретировать как среднюю площадь под траекторией процесса.
\end{itemize}

Если процесс задан на $[0;T]$ (или на $[0;\infty)$), то новая мера $P':=P\times\lambda$ не будет вероятностью (т.к. длина $\lambda([0;T])=T$). Но принципиально это ничего не меняет!

По прежнему можно будет считать выражения типа $P'(X<0.2)$. только это будет не <<вероятность>>, а <<средняя длина>> множества $X<0.2$. Для каждой отдельно взятой траектории (для каждого $w$) можно посчитать длину множества $\{t|X_{t}(w)<0.2\}$, а поскольку на $\Omega$ задана вероятность $P$, то интеграл означает среднее значение этой длины:

\begin{equation}
P'(X<0.2)=\int_{\Omega'}1_{X<0.2}dP'=\int_{\Omega}\int_{[0;T]}1_{X<0.2}d\lambda dP=\E(\lambda(X<0.2)),
\end{equation}
при раскрытии интеграла $\int_{\Omega'}(\cdot)dP'$ мы воспользовались теоремой Фубини.

Обозначение $E'(X)$ не совсем корректно (оно использовалось бы, если бы $P'$ была вероятностью). Осталось обозначение с интегралом $\int_{\Omega'}XdP'$. Сохранилась и интерпретация:  $\int_{\Omega'}XdP'$ - средняя площадь под траекторией процесса:

\begin{equation}
\int_{\Omega'}XdP'=\int_{\Omega}\int_{[0;T]}Xd\lambda dP=\E(\int_{[0;T]}Xd\lambda)
\end{equation}

Для усвоения еще пара примеров:  упр.

Единственное, что мы не проверили - это измеримость. За кадром должна быть некая \s-алгебра $\F'$, относительно которой функция $X$ должна быть измеримой. Какая же?

Процесс $X_{t}$ определен на пространстве $(\Omega,\F,P)$ и все случайные величины $X_{t}$ являются $\F$ измеримыми.  Может еще присутствовать фильтрация $\F_{t}$ и процесс $X_{t}$ может быть адаптирован к ней, но сейчас это не обязательно. Новое множество исходов, $\Omega':=\Omega\times [0;T]$ - это обычное декартово произведение, т.е. множество всех пар вида $(w,x)$, где $w\in\Omega$, $x\in [0;T]$. Естественная $\s$-алгебра событий на нем - это $\F\times\lambda$, минимальная \s-алгебра порожденная декартовым произведением \s-алгебр $\F$ и $\B$, $\F\times\B:=\s((F,B)|F\in\F,B\in\B)$. Эта же \s-алгебра $\F\times [0;T]$ является областью определения меры $P'=P\times\lambda$.

\begin{mydef} Процесс $X_{t}$ на пространстве $(\Omega,\F,P)$ для $t\in[0;T]$ (также и для $t\in[0;\infty)$) называется \indef{измеримым}, если функция $X$ измерима относительно $\s$-алгебры $\F\times \B$.
\end{mydef}

Зачем нам важна измеримость функции $X$ относительно $\F\times\B$? Именно это условие является позволяет интегрировать и получать <<хороший>> результат:

\begin{myth} Если функция $X$ измерима относительно $\F\times\lambda$, то для любого $t\in [0;T]$ интеграл $$Y_{t}=\int_{0}^{t}X_{t}d\lambda$$ корректно определен и является $\F$-измеримой случайной величиной.
\end{myth}
\begin{proof}
\end{proof}

Сформулируйте и докажите теорему (...) для случая $t\in[0;\infty)$ (упр.)

Иногда оказывается желательным, чтобы $Y_{t}=\int_{0}^{t}X_{t}d\lambda$ был не только $\F$-измерим, но и $\F_{t}$-измерим. Это требует более сильных условий на $X_{t}$:

\begin{mydef} Процесс $X_{t}$ на пространстве $(\Omega,\{\F_{t}\},\F,P)$ для $t\in[0;T]$ (также и для $t\in[0;\infty)$) называется \indef{прогрессивно измеримым}, если для любого $t\in[0;T]$ (или, соответственно, $t\in[0;\infty)$) случайная величина $X$ измерима относительно $\s$-алгебры $\F_{t}\times \B$.
\end{mydef}
\begin{myth} Если процесс $X_{t}$ прогрессивно измерим на $(\Omega,\{\F_{t}\},\F,P)$, то интеграл $$Y_{t}=\int_{0}^{t}X_{t}d\lambda$$ корректно определен и является $\F_{t}$-измеримой случайной величиной.
\end{myth}
\begin{proof} Зафиксируем момент времени $t$, в качестве $\F$ берем $\F_{t}$ и получаем желаемое в силу теоремы (...)
\end{proof}

Оказывается, что связь между адаптированностью $X_{t}$ к фильтрации $\F_{t}$  и измеримостью $X$ относительно $\F\times\lambda$ нетривиальная. Этому и посвящены два следующих примера:

\begin{myex} Процесс $X_{t}$ адаптирован к $\F_{t}$, но случайная величина $X$ не измерима относительно $\F\times\B$.
\end{myex}


\begin{myex} Процесс $X_{t}$ не адаптирован к $\F_{t}$, но случайная величина $X$ измерима относительно $\F\times\B$.
\end{myex}

Общая картина выглядит так:



Если процесс $X_{t}$ <<хороший>>, то $X$ измерим даже если он не адаптирован:
\begin{myth}
Если каждая траектория процесса $X_{t}$ является непрерывной слева (или непрерывной справа), то процесс $X_{t}$ измерим.
\end{myth}
\begin{proof}

\end{proof}



Для любопытных приведем пример измеримого, но не прогрессивно измеримого процесса:



}\subsection{Еще задачи}

\section{Броуновское движение} \problemtext{
}\subsection{Определение} \problemtext{

Wiener process - Винеровский процесс

Wiener dog - такса

Дадим два определения броуновского движения. \par
C $\sigma$-алгебрами. \par
\begin{mydef}
Случайный процесс $W_{t}$ - броуновское движение по отношению к фильтрации $\mathcal{F}_{t}$ если: \par
1. $W_{0}=0$ \par
2. $W_{t}-W_{s}\sim N(0;t-s)$ при $t>s$ \par
3. $W_{t}-W_{s}$ не зависит от $\mathcal{F}_{s}$ при $t>s$ \par
4. Траектория $W_{t}$ непрерывна с вероятностью 1. \par
5. $W_{t}$ адаптирован к $\mathcal{F}_{t}$ \par
\end{mydef}

\begin{mydef}
Случайный процесс $W_{t}$ - броуновское движение если: \par
1. $W_{0}=0$ \par
2. $W_{t}-W_{s}\sim N(0;t-s)$ при $t>s$ \par
3. $W_{t_{1}}-W_{t_{2}}$, $W_{t_{2}}-W_{t_{3}}$, ..., $W_{t_{n-1}}-W_{t_{n}}$ не зависимы \par
4. Траектория $W_{t}$ непрерывна с вероятностью 1. \par
\end{mydef}

Второе определение получается из первого если <<забыть>> про фильтрацию. \par
Первое определение получается из второго если <<добавить>> подходящую фильтрацию. Например, подходящей фильтрацией будет естественная $\mathcal{F}_{t}=\sigma(W_{s}, s\in[0;t])$ \par


}\subsection{Три преобразования} \problemtext{



}\subsection{Множество нулей}  \problemtext{

}\subsection{Непрерывное и недифференциируемое}  \problemtext{

Непрерывным броуновское движение является по определению. Оказывается, с вероятностью 1 траектория броуновского движения является нигде ни дифференциируемой. Интуиция довольно тонкая штука. С одной стороны, кажется что это невозможно: попробуйте нарисовать непрерывную нигде ни дифференциируемую линию! С другой стороны, с чего бы броуновскому движению быть дифференциируемым: берем произвольный момент времени $t_{0}$ и отступаем от него на $\Delta t$ вправо и влево. Два получаемых приращения, $(W(t_{0})-W(t_{0}-\Delta t))$ и $(W(t_{0}+\Delta t)-W(t_{0}))$, независимые случайные величины. А ведь для дифференциируемости они должны быть примерно равны при малом $\Delta t$!

}\subsection{Построения}  \problemtext{

}\subsection{Вариации} \problemtext{

Скорости у него нет, но бегает быстро...



}\subsection{Внимательно посмотрим на приращение} \problemtext{



Возьмем небольшой промежуток времени $\triangle t>0$.

И посмотрим на случайные величины $\triangle W$, $(\triangle W)^{2}$, $(\triangle W)^{3}$... в масштабе $\triangle t$.

$\E(\triangle W)=0$, $Var(\triangle W)=\triangle t$

$\E((\triangle W)^{2})=\triangle t$, $Var((\triangle W)^{2})=o(\triangle t)$

Для $k>2$:

$\E((\triangle W)^{k})=o(\triangle t)$, $Var((\triangle W)^{k})=o(\triangle t)$

Надо продумать тут интуицию


Почему нам важна малость дисперсии а не стандартного отклонения? Ведь (упрощенно говоря), множество значений случайной величины - это $[\mu-2\sigma;\mu+2\sigma]$? И согласно этой логике...

Дело в том, что мы будем работать только с суммами...


Мораль: если работать в масштабе $\triangle t$ при $\triangle t \approx 0$, то $\triangle W$ - это случайная величина с нулевым матожиданием, а $(\triangle W)^{2}$ - это константа равная $\triangle t$.
----
Хм... А как ответить на этот аргумент?:
На всякий случай напомним, что диапазон возможных значений примерно определяется с помощью стандартного отклонения и математического ожидания.

Пусть $\sigma$ и $\mu$ - это стандартное отклонение и мат. ожидание для $X$.

диапазон возможных значений не может быть уже, чем (...)

Неравенство Чебышева задает максимальную ширину диапазона <<частых>> значений $X$.

Например, если $d=3\sigma$, то по неравенству Чебышева $\P(X\in[\mu-3\sigma;\mu+3\sigma])\geq 8/9$.

Для наглядности мы на прямой покажем среднее значение плюс-минус три стандартных отклонения.

$\E(\triangle W)=0$, $\sqrt{Var()}=\sqrt{t}$....
----




}\subsection{Пространство Омега для броуновского движения}  \problemtext{

Многих интересует вопрос, можно ли как-то более наглядно предъявить какое-нибудь пространство $(\Omega,\F,\P)$, так чтобы на нем  было броуновское движение $W_{t}$?

Приведем два в каком-то смысле <<полярных>> примера, которые как-то проясняют ответ...

\begin{itemize}
\item Простые $\Omega$, $\F$, $\P$, но не очень явный $W_{t}$.

Берем в качестве $\Omega$ отрезок $[0;1]$, борелевскую \s-алгебру $\B[0;1]$ на этом отрезке и равномерную вероятность, <<длину>>, $\lambda$ в качестве меры $P$. Само броуновское движение строится не очень явно. Сначала строим последовательность $X_{n}$ независимых равномерно распределенных случайных величин. Ее мы строили (...). Затем преобразуем последовательность равномерных $X_{n}$ в последовательность нормальных и по-прежнему независимых $Z_{n}$. А на базе последовательности $Z_{n}$ строим броуновское движение. Способ указан!
\item Простое $\Omega$, $\F$, простой процесс $W_{t}$, но не очень явная $\P$.

Мы знаем, что траектории броуновского движения непрерывны, поэтому в качестве $\Omega$ возьмем множество непрерывных на $[0;\infty)$ функций. Обычно оно обозначается $C[0;\infty)$. Рассмотрим какую-нибудь метрику на этом пространстве. Например, в качестве расстояния между двумя непрерывными функциями можно взять $d(f,g)=\sup_{x\geq 0}|f(x)-g(x)|$. Эта метрика определяет открытые множества. А именно, $\varepsilon$-окрестность функции $f$ это все функции $g$, такие, что $d(f,g)<\varepsilon$. С помощью понятия открытого множества зададим борелевскую \s-алгебру - минимальную \s-алгебру порожденную открытыми множествами. Как определить $X_{t}(w)$? Поскольку $w$ - это готовая траектория, то $X_{t}(w):=w(t)$. А вот вероятность $P$ задается неявно. От этой вероятности нужно многого потребовать. Например, того, что $\P(w(10)<0)=0.5$. Ее полное описание совпадет с определением броуновского движения. Утешает лишь теорема (...), доказывающая, что такая вероятность существует.
\end{itemize}

}\subsection{На компьютере -?}  \problemtext{

}\subsection{Модель для игры в нарды}  \problemtext{

}\subsection{Еще задачи}

\problem{Пусть $W_{t}$ - винеровский процесс для $t\in [0;1]$. Определим новый процесс для $t\in [0;\infty)$ по формуле:
\begin{equation}
X_{t}=(1+t)\left(W_{(\frac{t}{1+t})}-\frac{tW_{1}}{1+t}\right)
\end{equation}
Верно ли, что $X_{t}$ - винеровский процесс?}
\solution{да}


\problem{Пусть $W_{t}$ - стандартное броуновское движение и момент остановки $\tau=\min\{t|W_{t}=1\}$. Найдите $\E(exp())$}
\solution{}

\problem{ Two questions on Brownian Motion:\par
1) A standard Brownian motion $Z_{t}$ starting at positon $a>0$. There is an absorbing boundary at $0$ - i.e. after $Z_{t}$ first hits zero at time $T_{0}$, $Z_{t}$ stays at zero for $t>T_{0}$. What is the probability that $Z_{t}$ is at zero at any arbitrary time $t$? \

2) Two independent standard Brownian motions $Z_{t}$ and $Z'_{t}$. $Z_{t}$ starts at position $a>0$, $z'_{t}$ starts at position $0$. $Z_{t}$ and $Z'_{t}$ are <<mutually absorbing>> - i.e. when $Z_{t}=Z'_{t}$ for the first time at $T_{0}$, they both stay at $Z_{T_{0}}=Z'_{T_{0}}$ for $t>T_{0}$. What is the probability that $Z_{t}=Z'_{t}$ at any arbitrary time $t$?}
\solution{
(check!)\par
Let $T_a = min{t>0:W_t = a}$. Using simple properties of B.M. you can easily show that $\P(T_a<T) = 2\P(W_T>a)$. That's all you need to solve both problems.\par
1. $2N(-a/sqrt(T))$\par
2. $2N(-a/sqrt(2T))$}



\section{Интеграл Ито и лемма Ито} \problemtext{

}\subsection{Интуиция и интеграл Ито для простых функций}  \problemtext{
Многие знают геометрический смысл обычного интеграла $\int_{0}^{t}f(x)dx$ - это площадь под кривой $f(x)$ на участке от $[0;t]$. Отдельные лица даже знают физический смысл обычного интеграла, $\int_{0}^{t}f(x)dx$ - это расстояние пройденной машиной за промежуток времени $[0;t]$, если она будет двигаться со скоростью $f(x)$.

А какой смысл можно придать  $\int_{0}^{t}q(x)dp(x)$? Многие студенты прекрасно считают интегралы такого типа. Вряд ли кто затруднится посчитать что-то типа $\int_{0}^{1}cos(x^{2})d(x^{2})$. Настала пора раскрыть экономический смысл интеграла! А именно: $\int_{0}^{T}q(t)dp(t)$ - это прибыль инвестора, если: \par
Цена акции в момент времени $t$ задается функцией $p(t)$ \par
Количество акций в момент времени $t$ на руках у инвестора задается функцией $q(t)$ \par

Ровно точно такой же смысл у интеграла-Ито. Интеграл $\int_{0}^{T}s(t)dW(t)$ - это чистая прибыль инвестора за период $[0;T]$, если в момент времени $t$ у него в наличии было $s(t)$ акций, которые стоили $W_{t}$. \par

Для возрастающих функций можно предложить еще одну геометрическую интерепретацию...
Площадь под линией $(p(t),q(t))$ - тут есть некоторая сложность $W(t)$ запросто может убывать, но эта мысль не повредит


Даже не зная формального определения, уже можно считать простейшие интегралы Ито. Единственное предостережение: функция $s$ предполагается непрерывной слева. Представить себе это можно так: в момент времени $t$, когда у меня на руках $s(t)$ акций я принимаю решение о покупке (продаже) и в любой момент времени $(t+\varepsilon)$ у меня уже новое количество акций, $s(t+\varepsilon)$. Новые акции я покупал (продавал) по цене $W_{t}$. При интегрировании по броуновскому движению можно было бы взять и $s(t)$ непрерывную справа - это ничего бы не изменило, т.к. броуновское движение непрерывно, однако при обобщении интеграла Ито в (...) это окажется важно.

\begin{myex} Например, Вася руководствуется следующей стратегией: купить в момент времени $t=0$ одну акцию, в момент времени $t=1$ докупить еще одну акцию, если они будут стоить меньше 5 рублей. Найдите его чистую прибыль к моменту времени $T=3$. В данном случае $s(t,W_{t})=\left\{ \right.$. Вася получит прибыль $W_{3}-W_{0}$ с первой акции и $W_{3}-W_{1}$ со второй акции (если он ее купит, т.е. если $W_{1}<5$), а значит $\int_{0}^{3}s(t,W_{t})dW(t)=(W_{3}-W_{0})+1_{W_{1}<5}(W_{3}-W{1})$.
\end{myex}

Если покупка-продажа акций идет непрерывно, то необходимо заменить ее на частую покупку-продажу и переходить к пределам. Для интеграла Ито используется предел в смысле $L^{2}$.

\begin{myex} Попробуем посчитать $\int_{0}^{T}WdW$, то есть в момент $t$ мы держим на руках столько акций, сколько они сейчас стоят.

Разобъем интервал $[0;T]$ на $n$ равных частей, посчитаем интеграл Ито, а затем устремим $n$ к бесконечности.
Обозначаем для краткости: $W_{i}=W(i\cdot \frac{T}{n})$ и $\Delta W_{i}=W_{i}-W_{i-1}$.

Сразу после момента времени $(i-1)\cdot \frac{T}{n}$ у нас на руках $W_{i-1}$ акций, а сразу после момента времени $i\cdot \frac{T}{n}$ должно быть $W_{i}$ акций. Значит в момент времени $t=i\cdot \frac{T}{n}$, когда акции стоят $W_{i}$ рублей, мы будет докупать $W_{i}-W_{i-1}$ акций. Таким образом после докупки у нас будет как раз $W_{i}$ акций. \par
В конце у нас будет $W_{n}$ акций и мы их продадим по $W_{n}$ рублей. \par
Наша прибыль составит выручка от продаж в конце минус расходы на все закупки: $W_{n}^{2}-\sum_{i=1}^{n}W_{i}\Delta W_{i}$ \par
Заметим, что $\sum_{i=1}^{n}(\Delta W_{i})^{2}=\sum_{i=1}^{n}(W_{i}^{2}+W_{i-1}^{2}-W_{i}W_{i-1}-W_{i}W_{i-1})=\sum_{i=1}^{n}(W_{i}^{2}+W_{i}^{2}-W_{i}W_{i-1}-W_{i}W_{i-1})-W_{n}^{2}=2\sum_{i=1}^{n}W_{i}\Delta W_{i}-W_{n}^{2}$ \par
Т.е. интересующую нас прибыль можно представить как $\frac{W_{n}^{2}}{2}-\frac{1}{2}\sum_{i=1}^{n}(\Delta W_{i})^{2}$ \par
В (...) мы доказали, что $\sum_{i=1}^{n}(\Delta W_{i})^{2}\to t$ в $L^{2}$ при $n\to\infty$ \par
А это значит, что $\int_{0}^{T}WdW=\frac{W(T)^{2}}{2}-\frac{t}{2}$ \par
\end{myex}


Вот стохастический анализ - это о том, как брать такие интегралы. И какими свойствами они обладают. Можно и такую аналогию провести. Обычный матанализ изучает функции, у которых существует производная, т.е. функции, локально похожие на прямую. Роль самой простой функции (<<прямой>>) в стохастическом анализе выполняет броуновское движение. Стохан изучает диффузии - случайные процессы локально похожие на броуновское движение.


Настала пора для формального определения. Мы построим интеграл Ито пошагово, как строили интеграл Лебега.

Наша цель - определить интеграл для достаточно широкого класса случайных процессов:

\begin{mydef} Пусть задано броуновское движение $W_{t}$ и $\F_{t}$ - его естественная фильтрация. Пусть $T$ - фиксированный момент времени. Обозначим с помощью $\mathcal{H}^{2}[0;T]$ множество процессов, удовлетворяющих трем условиям:

H1. Процесс $X_{t}$ адаптирован к фильтрации $\F_{t}$

H2. Процесс $X_{t}$ измерим

H3. $\E(\int_{0}^{T}X_{t}^{2}dt)<\infty$
\end{mydef}
Но начнем мы с более узкого класса, с \indef{простых} случайных процессов:

\begin{mydef} Пусть задано броуновское движение $W_{t}$ и $\F_{t}$ - его естественная фильтрация. Пусть $T$ - фиксированный момент времени. Назовем \indef{простыми} и обозначим с помощью $\mathcal{H}_{0}^{2}[0;T]$ множество процессов, удовлетворяющих условиям:

H01. Процесс $X_{t}\in\mathcal{H}^{2}[0;T]$

H02. Процесс $X_{t}$ представим в виде $X_{t}=\sum_{0}^{n-1}A_{i}1_{t\in(t_{i};t_{i+1}]}$, где $t_{i}$ - константы, удовлетворяющие условию $0=t_{0}<t_{1}<...<t_{n}=T$, а $A_{i}$ - $\F_{t_{i}}$-измеримые случайные величины.
\end{mydef}
\begin{myex}
\end{myex}


Комментарий: из H02 всегда следует H1, H2(?).

\begin{mydef} Для \indef{простых} процессов назовем \indef{интегралом Ито} случайную величину, определяемую по формуле:

$\int_{0}^{T}X_{t}dW_{t}:=\sum_{i=0}^{n-1}A_{i}(W(t_{i})-W(t_{i}))$.
\end{mydef}
Строго говоря, нужно убедиться, что определение корректно, а именно, что если один и тот же простой процесс имеет два разных представления, то использование любого из них приводит к одному и тому же результату. Это небольшое упражнение (...)

\begin{myth} Для простых случайных процессов интеграл Ито обладает свойствами:

PH01. $\int_{0}^{T}aX_{t}dW_{t}=a\int_{0}^{T}X_{t}dW_{t}$.

PH02. $\int_{0}^{T}(X_{t}+Y_{t})dW_{t}=\int_{0}^{T}X_{t}dW_{t}+\int_{0}^{T}Y_{t}dW_{t}$.

PH03. Изометрия Ито. $E\left((\int_{0}^{T}X_{t}dW_{t})^{2}\right)=E\int_{0}^{T}X_{t}^{2}dt$
\end{myth}
В доказательствах мы для краткости будем использовать обозначение $I(X(t))$ вместо $\int_{0}^{T}X(t)dW(t)$.

\begin{proof}
PH01. Сравнив обе части выражения видим, что они равны:

Левая: $\int_{0}^{T}aX_{t}dW_{t}=\sum_{i=0}^{n-1}aA_{i}(W(t_{i+1})-W(t_{i}))$.

Правая: $a\int_{0}^{T}X_{t}dW_{t}=a\sum_{i=0}^{n-1}A_{i}(W(t_{i+1})-W(t_{i}))$.

PH02. Как-то тавтологично даже. Возьмем  $0=t_{0}<t_{1}<...<t_{n}=T$, с помощью которого можно представить оба процесса. Заметим, что если $X_{t}$ представим в виде $X_{t}=\sum_{i=0}^{n-1}A_{i}1_{t\in(t_{i};t_{i+1}]}$, а $Y_{t}$ представим в виде $Y_{t}=\sum_{i=0}^{n-1}B_{i}1_{t\in(t_{i};t_{i+1}]}$, то процесс $X_{t}+Y_{t}$ представим в виде: $\sum_{i=0}^{n-1}(A_{i}+B_{i})1_{t\in(t_{i};t_{i+1}]}$. А теперь сравним:

Левая: $\sum_{i=0}^{n-1}(A_{i}+B_{i})(W(t_{i+1})-W(t_{i}))$

Правая: $\sum_{i=0}^{n-1}A_{i}(W(t_{i+1})-W(t_{i}))+\sum_{i=0}^{n-1}B_{i}(W(t_{i+1})-W(t_{i}))$

PH03. Снова сравним обе части:

Левая. Шаг 1. $(\int_{0}^{T}X_{t}dW_{t})^{2}=\sum_{i,j}A_{i}A_{j}(W(t_{i+1})-W(t_{i}))(W(t_{j+1})-W(t_{j}))$. Если взять $i\neq j$, например, $i<j$, то сомножитель $(W(t_{j+1})-W(t_{j}))$ не зависит от остальных сомножителей. Остальные сомножители являются $\F_{t_{j}}$ - измеримыми, а $(W(t_{j+1})-W(t_{j}))$ не зависит \s-алгебры $\F_{t_{j}}$. Значит при $i\neq j$ ожидание $\E(A_{i}A_{j}(W(t_{i+1})-W(t_{i}))(W(t_{j+1})-W(t_{j})))=\E(...)\E(W(t_{j+1})-W(t_{j}))=(...)\cdot 0=0$.

Шаг 2. После шага 1 от всей суммы осталось только: $\sum_{i}A_{i}^{2}(W(t_{i+1})-W(t_{i}))^{2}$. Замечаем, что $A_{i}^{2}$ не зависит от $(W(t_{i+1})-W(t_{i}))^{2}$, т.к. $A_{i}^{2}$ - это $\F_{t_{i}}$-измеримая случайная величина. И, наконец, $\E((\int_{0}^{T}X_{t}dW_{t})^{2})=\E(\sum_{i}A_{i}^{2}(W(t_{i+1})-W(t_{i}))^{2})=\sum_{i}\E(A_{i}^{2})\E(W(t_{i+1})-W(t_{i}))^{2})=\sum_{i}\E(A_{i}^{2})(t_{i+1}-t_{i})$.

Правая. С правой проще. Заметив, что $X_{t}^{2}=\sum_{i=0}^{n-1}A_{i}^{2}1_{t\in(t_{i};t_{i+1}]}$ (при $i\neq j$ произведение индикаторов обнуляется), получаем, что $\E(\int_{0}^{T}X_{t}^{2}dt)=\sum_{i=0}^{n-1}\E(A_{i}^{2})(t_{i+1}-t_{i})$.
\end{proof}

}\subsection{Интеграл Ито для аш2} \problemtext{

Итак, интеграл Ито определен для процессов из $\mathcal{H}_{0}[0;T]$. Как расширить его на процессы из $\mathcal{H}[0;T]$?

Идея нового, более широкого, определения проста:

Каждый процесс $X(t)$ из $\mathcal{H}[0;T]$ является пределом некоей последовательности простых процессов из $\mathcal{H}_{0}[0;T]$. Для каждого простого процесса $X_{n}(t)$ интеграл Ито определен и является случайной величиной, обозначим ее $I_{n}$. Оказывается, что последовательность интегралов Ито $I_{n}$ всегда сходится в пространстве $L^{2}(\Omega)$ к некоторой случайной величине $I$. И этот предел $I$ не зависит от выбора последовательности простых процессов $X_{n}(t)$, сходящейся к $X(t)$. Этот предел $I$ мы и назовем интегралом Ито для процесса $X_{t}$.

Сразу следует заметить, что интеграл Ито определен как предел в смысле $L^{2}(\Omega)$, поэтому единственности в поточечном смысле мы гарантировать не сможем. Интеграл Ито в $\mathcal{H}^{2}[0;T]$ определен с точностью до множества меры нуль. Несколько случайных величины равных почти наверное могут представлять один и тот же интеграл Ито. теперь все утверждения касающиеся Интеграла Ито будут формулироваться с припиской <<почти наверное>>.


Формальное определение выглядит так:

\begin{mydef} Пусть $X(t)\in\mathcal{H}^{2}[0;T]$ и $X_{n}(t)$ произвольная последовательность простых процессов, сходящаяся к процессу $X(t)$ в $L^{2}(\Omega\times\R)$. Пусть последовательность случайных величин $I(X_{n}(t))$ сходится в $L^{2}(\Omega)$  к случайной величине $I$. Интегралом Ито случайного процесса $X(t)$ называется случайная величина $I$, обозначается она как $\int_{0}^{T}X(t)dW(t)$.
\end{mydef}
Корректность определения подкрепляют 3 <<кита>>:

\begin{myth} Множество $\mathcal{H}_{0}^{2}[0;T]$ плотно в $\mathcal{H}^{2}[0;T]$. Для любого процесса $X(t)\in\mathcal{H}^{2}$ существует последовательность $X_{n}(t)\in\mathcal{H}_{0}^{2}[0;T]$, такая что $||X_{n}(t)-X(t)||_{L^{2}(\Omega \times \R)}\to 0$.
\end{myth}
\begin{proof} Доказательство кита отложим до (...)
\end{proof}
\begin{myth} Если есть последовательность простых процессов $X_{n}(t)\in\mathcal{H}_{0}^{2}[0;T]$ сходится к процессу $X_{t}$, т.е. $||X_{n}(t)-X(t)||_{L^{2}(\Omega \times \R)}\to 0$, то последовательность $I_{n}=\int_{0}^{T}X_{t}^{(n)}dW_{t}$ сходится к некоторой случайной величине $I$ в $L^{2}(\Omega)$.
\end{myth}
\begin{proof} Шаг 1. Последовательность $(X_{n}(t)-X(t))$ сходится к нулю в $L^{2}(\Omega \times \R)$, значит $X_{n}(t)$ - это последовательность Коши. Действительно, $||X_{i}(t)-X_{j}(t)||=||X_{i}(t)-X(t)+X(t)-X_{j}(t)||\leq ||X_{i}(t)-X(t)||+||X(t)-X_{j}(t)||$. Для любого $\varepsilon>0$, можно выбрать такое $N$, начиная с которого, т.е. при $i>N$ и $j>N$ оба слагаемых будут меньше $\varepsilon/2$.

Шаг 2. Последовательность $X_{n}(t)$ - это последовательность Коши в $L^{2}(\Omega\times\R)$. В силу изометрии Ито последовательность $I_{n}=\int_{0}^{T}X_{n}(t)dW(t)$ также будет последовательностью Коши в $L^{2}(\Omega)$. Подробнее. Процесс $Z(t)=X_{i}(t)-X_{j}(t)$ является простым, поэтому $||Z(t)||_{L^{2}(\Omega \times \R)}=||\int_{0}^{T}Z(t)dW(t)||_{L^{2}(\Omega)}$. Кроме того, $\int_{0}^{T}Z(t)dW(t)=\int_{0}^{T}X_{i}(t)dW(t)-\int_{0}^{T}X_{j}(t)dW(t)=I_{i}-I_{j}$. Значит $||X_{i}(t)-X_{j}(t)||_{L^{2}(\Omega \times \R)}=||I_{i}-I_{j}||_{L^{2}(\Omega)}$.

Шаг 3. Пространство $L^{2}(\Omega)$ полное, поэтому любая последовательность Коши $I_{n}$ сходится к некоторой случайной величине $I$.
\end{proof}

\begin{myth} Если две различные последовательности процессов $X_{n}(t)$ и $Y_{n}(t)$ сходятся в $L^{2}(\Omega\times \R)$ к одному пределу $X(t)$, то и последовательность интегралов Ито, $I(X_{n}(t))$ и $I(Y_{n}(t))$ сходятся к одному пределу в $L^{2}(\Omega)$.
\end{myth}
\begin{proof} Шаг 1. Заметим, что разница $||X_{n}(t)-Y_{n}(t)||$ cходится к нулю в силу неравенства треугольника: $||X_{n}(t)-Y_{n}(t)||=||X_{n}(t)-X(t)+X(t)-Y_{n}(t)||\leq ||X_{n}(t)-X(t)||+||X(t)-Y_{n}(t)||$. В этой сумме каждое слагаемое стремится к нулю с ростом $n$.

Шаг 2. В силу изометрии Ито, $||X_{n}(t)-Y_{n}(t)||=||I(X_{n}(t)-I(Y_{n}(t))||_{L^{2}(\Omega)}$. Значит последовательность $||I(X_{n})-I(Y_{n})||$ стремится к нулю.

Шаг 3. В силу теоремы (...) последовательность $I(X_{n}(t))$ сходится к некоей случайной величине $I$. Используем неравенство треугольника еще раз, $||I(Y_{n}(t))-I||=||I(Y_{n}(t))-I(X_{n}(t))+I(X_{n}(t))-I||\leq ||I(Y_{n}(t))-I(X_{n}(t))||+||I(X_{n}(t))-I||$. Оба слагаемых стремятся к нулю, первое в силу шага 2, второе в силу сходимости $I(X_{n}(t))$. Значит $I(Y_{n}(t))$ стремится к той же случайной величине $I$.
\end{proof}

теперь интеграл Ито корректно определен для случайных величин из $\mathcal{H}^{2}[0;T]$! Попутно заметим, что для простых процессов новое определение совпадает со старым, т.к. в качестве последовательности сходящейся к простому процессу $X(t)$ можно взять последовательность $X(t)$, $X(t)$, $X(t)$,... Поэтому можно использовать одно и то же обозначение для интеграла Ито на $\mathcal{H}^{2}[0;T]$ и на $\mathcal{H}_{0}^{2}[0;T]$

Интеграл Ито снова обладает хорошими свойствами:

\begin{myth} Для случайных процессов из $\mathcal{H}^{2}[0;T]$ интеграл Ито обладает свойствами:

PH1. $\int_{0}^{T}aX(t)dW(t)=a\int_{0}^{T}X(t)dW(t)$ (почти наверное).

PH2. $\int_{0}^{T}(X_{t}+Y_{t})dW_{t}=\int_{0}^{T}X_{t}dW_{t}+\int_{0}^{T}Y_{t}dW_{t}$ (почти наверное).

PH3. Изометрия Ито. $E\left((\int_{0}^{T}X_{t}dW_{t})^{2}\right)=E\int_{0}^{T}X_{t}^{2}dt$

PH4. Условная изометрия Ито.
\end{myth}
\begin{proof}

PH1. Берем последовательность $X_{n}(t)$, сходящуюся к $X(t)$, автоматически оказывается, что $aX_{n}(t)$ сходится к $aX(t)$, обе сходимости, конечно, в $L^{2}(\Omega\times \R)$. Но для простых процессов свойство PH01 доказано, значит $I(aX_{n}(t))=aI(X_{n}(t))$. Последовательность $I(aX_{n}(t))$ сходится к $I(aX(t))$, а последовательность $aI(X_{n}(t))$ сходится к $aI(X(t))$, на этот раз обе сходимости в $L^{2}(\Omega)$. Значит $I(aX(t))$ и $aI(X(t))$ равны почти наверное.

PH2. Берем последовательность $X_{n}(t)$, сходящуюся в $L^{2}(\Omega\times\R)$ к процессу $X(t)$ и последовательность $Y_{n}(t)$, сходящуюся в $L^{2}(\Omega\times\R)$ к процессу $Y(t)$. Последовательность $X_{n}(t)+Y_{n}(t)$ будет сходится к $X(t)+Y(t)$. Для простых процессов свойство PH02 доказано, значит $I(X_{n}(t)+Y_{n}(t))=I(X_{n}(t))+I(Y_{n}(t))$. По определению, предел последовательности $I(X_{n}(t))$ равен $I(X(t))$, предел последовательности $I(Y_{n}(t))$ равен $I(Y(t))$, а предел последовательности $I(X_{n}(t)+Y_{n}(t))$ равен $I(X(t)+Y(t))$. Значит $I(X(t)+Y(t))=I(X(t))+I(Y(t))$.

PH3. Существует последовательность простых процессов $X_{n}(t)$, сходящаяся к $X(t)$. Применяем к каждому ее члену изометрию Ито (доказанную для простых процессов: $||X_{n}(t)||_{L^{2}(\Omega\times\R)}=||I(X_{n}(t))||_{L^{2}(\Omega)}$. Последовательность процессов $X_{n}(t)$ сходится в $L^{2}(\Omega\times\R)$ к $X(t)$, а значит $||X_{n}(t)||\to ||X(t)||$. Последовательность случайных величин $I(X_{n}(t))$ сходится в $L^{2}(\Omega)$ к $I(X(t))$, а значит $||I(X_{n}(t))||\to ||I(X(t))||$. И, следовательно, $||I(X(t))||=||X(t)||$.
\end{proof}

}\subsection{Интеграл Ито как процесс}\problemtext{


}\subsection{Ito's lemma}\problemtext{

Почему когда я происходил от обезьяны меня не предупредили, что придется учить доказательство леммы Ито?

Когда надо посчитать обычный интеграл типа $\int_{0}^{T}\cos(3x+7)dx$, никто не будет считать его как предел сумм. Обычно пользуются теоремой Ньютона-Лейбница, знанием производных основных функций и свойствами производной. Аналогично и в стохастическом анализе. В тех редких случаях когда стохастический интеграл можно посчитать в явном виде, для подсчета обычно хватает леммы Ито и понимание смысла краткой записи.

Лемма Ито в краткой записи:
\begin{myth}

\end{myth}

Лемма Ито в полной записи:
\begin{myth}

\end{myth}



}\subsection{Использование процесса Ито при моделировании }\problemtext{
Данный раздел списан с источника \cite{lones:dtc}

Допустим у нас есть некий процесс $Y_{t}$, поведение которого без случайных шоков описывается обыкновенным дифференциальным уравнением $dY=f(t,Y)dt$.

Для описания шоков предположим, что время поделено на маленькие отрезочки длины $1/n$. И на каждом отрезке может с вероятностью $O(1/n)$ произойти случайный шок, который превращает $Y_{t}$ в $(1+O(1/n))Y_{t}$.

Оказывается, что в этом случае процесс $Y_{t}$ хорошо описывается с помощью процесса Ито.

Рассмотрим пару конкретных примеров.

(lones)


(steele, exam)

\url{http://math.stackexchange.com/questions/284874/why-do-people-simulate-with-brownian-motion-instead-of-intuitive-brownian-motio}



\begin{mydef}
Процессом Ито называется случайный процесс представимый в виде:

\end{mydef}

Функция










}\subsection{Еще задачи}


Пусть $dX=udt+vdW$, где $u$ и $v$ - не обязательно константы. Пусть $Y_{t}=\int_{0}^{t}X_{a}da$. Найдите $dY_{t}$.
Ответ: $X_{t}dt$.


\section{Основные теоремы стохастического анализа по броуновскому движению}\problemtext{











}\subsection{Медвежья услуга}  \problemtext{
Инопланетяне давно уже прибыли на Землю. Они пытаются общаться с нами с помощью дорожных знаков, но инопланетян никто не понимает... \par

Условные обозначения, которые были призваны упростить запись, оказались дополнительным барьером для понимания стохастического анализа. Например, часто используется обозначение типа $\E(dW)=0$. Проблема в том, что $dW$ - не существует! Это сбивает с толку тех, кто только начинает осваивать стохастический анализ. Несмотря на неудачные условные обозначения, книга может быть очень удачной, поэтому приведем полезный <<словарь>>: \par
$dX=a(t,X)dt+b(t,X)dW$ $X_{T}=X_{0}+\int_{0}^{T}a(t,X)dt+\int_{0}^{T}b(t,X)dW$ \par
$\E(b(t,X)dW)=0$ $\E(\int_{0}^{T}b(t,X)dW)=0$, если ... \par
$\E(dW)=0$ $\E(\Delta W)=0$ \par
$Var(b(t,X)dW)=b^{2}(t,X)dt$ $Var(\int_{0}^{T}b(t,X)dW)=\int_{0}^{T}\E(b^{2}(t,X))dt$ \par
$Var(dW)=dt$ $Var(\Delta W)=\Delta t$ \par



$dW\cdot dW=dt$,
$dt\cdot d($неважно что$)=0$ способ запомнить формулу Ито \par


Мы говорим Ленин,
                 подразумеваем -
                                 партия,
мы говорим
           партия,
                  подразумеваем -
                                 Ленин.
В.В. Маяковский. Владимир Ильич Ленин.

Вот так мы уже пятьдесят лет говорим одно, а подразумеваем совсем другое. (анекдот) \par

Вот потому, что вы говорите то, что не думаете и думаете то, что не думаете, вот в клетках и сидите. И вообще, весь этот горький катаклизм, который я тут наблюдаю... и Владимир Николаич тоже... (Скрипач, Кин-дза-дза) \par



}\subsection{теорема Гирсанова} \problemtext{

Простейшая версия теоремы Гирсанова формулируется

\begin{myth}
Если $W_t$ --- винеровский процесс относительно вероятности $\P$ и $\tilde{W}_t=\alpha t + W_t$, то существует вероятность $\tilde{\P}$,  относительно которой процесс $\tilde{W}_t$ будет винеровским.
\end{myth}



Более сложные версии теоремы Гирсанова


}\subsection{Martinale representation theorem} \problemtext{


}\subsection{Feynman-Kac} \problemtext{
Иногда теория вероятностей помогает решать задачи из других областей математики. Например, позволяет находить решения детерминистических дифференциальных уравнений.

\begin{myth} Пусть $q:\R\to\R$, $f:\R\to\R$ две ограниченные функции. Решение уравнения $\frac{\partial u(t,x)}{\partial t}=\frac{1}{2}\frac{\partial^{2}u(t,x)}{\partial x^{2}}+q(x)u(t,x)$ с начальным условием $u(0,x)=f(x)$ является единственным и его можно представить в виде $u(t,x)=\E(f(x+W_{t})\exp(\int_{0}^{t}q(x+W_{s})ds))$.
\end{myth}
До доказательства рассмотрим пару примеров. (...)

\begin{proof} Шаг 1. Применим лемму Ито к функции $f(s,y):=u(t-s,x+y)$:

$df(s,W_{s})=(-u_{1}(t-s,x+W_{s})+\frac{1}{2}u_{22}(t-s,x+W_{s}))ds+u_{2}(t-s,x+W_{s})dW_{s}$.

Шаг 2. Функция $u$ удовлетворяет исходному детерминистическому дифференциальному уравнению, поэтому:

$df(s,W_{s})=-q(x+W_{s})u(t-s,x+W_{s})ds+u_{2}(t-s,x+W_{s})dW_{s}$.

Шаг 3. Применим лемму Ито к случайному процессу $M_{s}:=u(t-s,x+W_{s})\exp(\int_{0}^{s}q(x+W_{v})dv)$:

Процесс $M_{s}$ является произведением, поэтому полезно вспомнить упражнение (...), в котором мы доказали, что $d(XY)=(dX)Y+(dY)X+dXdY$.

\begin{multline}
dM_{s}=df\cdot \exp(\int_{0}^{s}q(x+W_{v})dv) +f\cdot d(\exp(\int_{0}^{s}q(x+W_{v})dv))+df\cdot d(\exp(\int_{0}^{s}q(x+W_{v})dv))=\\
=-q(x+W_{s})u(t-s,x+W_{s})\exp(\int_{0}^{s}q(x+W_{v})dv)ds+u_{2}(t-s,x+W_{s})\exp(\int_{0}^{s}q(x+W_{v})dv)dW_{s}+fq(x+W_{s})\exp(\int_{0}^{s}q(x+W_{v})dv)ds=\\
=u_{2}(t-s,x+W_{s})\exp(\int_{0}^{s}q(x+W_{v})dv)dW_{s}
\end{multline}

Шаг 4. Значит $M_{v}=M_{0}+\int_{0}^{v}u_{2}(t-s,x+W_{s})\exp(\int_{0}^{s}q(x+W_{v})dv)dW_{s}$, и $M_{v}$ является мартингалом.

Шаг 5. По построению, $M_{0}=u(t,x)$ - неслучайная функция, $M_{0}=\E(M_{0})$. В силу того, что $M_{v}$ - мартингал, $\E(M_{0})=\E(M_{t})$. Откуда и следует утверждение теоремы:

$u(t,x)=\E(f(x+W_{t})\exp(\int_{0}^{t}q(x+W_{s})ds))$.
\end{proof}
(откуда следует единственность?)

Изложить по Steele!!!!

Взять примеры из Bjork!

\url{http://galton.uchicago.edu/~lalley/Courses/391/Lecture12.pdf}



}\subsection{Еще задачи}

\section{Стохастические уравнения} \problemtext{
Нам важно четко ответить на несколько вопросов:

Что такое стохастическое дифференциальное уравнение?

Что мы подразумеваем под решением?

Какие методы решения есть? Какие есть самые простые виды уравнений?

Существует ли решение и единственно ли оно?

Итак, по порядку.
}\subsection{Определение и виды решений} \problemtext{

\begin{mydef} Уравнение вида $dX_{t}=\mu(t,X_{t})dt+\sigma(t,X_{t})dW_{t}$ называется \indef{стохастическим дифференциальным уравнением}.
\end{mydef}
Естественно, это уравнение не более чем сокращенная запись и полное определение выглядело бы так:

\begin{mydef} Уравнение вида $X_{t}=x_{0}+\int_{0}^{t}\mu(s,X_{s})ds+\int_{0}^{t}\sigma(s,X_{s})dW_{s}$ называется \indef{стохастическим дифференциальным уравнением}.
\end{mydef}
Решения бывают двух типов, сильные и слабые. Если помимо уравнения (...) также заданы и броуновское движение, и фильтрация и нужно найти процесс $X_{t}$, который был бы функцией заданного броуновского движения и адаптирован (прогрессивно измерим и т.д.) к данной фильтрации, то речь идет о поиске сильного решения. Если задано только уравнение (...) и в качестве решения можно предъявить любое броуновское движение и любой $X_{t}$ связанный с ним уравнением (...), то речь идет о слабом решении.

\begin{mydef} Процесс $X_{t}$ называется ...
\end{mydef}
\begin{mydef} Процесс $X_{t}$ называется ...
\end{mydef}
Из этих двух определений непосредственно следует теорема

\begin{myth} Если существует сильное решение стохастического дифференциального уравнения, то существует и слабое решение.
\end{myth}
Можно продемонстрировать ситуации, когда слабое решение существует, а сильное - нет.

\begin{myex} ...
\end{myex}


}\subsection{Простые СДУ и аналитические методы решения} \problemtext{



Несколько идей, которые могут помочь решить СДУ в явном виде.

\begin{itemize}


\item Домножение на некоторую функцию. $Y=f(t,W)\cdot X$. Например, если в уравнении есть кусок вида $dX=(aX+...)dt+(...)dW$, то может помочь замена $Y=e^{-at}X$.

\item Поиск решения простого вида. $Y=f(t)g(W)$.

\item Замена $Y'=f(Y)$.
\begin{myex}
Иногда $f$ можно просто угадать...
\end{myex}

\begin{myex}
Функцию $f$ можно искать специально, чтобы сделать постоянным коэффициент при $dW$.
\end{myex}


\item Сначала решить детерминистическое уравнение. $dY=(...)dt$. Это может навести на хорошую замену.






\end{itemize}







}\subsection{Численные методы решения СДУ} \problemtext{


}\subsection{Существование и единственность} \problemtext{



}\section{Простые модели опционов} \problemtext{
Для всех рассматриваемых моделей мы будем предполагать постоянную процентную ставку $r$, наличие двух оригинальных ценных бумаг: акций с ценой $S_{t}$ в момент времени $t$ и облигаций с ценой $B_{t}$ в момент времени $t$.

}\subsection{Binomial model} \problemtext{

Время дискретно, $t\in\{0,1,2,...\}$.

...


Если <<правильным>> образом взять предел дискретной модели, то можно получить те же результаты, что и в непрерывном случае.

В дискретной модели время исполнения опциона и количество шагов - это одно и то же. При переходе к пределу нужно разделить эти два понятия. Время исполнения опциона нужно приравнять к константе $T$, а число шагов $n$ устремить к бесконечности.




}\subsection{Портфель в непрерывном времени} \problemtext{
Для того, чтобы описать портфель ценных бумаг, необходимо указать в каком количестве входит в портфель каждая ценная бумага. Портфель $V$ будет состоять из двух ценных бумаг, акций в количестве $X$ и облигаций в количестве $Y$. т.е. стоимость портфеля будет равна $V_{t}=X_{t}S_{t}+B_{t}Y_{t}$. При этом количество ценных бумаг в портфеле, конечно, может зависеть от их прошлых цен, но не может <<заглядывать>> вперед, т.е. есть процессы $X_{t}$ и $Y_{t}$ должны быть предсказуемыми. Формально,

\begin{mydef} Портфель $(X,Y)$ - это набор из двух предсказуемых процессов, $X_{t}$ и $Y_{t}$.
\end{mydef}
Более того: дядюшки, который нам оставил бы наследство у нас нет, поэтому кроме как из самого портфеля денег на покупку ценных бумаг нам взять неоткуда. Портфель должен финансировать сам себя!

\begin{mydef} Портфель $(X,Y)$ называется \indef{self-financing}, если $dV=X_{t}dS_{t}+Y_{t}dB_{t}$
\end{mydef}
}\subsection{Модель Блэка-Шоулса} \problemtext{


Предпосылки:
\begin{enumerate}
\item Время непрерывно
\item Есть два актива, акции и облигации
\item Активы можно покупать в дробном количестве
\item Стоимость акций, $S_{t}=S_{0}\exp((\mu-\frac{\sigma^{2}}{2})t+\sigma W_{t})$
\item Стоимость облигаций, $B_{t}=\exp(rt)$
\item Трансакционные издержки отсутствуют
\end{enumerate}


Факт 1.
\[
dS_t=\mu S_t \, dt + \sigma S_t \, dW_t
\]

Факт 2. Если $A_t$ --- количество акций на руках, а $X_t$ --- стоимость портфеля из акций и облигаций, то $(X_t - A_t S_t)/B_t$ --- количество облигаций.
\[
dX_t = A_t \, dS_t + (X_t - A_t S_t)/B_t \, dB_t
\]

Факт 3. Существует портфель, реплицирующий опцион.

\[
d(e^{-rt}X_t)= \ldots = (\ldots) \left( \frac{\mu - r}{\sigma } t + W_t  \right)
\]

Из предположения о невозможности арбитража следует, что текущая цена актива должна равняться текущей цене реплицирующего портфеля.

Сделаем замену $\tilde{W}_t=\frac{\mu - r}{\sigma } t + W_t$. При этом $d\tilde{W}_t = \frac{\mu - r}{\sigma } dt + dW_t$.

Значит
\[
d(e^{-rt}X_t)= (\ldots) d\tW_t
\]


Теорема Гирсанова.

По теореме Гирсанова существует вероятность $\tP$, относительно которой процесс $\tilde{W}_t=at + W_t$ будет винеровским процессом.

Здесь $\tilde{W}_t=\frac{\mu-r}{\sigma}t + W_t$


Относительно вероятности $\tP$ процесс $e^{-rt}X_t$ будет мартингалом, и, следовательно,

\[
X_0=\E_{\tP}(e^{-rT}X_T)=e^{-rT}\E_{\tP}(X_T)
\]


Примеры подсчета стоимости активов.

Как реплицировать? pde...

}\subsection{Модель Луи Башелье} \problemtext{

Время непрерывно. Есть два актива, которые можно покупать в любом (даже в отрицательном количестве):

Наличные деньги (на них процент не начисляется), стоимость $B_{t}=1$.

Акции, стоимость $S_{t}=S_{0}+\sigma W_{t}$.

}\subsection{Еще задачи}




%\part{<<И все это будет, но только потом, когда я чуть-чуть расквитаюсь с делами>>:}


%\section{Обобщение интеграла Ито}
%\subsection{Локальные мартингалы}
%\section{Пуассоновский процесс}
%\section{Стохастический анализ с прыжками!}
%\section{Бесконечно малые в защиту dW}
%\section{Оптимизация в непрерывном времени}
%\subsection{Как проверить готовое решение?}
%\subsection{HJB}
%\subsection{Smooth pasting}
%\section{Анализ Маллявина}


%%%%%%%%%%%%%%%%%%%%%%%%%%%









\section{Приложения} \problemtext{

}\subsection{Напоминалка по мат. анализу} \problemtext{

А может мы ее вперед вынесем вместе с бесконечностями...



}\subsection{Доказательство теоремы Каратеодори} \problemtext{

\begin{myth}
Вероятность $\mathbf{P}$, заданная на алгебре может быть
продолжена до вероятности $\mathbf{P^{*}}$, определенной на
$\sigma$-алгебре $\mathcal{U}$, содержащей алгебру $\mathcal{A}$.
Это продолжение единственно.
\end{myth}

Заметим, что указанная $\sigma$-алгебра $\mathcal{U}$ окажется
пополнением $\sigma(\mathcal{A})$.

Доказательство мы проведем в три этапа и, как оказалось, в две
лекции.

1. Для произвольного подмножества $A \subset \Omega$ определим
внешнюю меру $\mathbf{P^{*}}(A)$. Эта внешняя мера будет обладать
рядом неплохих свойств.

2. Набор таких подмножеств, где $\mathbf{P^{*}}$ обладает очень
хорошими свойствами (а именно, всеми свойствами вероятности)
окажется $\sigma$-алгеброй $\mathcal{U}$.

3. Любая другая вероятность на $\mathcal{U}$ совпадет
$\mathbf{P^{*}}$.


Для определения внешней меры нам потребуется понятие инфинума.
Инфинум следует понимать как минимум в тех ситуациях, когда сам
минимум не достижим. Пример. Пусть $x\in (0;1]$. Чему равен
минимальный $x$? Хотелось бы сказать нулю, но нельзя, потому, что
ноль - выколотая точка. Так вот в этом примере инфинум равен нулю.
Ниже следует формальное определение.

Пусть $A\subset \mathbb{R}$. Число $x\in\mathbb{R}$ называется
\emph{инфинумом} множества $A$, если $\forall a \in A \Rightarrow
x\leq a$ и в любой $\varepsilon$-окрестности точки $x$ найдется
хотя бы одна точка из множества $A$.

Если множество $A$ не ограничено снизу, то инфинум (равно как и
минимума) не будет.

Упражнение. Дайте формальное определение супремума - аналога
максимума.

Вернемся к определению внешней меры $\mathbf{P^{*}}$.

Рассмотрим произвольное множество $A \subset \Omega$. Накроем
множество $A$ набором попарно непересекающихся множеств из
алгебры.

Все наборы множеств $\{A_{i}\}$, накрывающие $A$ и принадлежащие
алгебре, будем обозначать символом $\gamma(A)$.

Для произвольного $A$ определим
$\mathbf{P^{*}}(A)=inf_{\{A_{i}\}\in
\gamma(A)}(\sum_{i}\mathbf{P}(A_{i}))$.

Внешняя мера (external measure) $\mathbf{P^{*}}$ обладает
свойствами:

EM1. Если $A\subset B$, то $\mathbf{P^{*}}(A)\leq
\mathbf{P^{*}}(B)\leq 1$.

EM2. Если $A_{i}\in \mathcal{A}$ и попарно не пересекаются, то
$\mathbf{P^{*}}(\bigcup_{i}A_{i})=\sum_{i}\mathbf{P}(A_{i})$.

EM3.
$\mathbf{P^{*}}(\bigcup_{i}A_{i})\leq\sum_{i}\mathbf{P^{*}}(A_{i})$


Доказательство EM1 остается в качестве упражнения.

Перейдем к доказательству EM2. Итак, $A=\bigcup_{i}A_{i}$, где
$A_{i}$ попарно не пересекаются и лежат в алгебре.

Во-первых, докажем, что
$\mathbf{P^{*}}(A)\geq\sum_{i}\mathbf{P}(A_{i})$.

Для этого рассмотрим произвольную последовательность $\{C_{i}\}$,
накрывающую $A$.

Из того, что последовательность $\{C_{i}\}$ накрывает $A$,
следует, что $\bigcup_{m}(A_{i}\bigcap C_{m})=A_{i}$.

Далее Суворов переходит через Альпы с комментариями:

$$
\sum_{i}\mathbf{P}(A_{i})=
\sum_{i}\mathbf{P}(\bigcup_{m}(A_{i}\bigcap C_{m}))
$$
В силу того, что $C_{m}$ не пересекаются:
$$
\sum_{i}\mathbf{P}(\bigcup_{m}(A_{i}\bigcap C_{m}))
=\sum_{i}\sum_{m}\mathbf{P}( A_{i}\bigcap C_{m} )
$$
В силу первого свойства внешней меры $\mathbf{P^{*}}$ этот ряд
сходится и значки сумм можно переставлять:
$$
\sum_{i}\sum_{m}\mathbf{P}( A_{i}\bigcap C_{m} )
=\sum_{m}\sum_{i}\mathbf{P}( A_{i}\bigcap C_{m} )
$$
Поскольку для любого $n$ выполнено $\bigcup_{i=1}^{n} (
A_{i}\bigcap C_{m} ) \subset C_{m}$, и объединяемые множества
попарно не пересекаются, то для любого $n$ будет верно неравенство
$\sum_{i=1}^{n}\mathbf{P} ( A_{i}\bigcap C_{m} ) \leq \mathbf{P}
(C_{m} )$. Если неравенство верно для произвольного $n$, то оно
верно и для соответствующего предела
$\sum_{i=1}^{\infty}\mathbf{P} ( A_{i}\bigcap C_{m} ) \leq
\mathbf{P} (C_{m} )$. Получаем решающий переход:
$$
\sum_{m}\sum_{i}\mathbf{P}( A_{i}\bigcap C_{m} )
 \leq \sum_{m} \mathbf{P} (C_{m} )
$$
Выходит, что каким бы ни было накрытие $\{C_{m}\}$ множества $A$
будет выполнено неравенство:
$$
\sum_{i}\mathbf{P}(A_{i})\leq \sum_{m} \mathbf{P} (C_{m} )
$$
Следовательно и
$$
\mathbf{P^{*}}(A)=\inf_{\{C_{i}\} \in \gamma(A)}(\sum_{m}
\mathbf{P} (C_{m} ))\geq \sum_{i}\mathbf{P}(A_{i})
$$

Во-вторых, докажем, что
$\mathbf{P^{*}}(A)\geq\sum_{i}\mathbf{P}(A_{i})$. Это очень легко,
т.к. $\{A_{i}\}$ - сами представляют собой последовательность
накрывающую $A$, то $\mathbf{P^{*}}(A)=inf_{\{C_{i}\}\in
\gamma(A)}(\sum_{i}\mathbf{P}(C_{i}))\leq
\sum_{i}\mathbf{P}(A_{i})$.

Один из тайных смыслов свойства EM2 заключается в том, что на
алгебре $\mathcal{A}$ внешняя мера $\mathbf{P^{*}}$ совпадает с
уже имеющейся вероятностью $\mathbf{P}$.

Доказательство EM3:

Сначала докажем свойство EM3 для множеств $A_{i}$, лежащих в
$\mathcal{A}$:

Старый трюк! От последовательности $A_{i}$, где возможны попарные
пересечения, перейдем к последовательности $\widetilde{A_{i}}$,
где попарных пересечений нет.

$$
\mathbf{P^{*}}(\bigcup_{i} A_{i})=\mathbf{P^{*}}(\bigcup_{i}
\widetilde{A_{i}})
$$
По только что доказанному второму свойству:
$$
\mathbf{P^{*}}(\bigcup_{i} \widetilde{A_{i}})
=\sum_{i}\mathbf{P}(\widetilde{A_{i}})
$$
По свойству старого трюка:
$$
\sum_{i}\mathbf{P}(\widetilde{A_{i}})\leq
\sum_{i}\mathbf{P}(A_{i})
$$
В силу EM2:
$$
\sum_{i}\mathbf{P}(A_{i}) = \sum_{i}\mathbf{P^{*}}(A_{i})
$$

Итого, для $A_{i} \in \mathcal{A}$ мы получили:
$$
\mathbf{P^{*}}(\bigcup_{i} A_{i}) \leq
\sum_{i}\mathbf{P^{*}}(A_{i})
$$
Перейдем к доказательству общего случая (general case). Особо
внимательный слушатель или читатель может заметить, что для этого
доказательства необходимо существование упомянутого general case.
Недавно математикам стало известно, что General Case существует!

... General Case, a graduate of West Point. The General gave long
... service to the U.S. Army


Смысл числа $\mathbf{P^{*}}(D)$ состоит в том, что найдется такое
накрытие $\{D_{i}\}$, которое будет накрывать $D$ с произвольной
точностью. Т.е. сумма $\sum_{i} \mathbf{P}(D_{i})$ будет не меньше
чем внешняя мера $\mathbf{P^{*}}(D)$, но при этом сколь угодно
близка к ней.

Итак, имеется последовательность произвольных $A_{i}$. Зафиксируем
произвольное $\varepsilon$.

Подберем последовательность $A_{1}^{k}$ накрывающую $A_{1}$ с
точностью до $\frac{\varepsilon}{2}$, т.е. $\sum_{k}
\mathbf{P}(A_{1}^{k})\leq
\mathbf{P^{*}}(A_{1})+\frac{\varepsilon}{2}$.

Подберем последовательность $A_{2}^{k}$ накрывающую $A_{2}$ с
точностью до $\frac{\varepsilon}{4}$.

Подберем последовательность $A_{3}^{k}$ накрывающую $A_{3}$ с
точностью до $\frac{\varepsilon}{8}$.

И т.д.

Заметим, что получившаяся последовательность $\{A_{i}^{k}\}$ будет
накрывать $A$.

По свойству EM1 внешней меры
$$
\mathbf{P^{*}}(\bigcup_{i}A_{i})\leq
\mathbf{P^{*}}(\bigcup_{i,k}A_{i}^{k})
$$
Т.к. для множеств из $\mathcal{A}$ свойство EM3 уже доказано, то
$$
\mathbf{P^{*}}(\bigcup_{i,k}A_{i}^{k}) \leq \sum_{i,k}
\mathbf{P^{*}}(A_{i}^{k})
$$
На алгебре вероятность и внешняя мера совпадают, поэтому
$$
\sum_{i,k} \mathbf{P^{*}}(A_{i}^{k})=\sum_{i} \sum_{k}
\mathbf{P}(A_{i}^{k})
$$

В силу выбора накрытий $A_{i}^{k}$ получаем переход:
$$
\sum_{i} \sum_{k} \mathbf{P}(A_{i}^{k})
\leq
\sum_{i}
(\mathbf{P^{*}}(A_{i})+\frac{\varepsilon}{2^{i}})
$$
Вспомнив девятый класс и формулу суммы геометрической прогрессии,
получаем:
$$
\sum_{i} (\mathbf{P^{*}}(A_{i})+\frac{\varepsilon}{2^{i}})
\leq
\sum_{i} \mathbf{P^{*}}(A_{i}) + \varepsilon
$$


\textbf{Расстояние. Метрика.}

Слова расстояние и метрика - это синонимы.

Если есть произвольный набор объектов, то между ними можно
придумать расстояние. Расстояние - это не обязательно то, что
можно померить линейкой. Например, расстояние между городами можно
мерить стоимостью телефонного звонка.

Мера - это размер подмножества, а метрика - это расстояние между
двумя элементами множества.

\begin{mydef}
Расстояние $\rho(x,y)$ - любая функция удовлетворяющая трем
аксиомам:

R1: $\rho(x,y)=\rho(y,x)\geq 0$

R2: $\rho(x,y)=0 \Leftrightarrow x=y$

R3: Неравенство треугольника. $\rho(x,y) \leq \rho(x,z)+\rho(z,y)$
\end{mydef}
Классический пример метрики - привычное расстояние на плоскости:

$\rho((x_{1},x_{2}),(y_{1},y_{2}))=\sqrt{(x_{1}-y_{1})^{2}+(x_{2}-y_{2})^{2}}$

Можно измерять расстояние другим способом, например:
$\rho((x_{1},x_{2}),(y_{1},y_{2}))=|x_{1}-y_{1}|+|x_{2}-y_{2}|$

В качестве упражнения можно убедиться, что эти две функции
удовлетворяют аксиомам R1-R3.

Мы будем измерять расстояние между множествами:
$\rho(A,B)=\mathbf{P^{*}}(A\triangle B)$

Тем кто не знал и забыл, что такое симметрическая разность
множеств, $A\triangle B$, напоминаем: под $A\triangle B$
понимается то, чем $A$ отличается от $B$. Формально $A\triangle
B=(A\setminus B)\bigcup(B\setminus A)$.

Симметрическая разность обладает свойствами:

S1. $A\triangle B=B\triangle A=\overline{A}\triangle
\overline{B}\subseteq A\bigcup B$

S2. $A\triangle A=\emptyset$

S3. $A\triangle\emptyset=A$

S4. $(A\triangle B)\triangle C=A\triangle (B\triangle C)$

S5. $(\bigcup A_{i})\triangle (\bigcup B_{i}) \subseteq \bigcup
(A_{i} \triangle B_{i})$

Доказательство свойств S1-S4 - нетрудное упражнение.

Доказательство S5:

Пусть некий $x \in (\bigcup A_{i})\triangle (\bigcup B_{i})$.

Если $x \in (\bigcup A_{i})$, то $x \notin (\bigcup B_{i})$, а
значит найдется такой номер $i$, что $x \in A_{i}$ и $x \notin
B_{i}$. Следовательно, $x \in A_{i} \triangle B_{i}$, а значит
такой $x$ принадлежит правой части.

Случай $x \in (\bigcup B_{i})$ рассматривается точно так же.


Полезно понимать, что в множество $A\triangle B\triangle C$ входят
только те элементы, которые встречаются нечетное число раз в
упомянутых $A$, $B$ и $C$.


В силу свойств симметрической разности, придуманное нами
расстояние между множествами обладает свойствами:

D1. $\rho(A,B)=\rho(B,A)=\rho(\overline{A},\overline{B})\geq 0$

D2. $\rho(A,A)=0$

Тут можно заметить, что введенное нами $\rho(A,B)$ не совсем
расстояние, потому что из $\rho(A,B)=0$ не следует, что $A=B$. Ну
и ладно.

D3. $\rho(A,B)\leq \rho(A,C)+\rho(C,B)$

D4. $\rho(\bigcup A_{i},\bigcup B_{i})\leq \sum\rho(A_{i},B_{i})$

D5. $|\mathbf{P^{*}}(A)-\mathbf{P^{*}}(B)|\leq\rho(A,B)$

Доказательство свойств D1-D4 - самостоятельное упражнение.

Доказательство D5:

$$ A\subseteq B\bigcup (A\triangle B) $$
$$ \mathbf{P^{*}}(A)\leq\mathbf{P^{*}}(B\bigcup (A\triangle B))
\leq \mathbf{P^{*}}(B)+\mathbf{P^{*}}(A\triangle B)$$
$$ \mathbf{P^{*}}(A)-\mathbf{P^{*}}(B)\leq \mathbf{P^{*}}(A\triangle
B)= \rho(A,B)$$

По аналогии можно получить, что
$$ \mathbf{P^{*}}(B)-\mathbf{P^{*}}(A)\leq \rho(A,B)$$

На практике D5 означает, что из $\rho(A_{i},A)\rightarrow 0$
следует, что $\mathbf{P^{*}}(A_{i})\rightarrow\mathbf{P^{*}}(A)$.


\begin{mydef}
Назовем множество $A$ аппроксимируемым (<<хорошим>>), если найдется
последовательность $A_{i}\in\mathcal{A}$, такая что
$\rho(A,A_{i})\rightarrow 0$.
\end{mydef}
Другими словами множество называется хорошим, если найдется сколь
угодно похожее на него множество в исходной алгебре $\mathcal{A}$.

\begin{myth}
Аппроксимируемые множества образуют $\sigma$-алгебру.
\end{myth}
Доказательство.

Обозначим набор всех аппроксимируемых множеств буквой
$\mathcal{U}$.

Докажем, что $\mathcal{U}$ удовлетворяет аксиомам
$\sigma$-алгебры:

A1. $\Omega\in\mathcal{U}$

A2. $A\in\mathcal{U}\Rightarrow \overline{A}\in\mathcal{U}$

A3. $A_{i}\in\mathcal{U}\Rightarrow \bigcup A_{i}\in\mathcal{U}$

Доказательство А1 и А2 не вызывает особых трудностей и оставлено в
качестве упражнения. Доказательство A3:

Для начала докажем более слабое утверждение:
$A_{i}\in\mathcal{A}\Rightarrow \bigcup A_{i}\in\mathcal{U}$

Старый трюк снова подвернулся под руку: от возможно пересекающихся
$A_{i}$ перейдем к непересекающимся $\widetilde{A_{i}}$.

Итак, $A=\bigcup \widetilde{A_{i}}$.
$$
\rho(A,\bigcup_{i=1}^{k} \widetilde{A_{i}})=
\mathbf{P^{*}}(\bigcup_{i=k+1}^{+\infty}\widetilde{A_{i}})=
\sum_{i=k+1}^{+\infty}\P(\widetilde{A_{i}})
$$
В силу того, что ряд
$\sum_{i=1}^{+\infty}\P(\widetilde{A_{i}})=\mathbf{P^{*}}(A)\leq 1$
сходится предел остаточных сумм $\lim_{k\rightarrow
+\infty}\sum_{i=k+1}^{+\infty}\P(\widetilde{A_{i}})=0$.

Таким образом, мы доказали, что $A$ можно сколь угодно приблизить
множествами из $\mathcal{U}$.

Перейдем к более общему случаю $A_{i}\in\mathcal{U}$.

Выберем произвольное $\varepsilon>0$. Т.к. $A_{1}$ "хорошее"
множество, то найдется $C_{1}\in \mathcal{A}$ такое, что
$\rho(A_{1},C_{1})<\frac{\varepsilon}{2^{1}}$. Аналогично, каждое
$A_{i}$ мы заменим на множество $C_{i}$ из исходной алгебры
$\mathcal{A}$ так чтобы
$\rho(A_{i},C_{i})<\frac{\varepsilon}{2^{i}}$.

В силу свойства расстояния D4 получаем: $\rho(\bigcup
A_{i},\bigcup C_{i})\leq \sum \rho(A_{i},C_{i})<\sum
\frac{\varepsilon}{2^{i}}=\varepsilon $.

Другими словами, выбрав подходящее $\varepsilon$ можно добиться
того, что расстояние между $\bigcup A_{i}$ и $\bigcup C_{i}$ будет
сколь угодно мало.

Но само множество $\bigcup C_{i}$ является аппроксимируемым, т.к.
все $C_{i} \in \mathcal{A}$. Следовательно, найдется $C \in
\mathcal{A}$ такое, что $\rho(\bigcup C_{i},C)<\varepsilon$.

Мы получили, что $\bigcup A_{i}$ похоже на $\bigcup C_{i}$, а
$\bigcup C_{i}$ похоже на $C$. Используя неравенство треугольника,
$\rho(\bigcup A_{i},C)\leq \rho(\bigcup A_{i},\bigcup
C_{i})+\rho(\bigcup C_{i},C) < 2\varepsilon$.

Т.е. множество $\bigcup A_{i}$ можно сколь угодно точно приблизить
с помощью множества $C$. Следовательно, $\bigcup A_{i} \in
\mathcal{U}$.

\begin{myth}
На $\sigma$-алгебре $\mathcal{U}$ внешняя мера $\mathbf{P^{*}}$
обладает всеми свойствами вероятности.
\end{myth}
Требуется доказать три свойства вероятности:

P1. $\forall A\in \mathcal{U}\Rightarrow \mathbf{P^{*}}(A)\geq$
$0$

P2. Если $A_{i}$ попарно непересекаются, то
$\mathbf{P^{*}}(\bigcup A_{i})=\sum \mathbf{P^{*}}(A_{i})$

P3. $\mathbf{P^{*}}(\Omega)=1$

Доказательство свойств P1 и P3 - упражнение.

Докажем свойство P2:

Пусть $A$ и $B$ лежат в $\mathcal{U}$ и $A \bigcap B=\emptyset$.

Рассмотрим последовательности множеств $A_{i}$ и $B_{i}$,
приближающиеся к множествам $A$ и $B$.

$$
\mathbf{P^{*}}(A_{i} \bigcup B_{i})=\mathbf{P}(A_{i} \bigcup
B_{i})=\mathbf{P}(A_{i})+\mathbf{P}(B_{i})-\mathbf{P}(A_{i}
\bigcap
B_{i})=\mathbf{P^{*}}(A_{i})+\mathbf{P^{*}}(B_{i})-\mathbf{P^{*}}(A_{i}
\bigcap B_{i})
$$
Или
$\mathbf{P^{*}}(A_{i})+\mathbf{P^{*}}(B_{i})-\mathbf{P^{*}}(A_{i}
\bigcup B_{i})=\mathbf{P^{*}}(A_{i} \bigcap B_{i})$

Возьмем предел $i\rightarrow +\infty$ от обеих частей.

В силу выбора $A_{i}$ и $B_{i}$ получаем
$\mathbf{P^{*}}(A_{i})\rightarrow \mathbf{P^{*}}(A)$ и
$\mathbf{P^{*}}(B_{i})\rightarrow \mathbf{P^{*}}(B)$.

В силу D5: $|\mathbf{P^{*}}(A \bigcup B)-\mathbf{P^{*}}(A_{i}
\bigcup B_{i})|\leq \rho(A\bigcup B,A_{i}\bigcup B_{i})$

В силу D4: $\rho(A\bigcup B,A_{i}\bigcup B_{i})\leq
\rho(A_{i},A)+\rho(B_{i},B)$.

Так как оба последних расстояния стремятся к $0$, то и
$\mathbf{P^{*}}(A_{i} \bigcup B_{i})\rightarrow
\mathbf{P^{*}}(A\bigcup B)$.

Осталось доказать, что $\mathbf{P^{*}}(A_{i} \bigcap
B_{i})\rightarrow 0$:

Заметим, что $A_{i}\bigcap B_{i} \subseteq (A\triangle
A_{i})\bigcup (B\triangle B_{i})$. Пусть $x$ лежит в левой части.
Значит $x \in A_{i}$ и $x \in B_{i}$. Раз $A$ и $B$ не
пересекаются, то $x$ не попадет хотя бы в одно из этих множеств,
но тогда он попадет в соответствующую симметрическую разность.

По свойству EM3, $\mathbf{P^{*}}(A_{i} \bigcap B_{i})\leq
\mathbf{P^{*}}(A_{i} \triangle A) + \mathbf{P^{*}}(B_{i} \triangle
B)$. Здесь видно, что правая часть стремится к нулю.

Итак, мы доказали, что
$\mathbf{P^{*}}(A)+\mathbf{P^{*}}(B)=\mathbf{P^{*}}(A \bigcup B)$
для непересекающихся $A$ и $B$. Из этого автоматически следует
аддитивность внешней меры для любых конечных объединений. Если
$A_{i}$ попарно не пересекаются, то
$\mathbf{P^{*}}(\bigcup_{i=1}^{n} A_{i})=\sum_{i=1}^{n}
\mathbf{P^{*}}(A_{i})$.

Рассмотрим теперь счетное объединение.

$\mathbf{P^{*}}(\bigcup_{i=1}^{+\infty} A_{i})\geq
\mathbf{P^{*}}(\bigcup_{i=1}^{n}
A_{i})=\sum_{i=1}^{n}\mathbf{P^{*}}(A_{i})$.

Взяв предел $n\rightarrow +\infty$ слева и справа, получаем
$\mathbf{P^{*}}(\bigcup_{i=1}^{+\infty} A_{i})\geq
\sum_{i=1}^{+\infty}\mathbf{P^{*}}(A_{i})$.

Обратное неравенство $\mathbf{P^{*}}(\bigcup_{i=1}^{+\infty}
A_{i})\leq \sum_{i=1}^{+\infty}\mathbf{P^{*}}(A_{i})$ - это
доказанное свойство EM3.


\begin{myth}
Не существует вероятности, отличной от $\mathbf{P^{*}}$ на наборе
$\mathcal{U}$ и являющейся продолжением вероятности $\mathbf{P}$
\end{myth}

Доказательство.

Допустим, что существует $\mathbf{P^{'}}\neq \mathbf{P^{*}}$.

Во-первых, возможно, что $\exists A\in\mathcal{U}$, такое что
$\mathbf{P^{'}}(A)> \mathbf{P^{*}}(A)$ или
$\mathbf{P^{'}}(A)-\mathbf{P^{*}}(A)=d>0$.

Докажем, что таких $A$ не существует. По определению
$\mathbf{P^{*}}(A)$ существует такое накрытие множества $A$ с
помощью набора непересекающихся множеств $B_{i}$, что
$A\subseteq\bigcup B_{i}$ и $\mathbf{P^{*}}(A)<\sum
\mathbf{P}(B_{i})+\frac{d}{2}$. Такое накрытие существует, так как
$\mathbf{P^{*}}$ определялась как инфинум накрытий.

Итак, $\mathbf{P^{*}}(A)\leq \sum
\mathbf{P}(B_{i})<\mathbf{P^{*}}(A)+\frac{d}{2}$.

$$
\mathbf{P^{'}}(A)=\mathbf{P^{*}}(A)+d>\sum
\mathbf{P}(B_{i})+\frac{d}{2}=\sum
\mathbf{P^{'}}(B_{i})+\frac{d}{2}=\mathbf{P^{'}}(\bigcup
B_{i})+\frac{d}{2}
$$

В результате мы получили, что
$\mathbf{P^{'}}(A)>\mathbf{P^{'}}(\bigcup B_{i})+\frac{d}{2}$, что
невозможно в силу того, что $\mathbf{P^{'}}$ - это вероятность, а
$A\subseteq\bigcup B_{i}$.

Во-вторых, возможно, что $\exists A\in\mathcal{U}$, такое что
$\mathbf{P^{'}}(A)< \mathbf{P^{*}}(A)$.

Рассмотрим произвольное $A$. Используя только что опровергнутое
"во-первых" опровергаем "во-вторых":
$\mathbf{P^{*}}(\overline{A})\geq\mathbf{P^{'}}(\overline{A})
\Rightarrow 1-\mathbf{P^{*}}(A)\geq 1-\mathbf{P^{'}}(A)
\Rightarrow \mathbf{P^{*}}(A)\leq \mathbf{P^{'}}(A)$



}\subsection{Еще задачи}








\section{Неразобрано!}  \problemtext{


Глава 2. Сигма-алгебры, измеримость. \par

Знаком $\sigma(\mathcal{E})$ мы будем обозначать минимальную
$\sigma$-алгебру, порожденную множеством $\mathcal{E}$


\begin{mydef}
Пусть $\Omega=\mathbb{R}$, и $\mathcal{E}=\{$Открытые
множества$\}$. \textit{Борелевской} $\sigma$-алгеброй
$\mathcal{B}$ называется $\mathcal{B}=\sigma(\mathcal{E})$
\end{mydef}
Элементы этой $\sigma$-алгебры называются борелевскими
множествами.



\begin{myth}
Пусть $\mathcal{A}=\{$Множества вида $(-\infty ;$ t$)\}$, и
$\mathcal{E}=\{$Открытые множества$\}$. Тогда
$\sigma(\mathcal{A})=\sigma(\mathcal{E})$.
\end{myth}
Из $\mathcal{A}\subseteq\mathcal{E}$ следует, что
$\sigma(\mathcal{A})\subseteq\sigma(\mathcal{E})$

Выберем произвольное открытое $A$. Доказательство того, что
 $A\in\sigma(\mathcal{A})$ разобьем на три этапа:

Во-первых, множества вида $[a;b)\in\sigma(\mathcal{A})$ в силу
того, что $[a;b)=(-\infty;b)\bigcap(\Omega \backslash
(-\infty;a))$

Во-вторых, построим последовательность множеств $A_{i}$.

$A_{1}$ будет состоять из полуинтервалов длины 1 вида $[n;n+1)$,
целиком содержащихся в $A$.

$A_{2}$ будет состоять из полуинтервалов длины $1/2$ вида
$[\frac{n}{2};\frac{n+1}{2})$, целиком содержащихся в $A$.

Каждое $A_{i}$ лежит в $\sigma(\mathcal{A})$

В-третьих, $A=\bigcup_{i=1}^{+\infty}A_{i}$





\begin{myth}
Если $\sigma(\mathcal{E})=\mathcal{B}$, то для того,
чтобы $f$ была измеримой, необходимо и достаточно, чтобы $\forall
A\in \mathcal{E}\Rightarrow$ $f^{-1}(A)\in\mathcal{F}$
\end{myth}
\begin{myth}
Если $X$ - случайная величина, а $f$ - борелевская
функция, то $f\circ X()=f(X(\cdot))$ - случайная величина.
\end{myth}
Пример. Если $X$ - случайная величина, то и $X^{2}$ - случайная
величина.


Корректно говорить, что функций $f$ является
$\mathcal{F}$-измеримой. Указывать о какой $\sigma$-алгебре идет
речь необходимо потому, что одна и та же функция может быть
измеримой относительно одной $\sigma$-алгебры и быть неизмеримой
относительно более бедной $\sigma$-алгебры. Однако, если из
контекста понятно, о какой $\sigma$-алгебре идет речь, мы будем
пропускать явное указание.



Идея replicating portfolio. \par
Пример (оценить 75 центов в случае > 1 - см. Crack)


Теорема. Формула Блэка-Шоулса в непрерывном времени как предел дискретной формулы. \par




Независимость сигма-алгебр. Независимость случайных величин. Из
независимости $X$ и $Y$ следует независимость $f(X)$ и $g(Y)$.


Для более удобной работы используются такие обозначения:


$A_{i}\uparrow A$ - $A_{i}$ "стремится снизу" к $A$. Это означает,
что $A_{1} \subseteq A_{2} \subseteq A_{3} \subseteq ...$ и
$\bigcup A_{i}=A$.

$A_{i}\downarrow A$ - $A_{i}$ "стремится сверху" к $A$. Это
означает, что $A_{1} \supseteq A_{2} \supseteq A_{3} \supseteq
...$ и $\bigcap A_{i}=A$.


Исходя из свойств P1-P3 можно вывести, что у вероятности также
имеется ряд других удобных свойств.

Если $A\in\mathcal{F}$, $B\in\mathcal{F}$, $\forall
A_{i}\in\mathcal{F}$, то выполнены, например, следующие свойства:

1. $\mathbf{P}(\overline{A})=1-\mathbf{P}(A)$

2. Если $B\subseteq A$, то $\mathbf{P}(B)\leq \mathbf{P}(A)$

3. $\mathbf{P}(A\bigcup
B)=\mathbf{P}(A)+\mathbf{P}(B)-\mathbf{P}(A\bigcap B)$

4. $\mathbf{P}(\bigcup_{i=1}^{+\infty} A_{i})=lim_{n\rightarrow
+\infty} \mathbf{P}(\bigcup_{i=1}^{n} A_{i})$

5. $A_{i} \uparrow A \Rightarrow \mathbf{P}(A)=lim_{i\rightarrow
+\infty} \mathbf{P}(A_{i})$

6. $A_{i} \downarrow A \Rightarrow \mathbf{P}(A)=lim_{i\rightarrow
+\infty} \mathbf{P}(A_{i})$


\begin{mydef}
Измеримое пространство - это набор
$(\Omega,\mathcal{F})$
\end{mydef}

\begin{mydef}
Вероятностное пространство - это набор
$(\Omega,\mathcal{F},\mathbf{P})$
\end{mydef}

Пополнение.

Пусть $(\Omega,\mathcal{F},\mathbf{P})$ - вероятностное
пространство, и $\mathbf{P}(A)=0$. Иногда может найтись такое
множество $C$, что $C$ неизмеримо, но $C \subseteq A$. Таких
ситуаций хотелось бы избежать, для этого существует процедура
пополнения (completion) вероятностного пространства.

Для начала определим набор множеств $\mathcal{N}=\{C \notin
\mathcal{F} |\exists A\supseteq C, \mathbf{P}(A)=0\}$.

$\mathcal{N}$ не является алгеброй. Например, $\Omega \notin
\mathcal{N}$.

Определим набор множеств $\mathcal{\overline{F}}=\{F\bigcup N | F
\in \mathcal{F}, N \in \mathcal{N}\}$.

Для $\overline{F}=F\bigcup N$ определим
$\mathbf{\overline{P}}(\overline{A})=\mathbf{P}(F)$.

Докажем, что $\mathcal{\overline{F}}$ - $\sigma$-алгебра:

Во-первых, $\emptyset\in \mathcal{\overline{F}}$  в силу того, что
$\emptyset=\emptyset\bigcup\emptyset$, где
$\emptyset\in\mathcal{F}$ и $\emptyset\in\mathcal{N}$.

Во-вторых,


В-третьих,
$$
\bigcup_{i}\left(F_{i}\bigcup N_{i}\right)=\left(\bigcup_{i}
F_{i}\right)\bigcup\left(\bigcup_{i} N_{i}\right)
$$
При этом $\bigcup_{i} F_{i}$ измеримо и $\bigcup_{i} N_{i} \in
\mathcal{N}$.

Докажем, что $\mathbf{\overline{P}}$ - вероятность.

Сначала установим, что определение внутренне непротиворечиво.

Допустим в $\mathcal{\overline{F}}$ появится некоторое множество
допускающее два разложения $C=F_{1}\bigcup N_{1}=F_{2}\bigcup
N_{2}$, где $N_{1}, N_{2} \in \mathcal{N}$, а $F_{1}, F_{2} \in
\mathcal{F}$, причем $\mathbf{P}(F_{1})\neq \mathbf{P}(F_{2})$.

Заметим, что $F_{1} \subset F_{2}\bigcup N_{1} \bigcup N_{2}$,
следовательно, $F_{1} \setminus F_{2} \subset (F_{2}\bigcup N_{1}
\bigcup N_{2}) \setminus F_{2}$.

Но $(F_{2}\bigcup N_{1} \bigcup N_{2})\setminus F_{2} \in
\mathcal{N}$, следовательно, $\mathbf{P}(F_{1} \setminus
F_{2})=0$.

Далее воспользовавшись тем, что $F_{1}=(F_{1}\bigcap
F_{2})\bigcup(F_{1} \setminus F_{2})$ получаем, что
$\mathbf{P}(F_{1})=\mathbf{P}(F_{1}\bigcap F_{2})$.

По аналогичному рассуждению получаем, что
$\mathbf{P}(F_{2})=\mathbf{P}(F_{1}\bigcap F_{2})$, что доказывает
непротиворечивость определения новой вероятности.

Остается доказать, что $\mathbf{P}$ является $\sigma$-аддитивной.
$\mathbf{\overline{P}}(\bigcup_{i}(F_{i}\bigcup
N_{i}))=\mathbf{\overline{P}}((\bigcup_{i}
F_{i})\bigcup(\bigcup_{i} N_{i}))=\mathbf{P}(\bigcup_{i} F_{i})$


Маленькая сенсация!

Оказывается, <<почти>> - это строгий математический термин.

Говорят, что некоторое свойство выполнено почти наверное (almost
surely, a.s.), если существует событие с вероятностью единица, на
котором свойство выполнено.

Например, $X=Y$ a.s. означает, что $\mathbf{P}(X\neq Y)=0$.

Понятие <<почти наверное>> играет важную роль в силу того, что
случайные величины равные почти наверное не отличимы по
большинству характеристик. Многие интуитивные выводы становятся
абсолютно точными, если к ним добавлять <<почти наверное>>.
Например, (скорее всего, это будет упражнением через лекцию или
две) из того, что $Var(X)=0$ следует, что $X=const$ почти
наверное.


Итак \textbf{Каратеодори} - человек и теорема!

Пусть задан набор $(\Omega,\mathcal{A},\mathbf{P})$, где
$\mathcal{A}$ - алгебра, а $\mathbf{P}$ - вероятность, заданная на
алгебре.

Вспомним, что мы определяли $\mathbf{P}$ на $\sigma$-алгебре. Там
требовалось выполнение свойств:

P1. $\mathbf{P}(A)\geq$ $0$

P2. Если $A_{i}$ попарно не пересекаются, то $\mathbf{P}(\bigcup
A_{i})=\sum \mathbf{P}(A_{i})$

P3. $\mathbf{P}(\Omega)=1$

Т.к. $\mathcal{A}$ - всего лишь алгебра, то в пункте P2 нужно
добавить условие $\bigcup_{i} A_{i} \in \mathcal{A}$. В
$\sigma$-алгебре оно было бы выполнено само собой.

P2': Если $A_{i}$ попарно не пересекаются и $\bigcup_{i} A_{i} \in
\mathcal{A}$, то $\mathbf{P}(\bigcup A_{i})=\sum
\mathbf{P}(A_{i})$






Глава 6. Интеграл Лебега. \par

<<Четыре шага>> \par
Для индикатора. \par
Для простой. \par
Для неотрицательной. \par
Для любой действительной. \par

FL. Fatou's Lemma. \par
Если $X_{n}\ge 0$, то
$$
E\left(\liminf_{n\rightarrow +\infty}X_{n}\right)\le
\liminf_{n\rightarrow +\infty}\E(X_{n})
$$

MCT. Monotone Convergence Theorem. \par
Если $X_{n+1} \ge X_{n} \ge 0$, то
$$
\lim_{n\rightarrow +\infty}\E(X_{n})=E\left(\lim_{n\rightarrow
+\infty}X_{n}\right)
$$

DCT. Dominated Convergence Theorem. \par
Если $X_{n}\rightarrow X$ п.н. и $|X_{n}|<Y$, где $\E(Y)<+\infty$,
то $\E(|X|)<+\infty$ и
$$ \lim_{n\rightarrow +\infty}\E(X_{n})=\E(X) $$
$$ \lim_{n\rightarrow+\infty}\E(|X_{n}-X|)=0 $$

В MCT и FL пределы могут принимать значение $+\infty$. \par

BCT. Bounded Convergence Theorem. \par
Если $X_{n}\rightarrow X$ (in P) и $|X_{n}|<M$, то
$\lim_{n\rightarrow +\infty}\E(X_{n})=\E(X)$. \par


Примеры: \par
Мат. ожидание = $\int dP$ \par
Площадь под кривой = $\int d\lambda$ \par

Теорема: \par
Интеграл Римана = интеграл Лебега \par

Теорема: \par
Пусть с.в. $X$ индуцирует меру $Pr$ на прямой. Тогда $\int f(X)dP=\int fdPr$ \par
Док-во: <<Четыре шага>> \par

Определение. Функция плотности. \par

Теорема: \par
Если у с.в. $X$ есть функция плотности, то $\int fdPr=\int fpd\lambda$ \par
Док-во: <<Четыре шага>> \par

Задачи: \par
доказать MCT, DCT для почти наверное \par
доказать FL для вероятности \par


Теорема: Если $X$ и $Y$ независимы, то $\E(XY)=\E(X)\E(Y)$ \par
Док-во: <<Четыре шага>> \par


Неравенства: Jensen, Cauchy-Schwarz, Holder. \par
Jensen - да, остальные - ? \par

Теорема Фубини (4 шага, возможно шаг 1 неполностью) \par
Взятие производной под интегралом. \par





Глава 8. Условное ожидание. \par

Условное математическое ожидание. Мыслим как о проекции.
Формальное определение. Свойства \par
Теорема Пифагора! \par
Теорема Радона-Никодима (без док-ва?). \par


Свойства в куче: \par
1. Единственность почти наверное. Если $Y_{1}=\E(X|\mathcal{H})$ и $Y_{2}=\E(X|\mathcal{H})$ то $Y_{1}=Y_{2}$ ae \par
Пусть $X$, $X_{n}$ и $Y$ - интегрируемые (из $L^{1}$) случайные величины. \par
2. $ \E(\E(X|\mathcal{H}))=\E(X) $ \par
3. $ \mathcal{H}=\{\emptyset,\Omega\} \Rightarrow \E(X|\mathcal{H})=\E(X) $ \par
4. $ X \in \mathcal{H} \Rightarrow \E(X|\mathcal{H})=X $ (as) \par
5. $\E(aX+bY|\mathcal{H})=a\E(X|\mathcal{H})+b\E(Y|\mathcal{H}) $ \par
6. $X \ge 0 \text{(as)} \Rightarrow \E(X|\mathcal{H})\ge 0$ (as) \par
7. $ X \ge Y \text{(as)} \Rightarrow \E(X|\mathcal{H})\ge \E(Y|\mathcal{H})$ (as) \par
8. $ |\E(X|\mathcal{H})|\le \E(|X||\mathcal{H})$ (as)  \par
9. $ X \in \mathcal{H}, XY \in L_{1} \Rightarrow \E(XY|\mathcal{H})=X\E(Y|\mathcal{H})$ (as) \par
10. $ X_{n} \uparrow X \Rightarrow \E(X_{n}|\mathcal{H})\rightarrow
\E(X|\mathcal{H})$(as) (MCT) \par
11. Если $\mathcal{H}\subseteq \mathcal{F}$, то
$\E(X|\mathcal{H})=\E(\E(X|\mathcal{F})|\mathcal{H})$ (as) (Tower property, теорема о трех перпендикулярах) \par
12. Неравенство Йенсена \par
13. Если $X$ и $\mathcal{H}$ независимы, то $\E(X|\mathcal{H})=\E(X)$ ae \par
14. Геометрический смысл - проекция \par
$\E((X-Y)^{2})$ достигает своего минимума для $Y\in\mathcal{H}$ при $Y=\E(X|\mathcal{H})$ \par
15. Т. Пифагора $\E(X^{2})=\E(\E(X|\mathcal{H})^{2})+\E((X-\E(X|\mathcal{H}))^{2})$ \par

Док-во 9. \par
1. Пусть $X$ - неотрицательная. $Y$ - индикатор, $Y$ - простая, $Y$ - неотрицательная.\par
2. $X$ и $Y$ - любые. \par

Упражнения: \par












Глава 9. <<Практическая>>.  \par
Метод первого шага. Задача про разборчивую невесту. \par
Первым шагом: \par
1. Вероятность достичь уровня A раньше, чем (-B) \par
2. Ожидаемое время достижения уровня А или уровня (-B) \par
3. Вероятность рано или поздно выигрыть 1 рубль. \par
4. Ожидаемое время до выигрыша в 1 рубль. \par
5. Ожидаемое время обнаружения пчел Винни-Пухом (время возвращения
пьяницы домой из кабака) \par
6. Вероятность возвращения когда-либо в точку старта \par
7. Задача про хрюшек-копилок \par
8. вероятность для асимметричного блуждания, \par

Марковские цепи. \par
Марковская цепь неформально (график состояний со стрелочками) \par
Что лучше ООР или РОО? \par



Глава 10. Мартингалы в дискретном времени. \par

Тема. Определение мартингала и момента остановки. Мартингальное
преобразование. Upcrossing inequality. \par

\textbf{Определение мартингалов}

Пусть задано вероятностное пространство
$(\Omega,\mathcal{F},\mathbf{P})$.

Определение. Фильтрацией называется последовательность вложенных
$\sigma$-алгебр:
$$
\mathcal{F}_{0} \subseteq \mathcal{ F }_{1} \subseteq ...
\subseteq \mathcal{F}_{n} \subseteq ... \subseteq\mathcal{F}
$$

$\mathcal{F}_{n}$ - те события, которые мы отличаем в момент
времени $n$. \par
$\mathcal{F}$ - самая полная (подробная) $\sigma$-алгебра. Все
рассматриваемые величины являются $\mathcal{F}$-измеримыми. \par
$\mathcal{F}_{0}$ как правило состоит только из $\emptyset$ и
$\Omega$. \par

%Определение. Вероятностное пространство с фильтрацией (filtered
%probability space, stochastic basis). $(\Omega,\mathcal{F},\{
%\mathcal{F}_{n} \}, \mathbf{P})$. \par
Определение. Случайный процесс - это набор случайных величин,
заданных на одном вероятностном пространстве. \par
Определение. Случайный процесс $\{ X_{t} \}$ адаптирован к
фильтрации $\{ \mathcal{F}_{t} \}$ если $X_{t} \in
\mathcal{F}_{t}$ (условная запись для фразы "$X_{t}$ является
$\mathcal{F}_{t}$-измеримой случайной величиной"). \par
Определение. Естественная фильтрация (natural filtration).
$\mathcal{F}_{n}=\sigma(X_{0},X_{1},...X_{n})$. \par
Определение. Интегрируемый адаптированный случайный процесс $X$
называется [по отношению к $\mathcal{F}_{t}$]: \par
Мартингалом (martingale): $\E(X_{t+1}|\mathcal{F}_{t})=X_{t}$ п.н. \par
Субмартингалом: $\E(X_{t+1}|\mathcal{F}_{t})\ge X_{t}$ п.н. \par
Супермартингалом: $\E(X_{t+1}|\mathcal{F}_{t})\le X_{t}$ п.н. \par

Мартингал полезно понимать, как денежное благосостояние игрока
после $n$ раундов честной игры. \par
Субмартингал соответствует игре в пользу игрока. \\
С точки зрения игрока, в супермартингале нет ничего "суперского"
:) \\


% Откуда происходит название? \par
% Определение. Функция $f(x_{1},...,x_{n})$ называется
% супергармонической, если у нее есть непрерывные производные
% первого и второго порядков и $\partial^{2}f/\partial
% x_{1}^{2}+...+\partial^{2}f/\partial x_{n}^{2}\le 0$. \par
% Теорема (без доказательства). Если $f(x)$ супергармоническая, то
% $$
% f(x) \ge \frac{1}{|B(0,r)|} \int_{B(x,r)}f(y)dy
% $$
% Упражнение. Пусть $X_{1}$, $X_{2}$, ... - iid, равномерны в шаре
% $B(0,1)$. Определим $S_{n}=S_{n-1}+X_{n}$. Докажите, что
% $M_{n}=f(S_{n})$ - супермартингал, если $f(x)$ -
% супергармоническая. \par
% Происхождение названия 'супергармонической' функции в этом курсе останется нераскрытым :)

Обозначения. Вместо формального $\{ X_{n} \}_{n=0,1,2...}$ мы
будем писать просто $X_{n}$ или даже $X$. \par

Упражнение 1. \par
Докажите, что если $X$ - мартингал, то \par
1. $\E(X_{n}|\mathcal{F}_{m})=X_{m}$ п.н. для $m\le n$ \par
2. $\E(X_{n+1}) = \E(X_{n})$ \par
Докажите аналогичные свойства для суб- и супермартингалов \par

Упражнение 2. \par
Докажите, что если процесс $X$ - супермартингал по отношению к
некой фильтрации $\{ \mathcal{F}_{n} \}$, то он также
супермартингал по отношению к естественной фильтрации
$\sigma(X_{0},X_{1},...X_{n})$. \par
Докажите, что $X$ - супермартингал $\Leftrightarrow$ $(-X)$ -
субмартингал. \par
Докажите, что
$$
\left \{
\begin{array}{rcl}
X \text{- субмартингал} \\
X \text{- супермартингал} \\
\end{array}
\right. \Leftrightarrow X \text{- мартингал}
$$
Упражнение 3. \par
3.1. Докажите, что если $X$ - мартингал, $\phi$ - выпуклая вниз и
$\phi(X_{n})$ - интегрируемая величина то $\phi(X)$ -
субмартингал. \par
3.2. Докажите аналогичный результат для случая, когда $X$ -
субмартингал, а $\phi$ - выпуклая вниз и неубывающая \par

Пример 1. \par
$S_{0}=0$, $\E(X_{i})=0$ /кстати, из этого, в частности, следует,
что $\E(|X_{i}|)<+\infty$ - интегрируемость/, $X_{i}$ - независимы,
$S_{n}=\sum_{i=1}^{n}
X_{i}$ \par
$S$ - мартингал по отношению к фильтрации, порождаемой последовательностью $X_{i}$. \par

Пример 2. \par
$X_{i}$ - независимы, $\E(X_{i})=0$, $Var(X_{i})=\sigma^{2}$,
$M_{n}=S_{n}^{2}-n\sigma^{2}$ \par
$M_{n}$ - мартингал по отношению к $X_{i}$ \par

Пример 3. Мартингал Леви.\par
$Y$ - произвольная интегрируемая случайная величина,
$\mathcal{F}_{n}$ - произвольная фильтрация. \par
$X_{n}=\E(Y|\mathcal{F}_{n})$ - мартингал. \par

Пример 4. \par
Возрастающая последовательность действительных чисел -
субмартингал. \par

Пример 5. \par
$X_{n}\ge 0$, $X_{i}$ - независимы, $\E(X_{n})=1$, $M_{0}=1$,
$M_{n}=X_{1}\cdot X_{2}
\cdot ... \cdot X_{n}$ \par
$M_{n}$ - мартингал по отношению к $X_{n}$ \par

Пример 6. \par
$Y_{i}$ - iid, $\phi(\lambda)=\E(exp(\lambda Y_{i}))<+\infty$,
тогда $X_{i}=exp(\lambda Y_{i})/\phi(\lambda)$ подходят в условия
предыдущего примера, и имеется целый набор мартингалов (для
каждого $\lambda$):
$$
M_{n}=exp\left(\lambda \sum_{i=1}^{n}
Y_{i}\right)/\phi(\lambda)^{n}
$$ \par
Среди этого набора мартингалов может быть особо полезен мартингал,
получающийся в случае такого $\lambda_{0}$, что
$\phi(\lambda_{0})=1$. \par

Пример 7. \par
Пуассоновский процесс. \par
P1. При $0=t_{0}<t_{1}<t_{2}<...<t_{n}$ величины
$N(t_{k})-N(t_{k-1})$ являются независимыми. \par
P2. Величина $N(t)-N(s)$ имеет распределение Пуассона с параметром
$\lambda \cdot (t-s)$ \par

Распределение Пуассона с параметром $\lambda$:
$\P(X=n)=e^{\lambda}\frac{\lambda^{n}}{n!}$ \par

Пусть $t_{i}$ - фиксированные моменты времени и
$X_{i}=N(t_{i})-\lambda\cdot t_{i}$. \par
Тогда $(X_{i},\mathcal{F}_{i}=\sigma(N(t),t\le t_{i}))$ -
мартингал. \par


Упражнение. \par
Руководствуясь примером 6 постройте мартингал из iid
$ Y_{i}=
\left\{
\begin{array}{rcl}
1, p \\
-1, 1-p \\
\end{array}
\right.
 $ \par
При подборе $\lambda$ заметьте, что уравнение $\phi(\lambda)=1$
будет иметь два корня!

Упражнение. \par
Постройте <<мультипликативный>> мартингал из $ Y_{i}= \left\{
\begin{array}{rcl}
1, p \\
0, 1-p \\
\end{array}
\right. $ \par

Упражнение. \par
Докажите, что максимум двух субмартингалов (по отношению к одной
фильтрации) - также субмартингал \par

Игрок может не просто играть в честную игру, но и делать ставки.
Естественно ставка должна определяться только из прошлой
информации.

Определение. Процесс $C$ на $(\Omega,\mathcal{F},\{\mathcal{F}_{n}
\}, \mathbf{P})$ называется предсказуемым (predictable,
nonanticipating) если $C_{n} \in \mathcal{F}_{n-1}$ \par

$C_{n}$ - это размер ставки.

Игра со ставками будет формально выглядеть как:

Определение. Мартингальным преобразованием (martingale transform)
процесса $X$ называется процесс:
$$
(C\cdot X)_{n}=\sum_{i=1}^{n} C_{i} (X_{i}-X_{i-1}), $$ $$ (C\cdot
X)_{0}=0
$$

Нетрудно заметить, что $X_{i}-X_{i-1}$ - это выигрыш в $i$-ой
игре, а $C_{i}$ - ставка, т.е. множитель для выигрыша. \par

Мартингальное преобразование - это дискретная версия интеграла. \par

Теорема. Если $X$ - супермартингал, $C_{n}\ge 0$ - предсказуемый
процесс и
каждая $C_{i}$ ограничена (т.е. $\forall i \exists a : |C_{i}|<a$), то $C\cdot X$ - также супермартингал. \par
Доказательство. \par
В силу ограниченности всех $C_{i}$, следует интегрируемость $(C
\cdot X)_{n}$. \par
$$
\E((C\cdot X)_{n+1}|\mathcal{F}_{n})=(C\cdot
X)_{n}+\E(C_{n+1}(X_{n+1}-X_{n})|\mathcal{F}_{n})=
$$
$$ =(C\cdot
X)_{n}+C_{n+1}\E(X_{n+1}-X_{n}|\mathcal{F}_{n})\le (C\cdot X)_{n}
$$

Упражнение. \par
Убедитесь в том, что эта теорема верна для субмартингалов без
изменений, а для мартингалов верна даже без условия $C_{n} \ge 0$.
\par

Мораль. В честной игре бесполезно изменять ставку в зависимости от
текущего везения-невезения: это не изменит ожидаемого выигрыша.
Нельзя победить систему. "System theorem". \par
С другой стороны, честную или благоприятную игру нельзя испортить
меняя ставки даже если очень стараться :) \par
Нетрудно догадаться, что и стратегия выхода из игры после крупного
выигрыша не повлияет на ожидаемый выигрыш. Выход из игры после
крупного выигрыша равносилен нулевой ставке.  \par



Хотя с помощью игровых стратегий невозможно сделать деньги, они
пригодятся для доказательства теорем :) \par
А можно ли сделать деньги с помощью теорем? \par

Определим остановленный процесс. Остановленный процесс $X_{N\wedge
n}$ совпадает с исходным процессом $X_{n}$ до момента $N$ и равен
$X_{N}$ после. \par

Теорема. \par
Пусть $N$ - момент остановки и $X$ - супермартингал. Тогда
остановленный процесс $X_{N\wedge n}$ является супермартингалом. \par

Доказательство \par
Определим $C_{n}=1_{N\ge n}$. Стратегия <<ставим по рублю вплоть до
остановки>>. Заметим, что процесс $C$ является предсказуемым, т.к.
$\{N\ge n\}=\{N\le n-1\}^{c}\in \mathcal{F}_{n-1}$. Из теоремы о
мартингальном преобразовании следует, что $(C\cdot
X)_{n}=X_{N\wedge n}-X_{0}$ - также является
супермартингалом. \par

Упражнение. Сформулируйте аналогичную теорему для субмартингалов и
мартингалов. \par

Пусть $X_{n}$ - субмартингал. Например, можно считать, что это
цена какой-нибудь акции. Построим график одной из
реализаций $X_{n}$. \par
Медитируем, смотрим на отсутствующий график. \par
Отметим два уровня цен $a<b$. Вопрос, на который мы сейчас в
некотором смысле ответим, звучит так: Сколько раз к моменту
времени $n$ мартингал пересечет диапазон $(a;b)$ снизу-вверх? \par
На графике таких пересечений снизу-вверх (upcrossing) ... штуки. \par

Введем последовательность случайных величин $N_{i}$. Так, чтобы
$N$ с нечетными номерами означали время начала пересечения, а $N$
с четными номерами - время окончания пересечения. \par
Формально:
$$
N_{2k-1}=\inf \{m>N_{2k-2}|X_{m}\le a\} $$
$$ N_{2k}=\inf
\{m>N_{2k-1}|X_{m}\ge b\} $$
$$
N_{0}=-1
$$
Заметим, что все $N_{i}$ являются моментами остановки (о том, что
произошло событие $N_{i}=k$, можно сделать зная $X_{1}$, ...,
$X_{k}$). \par
Рассмотрим событие $\{$момент времени $m$ приходится на $k$-ое
пересечение$\}$ \par
$\{N_{2k-1}<m\le N_{2k}\}=\{N_{2k-1}\le m-1 \}\cap\{N_{2k}\le
m-1\}^{c} \in \mathcal{F}_{m-1}$ \par
Рассмотрим $H_{m}= \left\{
\begin{array}{rcl}
1, \text{если} N_{2k-1}<m\le N_{2k} \text{для какого-нибудь} k \\
0, \text{иначе}
\end{array}
\right. $ \par
$H_{m}$ - предсказуемый процесс. \par
$U_{n}=\sup \{k|N_{2k}\le n\}$ - число законченных пересечений
снизу-вверх к моменту $n$. \par
Теорема. The upcrossing inequality (Doob) \par
$(b-a)\E(U_{n})\le \E(X_{n}-a)^{+}-\E(X_{0}-a)^{+}$ \par
Доказательство. \par
Вместо процесса $X_{n}$ рассмотрим процесс $Y_{n}$, который
совпадает с $X_{n}$, когда $X_{n}>a$, и равен $a$, если $X_{n}\le
a$. \par
Заметим, что $Y_{n}=a+(X_{n}-a)^{+}$, поэтому $Y_{n}$ -
субмартингал. Количество пересечений снизу вверх у $X_{n}$ и $Y_{n}$ одинаково. \par
Будем делать ставки на $Y$ согласно игровой стратегии $H$. Т.е.
будем каждый раз во время подъема от $a$ к $b$ делать ставку в $1$
рубль. \par
Каждый полный подъем от $a$ к $b$ дает выигрыш $\ge (b-a)$,
поэтому $(b-a)U_{n}\le (H\cdot Y)_{n}$. \par
В силу того, что мы делаем ставки на процесс $Y$, тот факт, что
последний подъем может быть неполным, а процесс $X$ может уйти
далеко вниз, нас нисколько не смущает. \par
Обозначим $K_{m}=1-H_{m}$. В силу теоремы о мартингальном
преобразовании, $(K\cdot Y)$
- субмартингал, поэтому, $\E(K\cdot Y)_{n} \ge \E(K\cdot Y)_{0}=0$.\par
Заметим, что $Y_{n}-Y_{0}=(H\cdot Y)_{n}+(K\cdot Y)_{n}$ (на
сколько раз рублей изменится благосостояние игрока, если каждый
раз делать ставку в $1$ рубль?). \par
Итого:
$$
(b-a)\E(U_{n})\le \E(H\cdot Y)_{n} = \E(Y_{n}-Y_{0})-\E(K\cdot Y)_{n}
\le \E(Y_{n})-\E(Y_{0})=$$ $$ =\E(X_{n}-a)^{+}-\E(X_{0}-a)^{+}
$$

В доказательстве использовался тот факт, что самая
<<глупая>> игровая стратегия $K$ приносит прибыль. :) \par



Подглава. Нужна ли? Равномерная интегрируемость. \par
Определение. Набор случайных величин $\{X_{\alpha}|\alpha \in A\}$
(необязательно счетный) называется равномерно интегрируемым, если:
$$
\lim_{M\rightarrow +\infty}\sup_{\alpha \in A}
E\left(|X_{\alpha}|1_{|X_{\alpha}|>M}\right)=0
$$

Пример 1. Конечный набор интегрируемых случайных величин
равномерно интегрируем. По DCT. \par

Пример 2. Если $|X_{\alpha}|<Y$ и $\E(Y)<+\infty$, то набор
$\{X_{\alpha}\}$ равномерно интегрируем. \par

Пример 3. Если набор случайных величин ограничен в смысле $L_{p}$,
$p>1$, то он равномерно интегрируем. \par
Ограничен в смысле $L_{p}$:
$sup_{\alpha}E\left(|X_{\alpha}|^{p}\right)<+\infty$. \par

Упражнение 1. \par
Равномерно интегрируемый набор ограничен в $L_{1}$.

Упражнение 2. \par
Сходящаяся в $L_{1}$ последовательность является равномерно
интегрируемой. \par

Упражнение 3. \par
Пусть $\{X_{\alpha}\}$ и $\{Y_{\beta}\}$ равномерно интегрируемы.
Тогда равномерно интегрируемо их объединение. \par

Определение. Случайная величина $X$ называется равномерно
интегрируемой, если для любой последовательности событий $A_{i}$,
такой что $\P(A_{i})\rightarrow 0$, выполнено условие $\E(X\cdot
1_{A_{i}})\rightarrow 0$. \par

Утверждение. Из равномерной интегрируемости набора
$\{X_{\alpha}\}$ следует: \par
$$
\text{UI1. } \sup_{\alpha} \E(|X_{\alpha}|)<+\infty
$$
$$
\text{UI2. } \lim_{M\rightarrow +\infty} \sup_{\alpha}
\P(|X_{\alpha}|>M)=0
$$
$$
\text{UI3. Для любой } A_{i} \text{ такой что }
\P(A_{i})\rightarrow 0 \text{ следует } \lim_{i\rightarrow +\infty}
\sup_{\alpha} \E(|X_{\alpha}|\cdot 1_{A_{i}})=0
$$
В частности из UI3 следует равномерная интегрируемость каждой
$X_{\alpha}$ \par
Утверждение. \par
Если выполнены свойства UI1 и UI3, то набор $\{X_{\alpha}\}$
равномерно интегрируем. \par
Если выполнены свойства UI2 и UI3, то набор $\{X_{\alpha}\}$
равномерно интегрируем. \par


Теорема. \par
Если $X_{n} \rightarrow X$ по вероятности, то утверждения UE1, UE2
и UE3 эквивалентны \par

Утверждение. \par
Если $X \in L_{1}$, то набор случайных величин
$\{\E(X|\mathcal{Y})|\mathcal{Y}\subseteq \mathcal{F}\}$ является
равномерно интегрируемым. \par


% про теорему о моменте остановки
% сначала в дискретном времени, потом в непрерывном

% источники:
% Ross, Second course in probability
% Stirzaker, Probability and random processes
% Williams, Probability with martingales
% Morters, Martingales
% Chang, Stochastic processes
% Blom, Problems and snapshots from probability theory


Если не ждать <<слишком>> долго, то ожидаемый выигрыш будет равен начальной сумме, $\E(X_{T})=\E(X_{1})$. Вот пример <<слишком>> долгого ожидания: ждать до выигрыша в один рубль в классическом случайном блуждании. Если $T$ - первый момент достижения суммы в один рубль, то $\E(X_{T})=X_{T}=1\neq X_{0}=0$ по построению, но ждать счастливого момента действительно придется долго: $\E(T)=+\infty$.

Точный смысл понятия <<слишком>> долго можно увидеть в теореме:

Если $X_{t}$ - мартингал, $T$ - момент остановки и выполнено хотя бы одно из пяти условий:

(i) Момент $T$ ограничен, то есть существует число $M$, такое что $T<M$.

(ii) $\P(T<+\infty)=1$ и процесс $X_{t\cap T}$ ограничен, то есть существует число $M$, такое что для любого $t$ верно неравенство $|X_{t\cap T}|<M$.

(iii) $\E(T)<+\infty$ и существует число $M$, такое что для любого $t$ верно неравенство $\E(|X_{t+1}-X_{t}||\mathcal{F}_{n})<M$.

(iv) $\P(T<+\infty)=1$, $\E(|X_{T}|)<\infty$ и $\lim_{t\to\infty}\E(X_{t}1_{T>t})=0$.

(v) $\P(T<+\infty)=1$ и мартингал $X_{t}$ является равномерно интегрируемым.

В большинстве случаев первых трех критериев достаточно для практического применения.
Четвертый критерий является следствием любого из первых трех (?).

В пятом критерии используется определение равномерной интегрируемости...
Набор случайных величин является равномерно интегрируемым, если...


Из этих критериев все кроме третьего (может есть какой-то <<предельный>> аналог и третьего? - я не знаю) работают в непрерывном времени.


Примеры:

% включить доказательство без теоремы Дуба

Тождество Вольда. Wald's identity.

Симметричное случайное блуждание, $T=min\{t|S_{t}=a\cup S_{t}=-b\}$ - подсчет $\P(S_{T}=a)$ (через $S_{t}$) и $\E(T)$ (через $S_{t}^{2}-t$)

Несимметричное случайное блуждание - подсчет $\P(S_{T}=a)$ (через $(p/q)^{S_{t}}$)

ABRACADABRA - $\E(T)$, $Var(T)$ - см. Ross, Second course

Следующая карта - красная (через долю красных карт)

Раунды при подбрасывании шляп (через $\sum X_{i} -n$) % Ross, Second

Ключи и сейфы

Ballot problem % Ross, Second

Second heart problem % Morters, Martingales, p. 31






Задачи:

% задачи из Stirzaker, 12.5

$\E(TS_{T})$ для классического случайного блуждания - ?


% идеология: лучше сделать лишний повтор, ибо: 1 - можно рассказать несколько раз, не опасаясь, что кто-нибудь поймет :), 2 - появляется большая независимость глав.



Задача.

Пусть $Y_{k}$ - количество посещений точки 0 симметричным случайным блужданием до посещения точки $k$. Заметим, что случайное блуждание может никогда не посетить точку $k$, но это событие происходит с вероятностью 0, поэтому величину $Y_{k}$ можно считать корректно определенной.
Верно ли, что $Y_{k}-2k$ - мартингал?

Решение:




Глава 14<<Практическая>>. Модель Блэка-Шоулса. \par

Предпосылка модели. \par
Решение в явном виде для $S_{t}$ \par

Уравнение на $e^{-rt}S_{t}$ \par
Уравнение на $e^{-rt}X_{t}$ \par

Теорема. Гирсанов. \par

Способ оценки актива - 1. $\E(X_{T}|\mathcal{F}_{0})$ \par

Примеры (в т.ч. оценить 75 центов в случае > 1 - см. Crack)

Необходимое условие - дифференциальное уравнение. \par

Способ оценки актива - 2. Решение ДУ с начальными условиями. \par

Пример (оценить 75 центов в случае > 1 - см. Crack)

Глава 15. Блэк-Шоулс глубже. \par
Греческие буквы. \par
Аддитивный вариант. \par
Быстрые вычисления \par
Задачи из Crack \par

Глава 16. Компьютерная. \par
Компьютерные симуляции броуновского движения. \par
Оценки мат. ожидания, дисперсии и функции плотности методом Монте-Карло. \par
Численное решение ДУ. \par
Оценка опционов через Монте-Карло и решение ДУ. \par


Глава 17. Path-Dependent Euro Option. \par
Knock-out options. Перестает действовать, если... \par
Look-back options. Выигрыш зависит от максимальной цены. \par
Asian options. Выигрыш зависит от средней цены. \par

Source: Shreve-II \par





} % скобочка от \problemtext{
